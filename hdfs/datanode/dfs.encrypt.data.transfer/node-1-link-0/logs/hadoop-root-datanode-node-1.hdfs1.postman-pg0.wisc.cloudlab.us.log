2019-01-15 10:30:39,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = c220g2-011127.wisc.cloudlab.us/128.104.222.179
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-01-15T15:50Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
2019-01-15 10:30:39,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-01-15 10:30:39,726 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/root/data
2019-01-15 10:30:39,963 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-01-15 10:30:40,056 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-01-15 10:30:40,056 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-01-15 10:30:40,320 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-01-15 10:30:40,322 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-01-15 10:30:40,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is c220g2-011127.wisc.cloudlab.us
2019-01-15 10:30:40,327 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-01-15 10:30:40,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-01-15 10:30:40,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2019-01-15 10:30:40,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-01-15 10:30:40,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-01-15 10:30:40,496 INFO org.eclipse.jetty.util.log: Logging initialized @2079ms
2019-01-15 10:30:40,621 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-01-15 10:30:40,626 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-01-15 10:30:40,635 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-01-15 10:30:40,639 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-01-15 10:30:40,639 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-01-15 10:30:40,639 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-01-15 10:30:40,674 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 33237
2019-01-15 10:30:40,676 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-01-15 10:30:40,722 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@48e92c5c{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-01-15 10:30:40,723 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@22356acd{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-01-15 10:30:40,808 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@366ac49b{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
2019-01-15 10:30:40,818 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@34cdeda2{HTTP/1.1,[http/1.1]}{localhost:33237}
2019-01-15 10:30:40,818 INFO org.eclipse.jetty.server.Server: Started @2401ms
2019-01-15 10:30:41,048 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2019-01-15 10:30:41,058 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-01-15 10:30:41,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-01-15 10:30:41,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-01-15 10:30:41,172 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-01-15 10:30:41,193 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2019-01-15 10:30:41,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2019-01-15 10:30:41,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-01-15 10:30:41,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-01-15 10:30:41,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node-0-link-0/10.10.1.1:9000 starting to offer service
2019-01-15 10:30:41,305 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-01-15 10:30:41,305 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2019-01-15 10:30:41,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to node-0-link-0/10.10.1.1:9000
2019-01-15 10:30:41,597 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-01-15 10:30:41,639 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /root/data/in_use.lock acquired by nodename 11026@c220g2-011127.wisc.cloudlab.us
2019-01-15 10:30:41,641 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/root/data is not formatted for namespace 1084935686. Formatting...
2019-01-15 10:30:41,642 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-c8a22269-99f3-4fa4-9995-d721b8ec64b3 for directory /root/data 
2019-01-15 10:30:41,694 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1092395432-128.104.222.178-1547573433722
2019-01-15 10:30:41,694 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /root/data/current/BP-1092395432-128.104.222.178-1547573433722
2019-01-15 10:30:41,695 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/root/data and block pool id BP-1092395432-128.104.222.178-1547573433722 is not formatted. Formatting ...
2019-01-15 10:30:41,695 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1092395432-128.104.222.178-1547573433722 directory /root/data/current/BP-1092395432-128.104.222.178-1547573433722/current
2019-01-15 10:30:41,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1084935686;bpid=BP-1092395432-128.104.222.178-1547573433722;lv=-57;nsInfo=lv=-64;cid=CID-95640850-2ca8-4049-9e8d-eb63226ea2f4;nsid=1084935686;c=1547573433722;bpid=BP-1092395432-128.104.222.178-1547573433722;dnuuid=null
2019-01-15 10:30:41,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 41af7c2e-9df7-4937-95df-003d195816fa
2019-01-15 10:30:41,844 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-c8a22269-99f3-4fa4-9995-d721b8ec64b3
2019-01-15 10:30:41,845 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/root/data, StorageType: DISK
2019-01-15 10:30:41,851 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-01-15 10:30:41,863 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /root/data
2019-01-15 10:30:41,876 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /root/data
2019-01-15 10:30:41,879 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1092395432-128.104.222.178-1547573433722
2019-01-15 10:30:41,879 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1092395432-128.104.222.178-1547573433722 on volume /root/data...
2019-01-15 10:30:41,901 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1092395432-128.104.222.178-1547573433722 on /root/data: 22ms
2019-01-15 10:30:41,901 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1092395432-128.104.222.178-1547573433722: 23ms
2019-01-15 10:30:41,905 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1092395432-128.104.222.178-1547573433722 on volume /root/data...
2019-01-15 10:30:41,906 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/replicas doesn't exist 
2019-01-15 10:30:41,906 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1092395432-128.104.222.178-1547573433722 on volume /root/data: 0ms
2019-01-15 10:30:41,906 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2019-01-15 10:30:41,909 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1092395432-128.104.222.178-1547573433722 on volume /root/data
2019-01-15 10:30:41,910 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/data, DS-c8a22269-99f3-4fa4-9995-d721b8ec64b3): finished scanning block pool BP-1092395432-128.104.222.178-1547573433722
2019-01-15 10:30:41,920 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1/15/19 11:05 AM with interval of 21600000ms
2019-01-15 10:30:41,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1092395432-128.104.222.178-1547573433722 (Datanode Uuid 41af7c2e-9df7-4937-95df-003d195816fa) service to node-0-link-0/10.10.1.1:9000 beginning handshake with NN
2019-01-15 10:30:41,940 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/data, DS-c8a22269-99f3-4fa4-9995-d721b8ec64b3): no suitable block pools found to scan.  Waiting 1814399969 ms.
2019-01-15 10:30:41,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1092395432-128.104.222.178-1547573433722 (Datanode Uuid 41af7c2e-9df7-4937-95df-003d195816fa) service to node-0-link-0/10.10.1.1:9000 successfully registered with NN
2019-01-15 10:30:41,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node-0-link-0/10.10.1.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-01-15 10:30:42,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xc0d31d2c3477c3b8,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 86 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-01-15 10:30:42,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1092395432-128.104.222.178-1547573433722
2019-01-15 10:31:24,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741826_1002 src: /10.10.1.5:34138 dest: /10.10.1.4:9866
2019-01-15 10:31:25,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.5:34138, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-172532835_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741826_1002, duration(ns): 563702012
2019-01-15 10:31:25,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2019-01-15 10:31:25,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741827_1003 src: /10.10.1.5:34140 dest: /10.10.1.4:9866
2019-01-15 10:31:25,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.5:34140, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-172532835_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741827_1003, duration(ns): 471691735
2019-01-15 10:31:25,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2019-01-15 10:31:50,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741829_1005 src: /10.10.1.5:34142 dest: /10.10.1.4:9866
2019-01-15 10:31:50,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.5:34142, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336668091_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741829_1005, duration(ns): 485204039
2019-01-15 10:31:50,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.3:9866] terminating
2019-01-15 10:31:50,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741830_1006 src: /10.10.1.5:34144 dest: /10.10.1.4:9866
2019-01-15 10:31:51,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.5:34144, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336668091_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741830_1006, duration(ns): 415862948
2019-01-15 10:31:51,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2019-01-15 10:32:15,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741832_1008 src: /10.10.1.3:55638 dest: /10.10.1.4:9866
2019-01-15 10:32:16,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.3:55638, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-734539156_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741832_1008, duration(ns): 445105494
2019-01-15 10:32:16,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.5:9866] terminating
2019-01-15 10:32:16,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741833_1009 src: /10.10.1.3:55640 dest: /10.10.1.4:9866
2019-01-15 10:32:16,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.3:55640, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-734539156_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741833_1009, duration(ns): 404867719
2019-01-15 10:32:16,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.5:9866] terminating
2019-01-15 10:32:40,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741834_1010 src: /10.10.1.1:42306 dest: /10.10.1.4:9866
2019-01-15 10:32:41,008 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DataNode{data=FSDataset{dirpath='[/root/data]'}, localName='c220g2-011127.wisc.cloudlab.us:9866', datanodeUuid='41af7c2e-9df7-4937-95df-003d195816fa', xmitsInProgress=0}:Exception transfering block BP-1092395432-128.104.222.178-1547573433722:blk_1073741834_1010 to mirror 10.10.1.2:9866
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:547)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:836)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2019-01-15 10:32:41,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opWriteBlock BP-1092395432-128.104.222.178-1547573433722:blk_1073741834_1010 received exception java.io.IOException: Connection reset by peer
2019-01-15 10:32:41,013 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: c220g2-011127.wisc.cloudlab.us:9866:DataXceiver error processing WRITE_BLOCK operation  src: /10.10.1.1:42306 dst: /10.10.1.4:9866
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:547)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:836)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2019-01-15 10:32:41,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741835_1011 src: /10.10.1.5:34148 dest: /10.10.1.4:9866
2019-01-15 10:32:41,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.5:34148, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1577400368_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741835_1011, duration(ns): 445463563
2019-01-15 10:32:41,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2019-01-15 10:32:41,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741836_1012 src: /10.10.1.1:42310 dest: /10.10.1.4:9866
2019-01-15 10:32:41,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.1:42310, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1577400368_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741836_1012, duration(ns): 362794725
2019-01-15 10:32:41,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.3:9866, 10.10.1.5:9866] terminating
2019-01-15 10:32:45,015 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741834_1010 replica ReplicaBeingWritten, blk_1073741834_1010, RBW
  getNumBytes()     = 0
  getBytesOnDisk()  = 0
  getVisibleLength()= 0
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/rbw/blk_1073741834
  bytesAcked=0
  bytesOnDisk=0 for deletion
2019-01-15 10:32:45,018 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741834_1010 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/rbw/blk_1073741834
2019-01-15 10:33:05,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741837_1013 src: /10.10.1.3:55646 dest: /10.10.1.4:9866
2019-01-15 10:33:06,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.3:55646, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_535907316_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741837_1013, duration(ns): 470796142
2019-01-15 10:33:06,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.5:9866] terminating
2019-01-15 10:33:06,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741838_1014 src: /10.10.1.5:34150 dest: /10.10.1.4:9866
2019-01-15 10:33:06,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.5:34150, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_535907316_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741838_1014, duration(ns): 395121182
2019-01-15 10:33:06,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2019-01-15 10:33:15,008 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741826_1002 replica FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
2019-01-15 10:33:15,009 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741827_1003 replica FinalizedReplica, blk_1073741827_1003, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741827 for deletion
2019-01-15 10:33:15,009 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741829_1005 replica FinalizedReplica, blk_1073741829_1005, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741829 for deletion
2019-01-15 10:33:15,009 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 replica FinalizedReplica, blk_1073741830_1006, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2019-01-15 10:33:15,010 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741832_1008 replica FinalizedReplica, blk_1073741832_1008, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741832 for deletion
2019-01-15 10:33:15,010 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741833_1009 replica FinalizedReplica, blk_1073741833_1009, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741833 for deletion
2019-01-15 10:33:15,011 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741835_1011 replica FinalizedReplica, blk_1073741835_1011, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741835 for deletion
2019-01-15 10:33:15,011 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741836_1012 replica FinalizedReplica, blk_1073741836_1012, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741836 for deletion
2019-01-15 10:33:15,012 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741837_1013 replica FinalizedReplica, blk_1073741837_1013, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
2019-01-15 10:33:15,012 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741838_1014 replica FinalizedReplica, blk_1073741838_1014, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741838 for deletion
2019-01-15 10:33:15,046 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741826_1002 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741826
2019-01-15 10:33:15,078 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741827_1003 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741827
2019-01-15 10:33:15,106 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741829_1005 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741829
2019-01-15 10:33:15,130 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741830_1006 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741830
2019-01-15 10:33:15,152 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741832_1008 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741832
2019-01-15 10:33:15,173 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741833_1009 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741833
2019-01-15 10:33:15,193 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741835_1011 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741835
2019-01-15 10:33:15,212 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741836_1012 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741836
2019-01-15 10:33:15,231 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741837_1013 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741837
2019-01-15 10:33:15,250 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741838_1014 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741838
2019-01-15 10:33:43,617 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741840_1016 src: /10.10.1.5:34152 dest: /10.10.1.4:9866
2019-01-15 10:33:44,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.5:34152, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_352580614_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741840_1016, duration(ns): 450519795
2019-01-15 10:33:44,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.3:9866] terminating
2019-01-15 10:33:44,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741841_1017 src: /10.10.1.1:42338 dest: /10.10.1.4:9866
2019-01-15 10:33:44,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.1:42338, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_352580614_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741841_1017, duration(ns): 402394037
2019-01-15 10:33:44,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.5:9866, 10.10.1.3:9866] terminating
2019-01-15 10:34:09,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741843_1019 src: /10.10.1.3:55650 dest: /10.10.1.4:9866
2019-01-15 10:34:09,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.3:55650, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1891411573_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741843_1019, duration(ns): 415351781
2019-01-15 10:34:09,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.5:9866] terminating
2019-01-15 10:34:09,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741844_1020 src: /10.10.1.3:55652 dest: /10.10.1.4:9866
2019-01-15 10:34:09,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.3:55652, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1891411573_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741844_1020, duration(ns): 365972023
2019-01-15 10:34:09,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2019-01-15 10:34:33,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741845_1021 src: /10.10.1.1:42362 dest: /10.10.1.4:9866
2019-01-15 10:34:33,735 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DataNode{data=FSDataset{dirpath='[/root/data]'}, localName='c220g2-011127.wisc.cloudlab.us:9866', datanodeUuid='41af7c2e-9df7-4937-95df-003d195816fa', xmitsInProgress=0}:Exception transfering block BP-1092395432-128.104.222.178-1547573433722:blk_1073741845_1021 to mirror 10.10.1.2:9866
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:547)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:836)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2019-01-15 10:34:33,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opWriteBlock BP-1092395432-128.104.222.178-1547573433722:blk_1073741845_1021 received exception java.io.IOException: Connection reset by peer
2019-01-15 10:34:33,736 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: c220g2-011127.wisc.cloudlab.us:9866:DataXceiver error processing WRITE_BLOCK operation  src: /10.10.1.1:42362 dst: /10.10.1.4:9866
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:547)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:836)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2019-01-15 10:34:33,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741846_1022 src: /10.10.1.3:55654 dest: /10.10.1.4:9866
2019-01-15 10:34:34,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.3:55654, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-872214824_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741846_1022, duration(ns): 388492051
2019-01-15 10:34:34,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.5:9866] terminating
2019-01-15 10:34:34,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741847_1023 src: /10.10.1.3:55656 dest: /10.10.1.4:9866
2019-01-15 10:34:34,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.3:55656, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-872214824_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741847_1023, duration(ns): 387845669
2019-01-15 10:34:34,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741847_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.5:9866] terminating
2019-01-15 10:34:36,012 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741845_1021 replica ReplicaBeingWritten, blk_1073741845_1021, RBW
  getNumBytes()     = 0
  getBytesOnDisk()  = 0
  getVisibleLength()= 0
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/rbw/blk_1073741845
  bytesAcked=0
  bytesOnDisk=0 for deletion
2019-01-15 10:34:36,013 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741845_1021 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/rbw/blk_1073741845
2019-01-15 10:34:58,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741848_1024 src: /10.10.1.5:34158 dest: /10.10.1.4:9866
2019-01-15 10:34:58,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.5:34158, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_753663976_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741848_1024, duration(ns): 424708563
2019-01-15 10:34:58,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.3:9866] terminating
2019-01-15 10:34:58,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741849_1025 src: /10.10.1.1:42378 dest: /10.10.1.4:9866
2019-01-15 10:34:58,873 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DataNode{data=FSDataset{dirpath='[/root/data]'}, localName='c220g2-011127.wisc.cloudlab.us:9866', datanodeUuid='41af7c2e-9df7-4937-95df-003d195816fa', xmitsInProgress=0}:Exception transfering block BP-1092395432-128.104.222.178-1547573433722:blk_1073741849_1025 to mirror 10.10.1.2:9866
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:547)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:836)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2019-01-15 10:34:58,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opWriteBlock BP-1092395432-128.104.222.178-1547573433722:blk_1073741849_1025 received exception java.io.IOException: Connection reset by peer
2019-01-15 10:34:58,874 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: c220g2-011127.wisc.cloudlab.us:9866:DataXceiver error processing WRITE_BLOCK operation  src: /10.10.1.1:42378 dst: /10.10.1.4:9866
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:547)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:836)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2019-01-15 10:34:58,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741850_1026 src: /10.10.1.3:55658 dest: /10.10.1.4:9866
2019-01-15 10:34:59,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.3:55658, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_753663976_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741850_1026, duration(ns): 404736810
2019-01-15 10:34:59,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2019-01-15 10:35:03,012 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741849_1025 replica ReplicaBeingWritten, blk_1073741849_1025, RBW
  getNumBytes()     = 0
  getBytesOnDisk()  = 0
  getVisibleLength()= 0
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/rbw/blk_1073741849
  bytesAcked=0
  bytesOnDisk=0 for deletion
2019-01-15 10:35:03,013 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741849_1025 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/rbw/blk_1073741849
2019-01-15 10:35:23,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741851_1027 src: /10.10.1.5:34162 dest: /10.10.1.4:9866
2019-01-15 10:35:23,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.5:34162, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1278560814_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741851_1027, duration(ns): 420144925
2019-01-15 10:35:23,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.3:9866] terminating
2019-01-15 10:35:23,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741853_1029 src: /10.10.1.1:42392 dest: /10.10.1.4:9866
2019-01-15 10:35:24,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.1:42392, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1278560814_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741853_1029, duration(ns): 455815629
2019-01-15 10:35:24,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.5:9866, 10.10.1.3:9866] terminating
2019-01-15 10:35:33,014 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741840_1016 replica FinalizedReplica, blk_1073741840_1016, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741840 for deletion
2019-01-15 10:35:33,015 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741841_1017 replica FinalizedReplica, blk_1073741841_1017, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741841 for deletion
2019-01-15 10:35:33,015 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741843_1019 replica FinalizedReplica, blk_1073741843_1019, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2019-01-15 10:35:33,016 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741844_1020 replica FinalizedReplica, blk_1073741844_1020, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741844 for deletion
2019-01-15 10:35:33,016 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741846_1022 replica FinalizedReplica, blk_1073741846_1022, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741846 for deletion
2019-01-15 10:35:33,016 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741847_1023 replica FinalizedReplica, blk_1073741847_1023, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741847 for deletion
2019-01-15 10:35:33,017 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741848_1024 replica FinalizedReplica, blk_1073741848_1024, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741848 for deletion
2019-01-15 10:35:33,017 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741850_1026 replica FinalizedReplica, blk_1073741850_1026, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741850 for deletion
2019-01-15 10:35:33,017 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741851_1027 replica FinalizedReplica, blk_1073741851_1027, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741851 for deletion
2019-01-15 10:35:33,017 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741853_1029 replica FinalizedReplica, blk_1073741853_1029, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741853 for deletion
2019-01-15 10:35:33,050 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741840_1016 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741840
2019-01-15 10:35:33,080 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741841_1017 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741841
2019-01-15 10:35:33,107 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741843_1019 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741843
2019-01-15 10:35:33,130 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741844_1020 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741844
2019-01-15 10:35:33,150 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741846_1022 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741846
2019-01-15 10:35:33,170 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741847_1023 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741847
2019-01-15 10:35:33,188 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741848_1024 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741848
2019-01-15 10:35:33,205 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741850_1026 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741850
2019-01-15 10:35:33,223 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741851_1027 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741851
2019-01-15 10:35:33,240 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741853_1029 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741853
2019-01-15 10:36:01,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741855_1031 src: /10.10.1.5:34168 dest: /10.10.1.4:9866
2019-01-15 10:36:01,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.5:34168, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2020020890_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741855_1031, duration(ns): 442664609
2019-01-15 10:36:01,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2019-01-15 10:36:01,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741856_1032 src: /10.10.1.5:34170 dest: /10.10.1.4:9866
2019-01-15 10:36:01,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.5:34170, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2020020890_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741856_1032, duration(ns): 390861530
2019-01-15 10:36:01,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2019-01-15 10:36:25,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741857_1033 src: /10.10.1.3:55666 dest: /10.10.1.4:9866
2019-01-15 10:36:25,384 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DataNode{data=FSDataset{dirpath='[/root/data]'}, localName='c220g2-011127.wisc.cloudlab.us:9866', datanodeUuid='41af7c2e-9df7-4937-95df-003d195816fa', xmitsInProgress=0}:Exception transfering block BP-1092395432-128.104.222.178-1547573433722:blk_1073741857_1033 to mirror 10.10.1.2:9866
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:547)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:836)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2019-01-15 10:36:25,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opWriteBlock BP-1092395432-128.104.222.178-1547573433722:blk_1073741857_1033 received exception java.io.IOException: Connection reset by peer
2019-01-15 10:36:25,385 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: c220g2-011127.wisc.cloudlab.us:9866:DataXceiver error processing WRITE_BLOCK operation  src: /10.10.1.3:55666 dst: /10.10.1.4:9866
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:547)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:836)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2019-01-15 10:36:25,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741858_1034 src: /10.10.1.1:42420 dest: /10.10.1.4:9866
2019-01-15 10:36:25,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.1:42420, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_782739541_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741858_1034, duration(ns): 446457919
2019-01-15 10:36:25,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.3:9866, 10.10.1.5:9866] terminating
2019-01-15 10:36:25,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741859_1035 src: /10.10.1.1:42422 dest: /10.10.1.4:9866
2019-01-15 10:36:26,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.1:42422, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_782739541_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741859_1035, duration(ns): 398418223
2019-01-15 10:36:26,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741859_1035, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.5:9866, 10.10.1.3:9866] terminating
2019-01-15 10:36:30,016 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741857_1033 replica ReplicaBeingWritten, blk_1073741857_1033, RBW
  getNumBytes()     = 0
  getBytesOnDisk()  = 0
  getVisibleLength()= 0
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/rbw/blk_1073741857
  bytesAcked=0
  bytesOnDisk=0 for deletion
2019-01-15 10:36:30,017 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741857_1033 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/rbw/blk_1073741857
2019-01-15 10:36:51,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741861_1037 src: /10.10.1.3:55670 dest: /10.10.1.4:9866
2019-01-15 10:36:51,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.3:55670, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_758776378_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741861_1037, duration(ns): 438699635
2019-01-15 10:36:51,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741861_1037, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.5:9866] terminating
2019-01-15 10:36:51,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741862_1038 src: /10.10.1.5:34174 dest: /10.10.1.4:9866
2019-01-15 10:36:52,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.5:34174, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_758776378_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741862_1038, duration(ns): 390781655
2019-01-15 10:36:52,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741862_1038, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.3:9866] terminating
2019-01-15 10:37:16,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741863_1039 src: /10.10.1.1:42446 dest: /10.10.1.4:9866
2019-01-15 10:37:16,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.5:9866, 10.10.1.2:9866]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:549)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:213)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1384)
	at java.lang.Thread.run(Thread.java:748)
2019-01-15 10:37:16,231 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): 
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)
	at java.io.DataOutputStream.flush(DataOutputStream.java:123)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.sendAckUpstreamUnprotected(BlockReceiver.java:1633)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.sendAckUpstream(BlockReceiver.java:1568)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1481)
	at java.lang.Thread.run(Thread.java:748)
2019-01-15 10:37:16,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.5:9866, 10.10.1.2:9866]
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)
	at java.io.DataOutputStream.flush(DataOutputStream.java:123)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.sendAckUpstreamUnprotected(BlockReceiver.java:1633)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.sendAckUpstream(BlockReceiver.java:1568)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1481)
	at java.lang.Thread.run(Thread.java:748)
2019-01-15 10:37:16,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception for BP-1092395432-128.104.222.178-1547573433722:blk_1073741863_1039
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:891)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2019-01-15 10:37:16,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.5:9866, 10.10.1.2:9866] terminating
2019-01-15 10:37:16,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: opWriteBlock BP-1092395432-128.104.222.178-1547573433722:blk_1073741863_1039 received exception java.io.IOException: Premature EOF from inputStream
2019-01-15 10:37:16,233 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: c220g2-011127.wisc.cloudlab.us:9866:DataXceiver error processing WRITE_BLOCK operation  src: /10.10.1.1:42446 dst: /10.10.1.4:9866
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:891)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2019-01-15 10:37:16,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741864_1040 src: /10.10.1.1:42448 dest: /10.10.1.4:9866
2019-01-15 10:37:16,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.1:42448, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_686266522_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741864_1040, duration(ns): 483385828
2019-01-15 10:37:16,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741864_1040, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.5:9866, 10.10.1.3:9866] terminating
2019-01-15 10:37:16,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741865_1041 src: /10.10.1.3:55672 dest: /10.10.1.4:9866
2019-01-15 10:37:17,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.3:55672, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_686266522_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741865_1041, duration(ns): 397156835
2019-01-15 10:37:17,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2019-01-15 10:37:21,019 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741863_1039 replica ReplicaBeingWritten, blk_1073741863_1039, RBW
  getNumBytes()     = 0
  getBytesOnDisk()  = 0
  getVisibleLength()= 0
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/rbw/blk_1073741863
  bytesAcked=0
  bytesOnDisk=0 for deletion
2019-01-15 10:37:21,019 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741863_1039 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/rbw/blk_1073741863
2019-01-15 10:37:41,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741867_1043 src: /10.10.1.3:55674 dest: /10.10.1.4:9866
2019-01-15 10:37:41,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.3:55674, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-460007282_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741867_1043, duration(ns): 393902044
2019-01-15 10:37:41,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741867_1043, type=LAST_IN_PIPELINE terminating
2019-01-15 10:37:41,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1092395432-128.104.222.178-1547573433722:blk_1073741868_1044 src: /10.10.1.5:34186 dest: /10.10.1.4:9866
2019-01-15 10:37:42,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.10.1.5:34186, dest: /10.10.1.4:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-460007282_1, offset: 0, srvID: 41af7c2e-9df7-4937-95df-003d195816fa, blockid: BP-1092395432-128.104.222.178-1547573433722:blk_1073741868_1044, duration(ns): 432506607
2019-01-15 10:37:42,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1092395432-128.104.222.178-1547573433722:blk_1073741868_1044, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.3:9866] terminating
2019-01-15 10:37:51,021 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741856_1032 replica FinalizedReplica, blk_1073741856_1032, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741856 for deletion
2019-01-15 10:37:51,021 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741858_1034 replica FinalizedReplica, blk_1073741858_1034, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741858 for deletion
2019-01-15 10:37:51,022 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741859_1035 replica FinalizedReplica, blk_1073741859_1035, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2019-01-15 10:37:51,022 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741861_1037 replica FinalizedReplica, blk_1073741861_1037, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741861 for deletion
2019-01-15 10:37:51,022 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741862_1038 replica FinalizedReplica, blk_1073741862_1038, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741862 for deletion
2019-01-15 10:37:51,022 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741864_1040 replica FinalizedReplica, blk_1073741864_1040, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741864 for deletion
2019-01-15 10:37:51,023 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741865_1041 replica FinalizedReplica, blk_1073741865_1041, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741865 for deletion
2019-01-15 10:37:51,023 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741867_1043 replica FinalizedReplica, blk_1073741867_1043, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741867 for deletion
2019-01-15 10:37:51,023 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741868_1044 replica FinalizedReplica, blk_1073741868_1044, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741868 for deletion
2019-01-15 10:37:51,023 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741855_1031 replica FinalizedReplica, blk_1073741855_1031, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/data
  getBlockURI()     = file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741855 for deletion
2019-01-15 10:37:51,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741856_1032 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741856
2019-01-15 10:37:51,087 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741858_1034 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741858
2019-01-15 10:37:51,112 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741859_1035 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741859
2019-01-15 10:37:51,135 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741861_1037 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741861
2019-01-15 10:37:51,156 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741862_1038 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741862
2019-01-15 10:37:51,177 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741864_1040 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741864
2019-01-15 10:37:51,195 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741865_1041 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741865
2019-01-15 10:37:51,213 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741867_1043 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741867
2019-01-15 10:37:51,231 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741868_1044 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741868
2019-01-15 10:37:51,250 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1092395432-128.104.222.178-1547573433722 blk_1073741855_1031 URI file:/root/data/current/BP-1092395432-128.104.222.178-1547573433722/current/finalized/subdir0/subdir0/blk_1073741855
