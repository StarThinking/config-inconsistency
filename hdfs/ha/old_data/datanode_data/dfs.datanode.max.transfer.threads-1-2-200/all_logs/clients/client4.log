Found 20 items
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:21 /myfile1
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:21 /myfile10
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:21 /myfile11
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:21 /myfile12
-rw-r--r--   3 root supergroup  939524096 2019-02-28 16:21 /myfile13._COPYING_
-rw-r--r--   3 root supergroup  939524096 2019-02-28 16:21 /myfile14._COPYING_
-rw-r--r--   3 root supergroup  939524096 2019-02-28 16:21 /myfile15._COPYING_
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:21 /myfile16
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:21 /myfile17
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:21 /myfile18
-rw-r--r--   3 root supergroup  939524096 2019-02-28 16:21 /myfile19._COPYING_
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:21 /myfile2
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:21 /myfile20
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:21 /myfile3
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:21 /myfile4
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:21 /myfile5
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:21 /myfile6
-rw-r--r--   3 root supergroup  939524096 2019-02-28 16:21 /myfile7._COPYING_
-rw-r--r--   3 root supergroup  805306368 2019-02-28 16:21 /myfile8._COPYING_
-rw-r--r--   3 root supergroup  939524096 2019-02-28 16:21 /myfile9._COPYING_
file 4 has been put into HDFS
file 4 has been read from HDFS for 1 time
diff succeed!
file 4 has been read from HDFS for 2 time
diff succeed!
file 4 has been read from HDFS for 3 time
diff succeed!
2019-02-28 16:23:08,124 WARN impl.BlockReaderFactory: I/O error constructing remote block reader.
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:549)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:407)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:641)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:572)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:754)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:820)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:303)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:285)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:269)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:176)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391)
2019-02-28 16:23:08,131 WARN hdfs.DFSClient: Failed to connect to /10.10.1.2:9866 for block BP-1768601401-130.127.133.67-1551396046200:blk_1073741838_1014, add to deadNodes and continue. 
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:549)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:407)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:641)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:572)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:754)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:820)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:303)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:285)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:269)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:176)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391)
2019-02-28 16:23:08,155 INFO hdfs.DFSClient: Successfully connected to /10.10.1.3:9866 for BP-1768601401-130.127.133.67-1551396046200:blk_1073741838_1014
file 4 has been read from HDFS for 4 time
diff succeed!
file 4 has been read from HDFS for 5 time
diff succeed!
2019-02-28 16:23:46,406 WARN impl.BlockReaderFactory: I/O error constructing remote block reader.
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:549)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:407)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:641)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:572)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:754)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:820)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:303)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:285)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:269)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:176)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391)
2019-02-28 16:23:46,412 WARN hdfs.DFSClient: Failed to connect to /10.10.1.2:9866 for block BP-1768601401-130.127.133.67-1551396046200:blk_1073741847_1023, add to deadNodes and continue. 
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:549)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:407)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:641)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:572)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:754)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:820)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:303)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:285)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:269)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:176)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391)
2019-02-28 16:23:46,418 INFO hdfs.DFSClient: Successfully connected to /10.10.1.4:9866 for BP-1768601401-130.127.133.67-1551396046200:blk_1073741847_1023
file 4 has been read from HDFS for 6 time
diff succeed!
file 4 has been read from HDFS for 7 time
diff succeed!
2019-02-28 16:24:30,483 WARN impl.BlockReaderFactory: I/O error constructing remote block reader.
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:549)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:407)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:641)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:572)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:754)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:820)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:303)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:285)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:269)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:176)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391)
2019-02-28 16:24:30,489 WARN hdfs.DFSClient: Failed to connect to /10.10.1.2:9866 for block BP-1768601401-130.127.133.67-1551396046200:blk_1073741838_1014, add to deadNodes and continue. 
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:549)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:407)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:641)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:572)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:754)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:820)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:303)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:285)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:269)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:176)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391)
2019-02-28 16:24:30,511 INFO hdfs.DFSClient: Successfully connected to /10.10.1.3:9866 for BP-1768601401-130.127.133.67-1551396046200:blk_1073741838_1014
file 4 has been read from HDFS for 8 time
diff succeed!
2019-02-28 16:24:48,589 WARN impl.BlockReaderFactory: I/O error constructing remote block reader.
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:549)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:407)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:641)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:572)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:754)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:820)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:303)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:285)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:269)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:176)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391)
2019-02-28 16:24:48,598 WARN hdfs.DFSClient: Failed to connect to /10.10.1.2:9866 for block BP-1768601401-130.127.133.67-1551396046200:blk_1073741838_1014, add to deadNodes and continue. 
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:549)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:407)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:641)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:572)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:754)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:820)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:303)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:285)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:269)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:176)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391)
2019-02-28 16:24:48,617 INFO hdfs.DFSClient: Successfully connected to /10.10.1.4:9866 for BP-1768601401-130.127.133.67-1551396046200:blk_1073741838_1014
file 4 has been read from HDFS for 9 time
diff succeed!
2019-02-28 16:25:09,152 WARN impl.BlockReaderFactory: I/O error constructing remote block reader.
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:549)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:407)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:641)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:572)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:754)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:820)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:303)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:285)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:269)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:176)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391)
2019-02-28 16:25:09,158 WARN hdfs.DFSClient: Failed to connect to /10.10.1.2:9866 for block BP-1768601401-130.127.133.67-1551396046200:blk_1073741868_1044, add to deadNodes and continue. 
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:549)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:407)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:641)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:572)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:754)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:820)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:303)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:285)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:269)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:176)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391)
2019-02-28 16:25:09,162 INFO hdfs.DFSClient: Successfully connected to /10.10.1.4:9866 for BP-1768601401-130.127.133.67-1551396046200:blk_1073741868_1044
file 4 has been read from HDFS for 10 time
diff succeed!
Deleted /myfile4
file 4 has been removed from HDFS
2019-02-28 16:25:41,666 INFO hdfs.DataStreamer: Exception in createBlockOutputStream blk_1073742010_1186
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at com.google.protobuf.CodedOutputStream.refreshBuffer(CodedOutputStream.java:833)
	at com.google.protobuf.CodedOutputStream.flush(CodedOutputStream.java:843)
	at com.google.protobuf.AbstractMessageLite.writeDelimitedTo(AbstractMessageLite.java:91)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Sender.send(Sender.java:82)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Sender.writeBlock(Sender.java:170)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1753)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2019-02-28 16:25:41,671 WARN hdfs.DataStreamer: Abandoning BP-1768601401-130.127.133.67-1551396046200:blk_1073742010_1186
2019-02-28 16:25:41,704 WARN hdfs.DataStreamer: Excluding datanode DatanodeInfoWithStorage[10.10.1.2:9866,DS-79507121-270c-48ec-989e-dd53b6690550,DISK]
Found 19 items
-rw-r--r--   3 root supergroup  805306368 2019-02-28 16:25 /myfile1._COPYING_
-rw-r--r--   3 root supergroup  939524096 2019-02-28 16:25 /myfile10._COPYING_
-rw-r--r--   3 root supergroup  134217728 2019-02-28 16:25 /myfile11._COPYING_
-rw-r--r--   3 root supergroup  671088640 2019-02-28 16:25 /myfile12._COPYING_
-rw-r--r--   3 root supergroup          0 2019-02-28 16:25 /myfile13._COPYING_
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:25 /myfile14
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:25 /myfile16
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:25 /myfile17
-rw-r--r--   3 root supergroup          0 2019-02-28 16:25 /myfile18._COPYING_
-rw-r--r--   3 root supergroup          0 2019-02-28 16:25 /myfile19._COPYING_
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:25 /myfile2
-rw-r--r--   3 root supergroup  402653184 2019-02-28 16:25 /myfile20._COPYING_
-rw-r--r--   3 root supergroup          0 2019-02-28 16:25 /myfile3._COPYING_
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:25 /myfile4
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:25 /myfile5
-rw-r--r--   3 root supergroup          0 2019-02-28 16:25 /myfile6._COPYING_
-rw-r--r--   3 root supergroup          0 2019-02-28 16:25 /myfile7._COPYING_
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:22 /myfile8
-rw-r--r--   3 root supergroup          0 2019-02-28 16:25 /myfile9._COPYING_
file 4 has been put into HDFS
file 4 has been read from HDFS for 1 time
diff succeed!
file 4 has been read from HDFS for 2 time
diff succeed!
file 4 has been read from HDFS for 3 time
diff succeed!
file 4 has been read from HDFS for 4 time
diff succeed!
file 4 has been read from HDFS for 5 time
diff succeed!
file 4 has been read from HDFS for 6 time
diff succeed!
file 4 has been read from HDFS for 7 time
diff succeed!
file 4 has been read from HDFS for 8 time
diff succeed!
file 4 has been read from HDFS for 9 time
diff succeed!
file 4 has been read from HDFS for 10 time
diff succeed!
Deleted /myfile4
file 4 has been removed from HDFS
2019-02-28 16:30:09,801 INFO hdfs.DataStreamer: Exception in createBlockOutputStream blk_1073742257_1433
java.io.IOException: Got error, status=ERROR, status message , ack with firstBadLink as 10.10.1.2:9866
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1778)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2019-02-28 16:30:09,805 WARN hdfs.DataStreamer: Abandoning BP-1768601401-130.127.133.67-1551396046200:blk_1073742257_1433
2019-02-28 16:30:09,827 WARN hdfs.DataStreamer: Excluding datanode DatanodeInfoWithStorage[10.10.1.2:9866,DS-79507121-270c-48ec-989e-dd53b6690550,DISK]
Found 19 items
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:26 /myfile1
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:29 /myfile10
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:30 /myfile11
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:29 /myfile12
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:26 /myfile13
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:29 /myfile14
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:30 /myfile15
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:29 /myfile16
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:26 /myfile18
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:30 /myfile19
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:29 /myfile2
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:26 /myfile20
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:29 /myfile3
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:30 /myfile4
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:29 /myfile5
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:30 /myfile6
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:26 /myfile7
-rw-r--r--   3 root supergroup  805306368 2019-02-28 16:30 /myfile8._COPYING_
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:30 /myfile9
file 4 has been put into HDFS
file 4 has been read from HDFS for 1 time
diff succeed!
file 4 has been read from HDFS for 2 time
diff succeed!
file 4 has been read from HDFS for 3 time
diff succeed!
file 4 has been read from HDFS for 4 time
diff succeed!
file 4 has been read from HDFS for 5 time
diff succeed!
file 4 has been read from HDFS for 6 time
diff succeed!
file 4 has been read from HDFS for 7 time
diff succeed!
file 4 has been read from HDFS for 8 time
diff succeed!
file 4 has been read from HDFS for 9 time
diff succeed!
file 4 has been read from HDFS for 10 time
diff succeed!
Deleted /myfile4
file 4 has been removed from HDFS
Found 18 items
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:31 /myfile1
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:33 /myfile10
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:34 /myfile11
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:34 /myfile12
-rw-r--r--   3 root supergroup  536870912 2019-02-28 16:35 /myfile13._COPYING_
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:34 /myfile14
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:34 /myfile15
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:33 /myfile16
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:35 /myfile17
-rw-r--r--   3 root supergroup  939524096 2019-02-28 16:35 /myfile19._COPYING_
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:34 /myfile2
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:34 /myfile3
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:35 /myfile4
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:34 /myfile5
-rw-r--r--   3 root supergroup  536870912 2019-02-28 16:35 /myfile6._COPYING_
-rw-r--r--   3 root supergroup          0 2019-02-28 16:35 /myfile7._COPYING_
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:34 /myfile8
-rw-r--r--   3 root supergroup 1073741824 2019-02-28 16:34 /myfile9
file 4 has been put into HDFS
file 4 has been read from HDFS for 1 time
diff succeed!
sub_benchmark 2 signal TERM catched and let quit gracefully
file 4 has been read from HDFS for 2 time
diff succeed!
Deleted /myfile4
file 4 has been removed from HDFS
