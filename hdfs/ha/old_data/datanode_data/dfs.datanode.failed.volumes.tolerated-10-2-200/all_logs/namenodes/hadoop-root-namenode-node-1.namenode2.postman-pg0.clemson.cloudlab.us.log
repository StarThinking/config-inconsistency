2019-02-28 19:22:58,676 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode082.clemson.cloudlab.us/130.127.133.91
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-17T03:08Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-28 19:22:58,686 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-28 19:22:58,691 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-28 19:22:58,981 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-28 19:22:59,088 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-28 19:22:59,088 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-28 19:22:59,148 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-28 19:22:59,148 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-28 19:22:59,314 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-28 19:22:59,342 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-02-28 19:22:59,359 INFO org.eclipse.jetty.util.log: Logging initialized @1200ms
2019-02-28 19:22:59,467 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-28 19:22:59,481 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-28 19:22:59,492 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-28 19:22:59,495 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-28 19:22:59,495 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-28 19:22:59,495 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-28 19:22:59,521 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-28 19:22:59,522 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-28 19:22:59,531 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-28 19:22:59,532 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-28 19:22:59,567 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-28 19:22:59,568 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-28 19:22:59,642 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-28 19:22:59,671 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-02-28 19:22:59,672 INFO org.eclipse.jetty.server.Server: Started @1514ms
2019-02-28 19:23:00,012 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-28 19:23:00,063 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-28 19:23:00,078 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-28 19:23:00,079 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-28 19:23:00,082 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-28 19:23:00,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-28 19:23:00,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-28 19:23:00,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-28 19:23:00,089 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-28 19:23:00,089 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-28 19:23:00,132 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-28 19:23:00,144 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-28 19:23:00,145 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-28 19:23:00,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-28 19:23:00,150 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 28 19:23:00
2019-02-28 19:23:00,152 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-28 19:23:00,152 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-28 19:23:00,153 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-28 19:23:00,153 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-28 19:23:00,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-28 19:23:00,300 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-28 19:23:00,300 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-28 19:23:00,300 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-28 19:23:00,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-28 19:23:00,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-28 19:23:00,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-28 19:23:00,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-28 19:23:00,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-28 19:23:00,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-28 19:23:00,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-28 19:23:00,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-28 19:23:00,385 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-28 19:23:00,385 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-28 19:23:00,385 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-28 19:23:00,385 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-28 19:23:00,459 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-28 19:23:00,459 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-28 19:23:00,459 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-28 19:23:00,459 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-28 19:23:00,466 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-28 19:23:00,469 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-28 19:23:00,475 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-28 19:23:00,475 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-28 19:23:00,475 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-28 19:23:00,475 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-28 19:23:00,503 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-28 19:23:00,503 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-28 19:23:00,503 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-28 19:23:00,507 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-28 19:23:00,507 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-28 19:23:00,510 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-28 19:23:00,510 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-28 19:23:00,510 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-28 19:23:00,510 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-28 19:23:00,583 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 108049@clnode082.clemson.cloudlab.us
2019-02-28 19:23:02,239 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1420ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=376ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1147ms
2019-02-28 19:23:03,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:03,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:03,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-1-link-0/10.10.1.4:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:04,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:04,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:04,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-1-link-0/10.10.1.4:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:05,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:05,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-1-link-0/10.10.1.4:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:05,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:06,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-1-link-0/10.10.1.4:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:06,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:06,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:06,691 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-02-28 19:23:07,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-1-link-0/10.10.1.4:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:07,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:07,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:23:07,693 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-02-28 19:23:07,765 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2019-02-28 19:23:07,765 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-28 19:23:07,828 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-28 19:23:07,830 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-28 19:23:07,861 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-28 19:23:07,861 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-28 19:23:07,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-28 19:23:07,867 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-28 19:23:07,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 7349 msecs
2019-02-28 19:23:08,048 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-1-link-0:8020
2019-02-28 19:23:08,053 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-28 19:23:08,066 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-28 19:23:08,254 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-28 19:23:08,262 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-28 19:23:08,273 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2019-02-28 19:23:08,273 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2019-02-28 19:23:08,273 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-28 19:23:08,307 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-28 19:23:08,307 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-28 19:23:08,310 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-1-link-0/10.10.1.4:8020
2019-02-28 19:23:08,313 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-28 19:23:08,318 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-28 19:23:08,324 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-02-28 19:23:08,839 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=d891bdc2-e964-4ae5-8bb8-e98e94c4741b, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-c9a7a7e3-b3ff-47da-a081-2123ff463a5a;nsid=2007392119;c=1551406967379) storage d891bdc2-e964-4ae5-8bb8-e98e94c4741b
2019-02-28 19:23:08,841 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-28 19:23:08,842 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN d891bdc2-e964-4ae5-8bb8-e98e94c4741b (10.10.1.5:9866).
2019-02-28 19:23:08,844 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=d60181cc-6a21-41e2-932d-7bf14d6088ba, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-c9a7a7e3-b3ff-47da-a081-2123ff463a5a;nsid=2007392119;c=1551406967379) storage d60181cc-6a21-41e2-932d-7bf14d6088ba
2019-02-28 19:23:08,844 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-28 19:23:08,844 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN d60181cc-6a21-41e2-932d-7bf14d6088ba (10.10.1.3:9866).
2019-02-28 19:23:08,851 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=576282d3-c289-4cff-bddf-e9976e482aef, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-c9a7a7e3-b3ff-47da-a081-2123ff463a5a;nsid=2007392119;c=1551406967379) storage 576282d3-c289-4cff-bddf-e9976e482aef
2019-02-28 19:23:08,851 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-28 19:23:08,851 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 576282d3-c289-4cff-bddf-e9976e482aef (10.10.1.2:9866).
2019-02-28 19:23:08,875 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.4:9866, datanodeUuid=7c10e7c0-5f2d-48ce-8ed8-54fc880a3c3f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-c9a7a7e3-b3ff-47da-a081-2123ff463a5a;nsid=2007392119;c=1551406967379) storage 7c10e7c0-5f2d-48ce-8ed8-54fc880a3c3f
2019-02-28 19:23:08,875 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.4:9866
2019-02-28 19:23:08,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 7c10e7c0-5f2d-48ce-8ed8-54fc880a3c3f (10.10.1.4:9866).
2019-02-28 19:23:08,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-b5a56dd1-463d-4258-bdb0-7a30725c5c62 for DN 10.10.1.3:9866
2019-02-28 19:23:08,937 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-91f09d4b-d28c-4af4-b2e3-39e7d51218ec for DN 10.10.1.5:9866
2019-02-28 19:23:08,937 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-fd2e57e4-4326-421c-9021-76ec27d8725d for DN 10.10.1.2:9866
2019-02-28 19:23:08,938 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-a31acc4f-64d2-46af-b5e2-6d75c5120465 for DN 10.10.1.4:9866
2019-02-28 19:23:08,983 INFO BlockStateChange: BLOCK* processReport 0xd9828c368fbc98c3: Processing first storage report for DS-b5a56dd1-463d-4258-bdb0-7a30725c5c62 from datanode d60181cc-6a21-41e2-932d-7bf14d6088ba
2019-02-28 19:23:08,985 INFO BlockStateChange: BLOCK* processReport 0xd9828c368fbc98c3: from storage DS-b5a56dd1-463d-4258-bdb0-7a30725c5c62 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=d60181cc-6a21-41e2-932d-7bf14d6088ba, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-c9a7a7e3-b3ff-47da-a081-2123ff463a5a;nsid=2007392119;c=1551406967379), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-02-28 19:23:08,985 INFO BlockStateChange: BLOCK* processReport 0x5cad4c5f8143d7fd: Processing first storage report for DS-a31acc4f-64d2-46af-b5e2-6d75c5120465 from datanode 7c10e7c0-5f2d-48ce-8ed8-54fc880a3c3f
2019-02-28 19:23:08,985 INFO BlockStateChange: BLOCK* processReport 0x5cad4c5f8143d7fd: from storage DS-a31acc4f-64d2-46af-b5e2-6d75c5120465 node DatanodeRegistration(10.10.1.4:9866, datanodeUuid=7c10e7c0-5f2d-48ce-8ed8-54fc880a3c3f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-c9a7a7e3-b3ff-47da-a081-2123ff463a5a;nsid=2007392119;c=1551406967379), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-02-28 19:23:08,986 INFO BlockStateChange: BLOCK* processReport 0x2082f3ce41f24eff: Processing first storage report for DS-fd2e57e4-4326-421c-9021-76ec27d8725d from datanode 576282d3-c289-4cff-bddf-e9976e482aef
2019-02-28 19:23:08,986 INFO BlockStateChange: BLOCK* processReport 0x2082f3ce41f24eff: from storage DS-fd2e57e4-4326-421c-9021-76ec27d8725d node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=576282d3-c289-4cff-bddf-e9976e482aef, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-c9a7a7e3-b3ff-47da-a081-2123ff463a5a;nsid=2007392119;c=1551406967379), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-28 19:23:08,986 INFO BlockStateChange: BLOCK* processReport 0xfc5f3e0f8b1b12e9: Processing first storage report for DS-91f09d4b-d28c-4af4-b2e3-39e7d51218ec from datanode d891bdc2-e964-4ae5-8bb8-e98e94c4741b
2019-02-28 19:23:08,986 INFO BlockStateChange: BLOCK* processReport 0xfc5f3e0f8b1b12e9: from storage DS-91f09d4b-d28c-4af4-b2e3-39e7d51218ec node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=d891bdc2-e964-4ae5-8bb8-e98e94c4741b, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-c9a7a7e3-b3ff-47da-a081-2123ff463a5a;nsid=2007392119;c=1551406967379), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-28 19:23:09,468 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-02-28 19:23:09,470 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-02-28 19:23:09,573 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-28 19:23:09,583 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-02-28 19:23:09,665 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 1
2019-02-28 19:23:09,666 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-02-28 19:23:09,666 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-02-28 19:23:09,670 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-02-28 19:23:09,672 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-02-28 19:23:09,672 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-28 19:23:09,673 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 1
2019-02-28 19:23:09,675 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2019-02-28 19:23:10,108 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-28 19:23:10,113 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 5 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-02-28 19:23:10,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2019-02-28 19:23:10,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-28 19:23:10,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-28 19:23:10,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-28 19:23:10,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-28 19:23:10,119 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-02-28 19:23:10,119 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 446 msec
2019-02-28 19:23:15,250 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:23:15,353 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-28 19:23:15,374 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:23:15,410 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:23:15,453 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:23:15,469 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:23:15,487 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:23:15,500 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-28 19:23:15,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:23:15,516 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:23:15,540 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-28 19:23:15,540 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile17._COPYING_
2019-02-28 19:23:15,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:23:15,556 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile19._COPYING_
2019-02-28 19:23:15,589 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile2._COPYING_
2019-02-28 19:23:15,594 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:23:15,597 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:23:15,613 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:23:15,617 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:23:15,633 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:23:17,190 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile18._COPYING_
2019-02-28 19:23:17,192 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-28 19:23:17,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile17._COPYING_
2019-02-28 19:23:17,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile5._COPYING_
2019-02-28 19:23:17,360 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:23:17,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:23:17,379 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:23:17,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:23:18,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:23:18,346 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile18._COPYING_
2019-02-28 19:23:18,359 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-28 19:23:18,385 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-28 19:23:18,446 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-28 19:23:18,471 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-28 19:23:18,656 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:23:18,844 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-28 19:23:18,932 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:23:19,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile17._COPYING_
2019-02-28 19:23:19,280 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-28 19:23:19,303 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:23:19,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:23:19,398 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:23:19,442 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:23:19,641 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:23:19,688 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-28 19:23:19,767 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile10._COPYING_
2019-02-28 19:23:19,787 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:23:19,788 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:23:19,871 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:23:19,988 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-02-28 19:23:19,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-28 19:23:20,047 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:23:20,061 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-28 19:23:20,102 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:23:20,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:23:21,759 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile10._COPYING_
2019-02-28 19:23:21,760 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:23:21,780 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:23:21,795 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:23:22,077 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-28 19:23:22,084 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-28 19:23:22,197 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:23:22,242 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:23:22,344 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:23:22,365 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:23:22,405 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:23:22,407 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile12._COPYING_
2019-02-28 19:23:22,407 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:23:22,408 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:23:22,408 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:23:22,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1071, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:23:22,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1072, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:23:22,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1073, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:23:22,410 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1074, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:23:22,411 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1075, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:23:22,412 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1076, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:23:22,414 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1077, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:23:23,946 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1078, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile10._COPYING_
2019-02-28 19:23:24,088 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1079, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-28 19:23:24,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1080, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:23:24,163 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1081, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:23:24,164 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1082, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-28 19:23:24,165 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1083, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:23:24,168 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1084, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:23:24,173 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1085, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:23:24,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1086, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile12._COPYING_
2019-02-28 19:23:24,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1087, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:23:24,415 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1088, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-28 19:23:24,520 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1089, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:23:24,521 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1090, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:23:25,126 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1091, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile18._COPYING_
2019-02-28 19:23:25,281 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1092, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:23:25,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1093, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile11._COPYING_
2019-02-28 19:23:25,481 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1094, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:23:25,526 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1095, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile20._COPYING_
2019-02-28 19:23:25,599 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1096, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:23:25,664 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1097, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-28 19:23:25,668 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1098, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:23:25,835 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1099, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile5._COPYING_
2019-02-28 19:23:25,850 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1100, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:23:25,866 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1101, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:23:25,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1102, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:23:25,884 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1103, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:23:26,030 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1104, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-02-28 19:23:26,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1105, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile17._COPYING_
2019-02-28 19:23:26,676 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741930_1106, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:23:26,693 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741931_1107, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:23:26,750 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741932_1108, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:23:26,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741933_1109, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:23:27,021 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741934_1110, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-28 19:23:27,220 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741935_1111, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile5._COPYING_
2019-02-28 19:23:27,460 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741936_1112, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:23:27,535 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741937_1113, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:23:27,548 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741938_1114, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile18._COPYING_
2019-02-28 19:23:27,617 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741939_1115, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:23:27,756 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741940_1116, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:23:27,788 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile11._COPYING_ is closed by DFSClient_NONMAPREDUCE_-302298789_1
2019-02-28 19:23:27,789 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741941_1117, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:23:27,833 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741942_1118, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:23:28,091 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741943_1119, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile12._COPYING_
2019-02-28 19:23:28,495 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741944_1120, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:23:28,503 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741945_1121, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:23:28,586 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741946_1122, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:23:28,686 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741947_1123, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:23:28,720 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741948_1124, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:23:28,825 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741949_1125, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:23:29,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741950_1126, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile10._COPYING_
2019-02-28 19:23:29,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741951_1127, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:23:29,234 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741952_1128, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-28 19:23:29,326 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile18._COPYING_ is closed by DFSClient_NONMAPREDUCE_1124725588_1
2019-02-28 19:23:29,433 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile20._COPYING_ is closed by DFSClient_NONMAPREDUCE_222164155_1
2019-02-28 19:23:29,684 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1597311953_1
2019-02-28 19:23:29,831 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741953_1129, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:23:29,894 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile10._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1572221873_1
2019-02-28 19:23:29,963 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741954_1130, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-28 19:23:29,978 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741955_1131, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:23:30,005 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741956_1132, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:23:30,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741957_1133, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:23:30,072 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile8._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1069845706_1
2019-02-28 19:23:30,091 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile9._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1367862149_1
2019-02-28 19:23:30,360 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741958_1134, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:23:30,368 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile17._COPYING_ is closed by DFSClient_NONMAPREDUCE_1823280556_1
2019-02-28 19:23:30,613 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741959_1135, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile13._COPYING_
2019-02-28 19:23:30,869 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741960_1136, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-28 19:23:31,196 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741961_1137, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:23:31,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741962_1138, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:23:31,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741963_1139, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile19._COPYING_
2019-02-28 19:23:31,311 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile12._COPYING_ is closed by DFSClient_NONMAPREDUCE_379208872_1
2019-02-28 19:23:31,563 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741964_1140, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-28 19:23:31,738 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile15._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1991549375_1
2019-02-28 19:23:36,460 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile3._COPYING_ is closed by DFSClient_NONMAPREDUCE_1223152864_1
2019-02-28 19:23:36,460 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741965_1141, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:23:36,461 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741966_1142, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:23:37,978 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741967_1143, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:23:37,980 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741968_1144, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:23:37,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741969_1145, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:23:39,074 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741970_1146, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-28 19:23:40,502 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile7._COPYING_ is closed by DFSClient_NONMAPREDUCE_-995543549_1
2019-02-28 19:23:40,550 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741971_1147, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile2._COPYING_
2019-02-28 19:23:40,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741972_1148, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:23:45,795 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile16._COPYING_ is closed by DFSClient_NONMAPREDUCE_1998428002_1
2019-02-28 19:23:47,264 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741973_1149, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:23:47,265 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741974_1150, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:23:47,266 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741975_1151, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:23:47,266 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741976_1152, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:23:48,213 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741977_1153, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:23:48,538 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741978_1154, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-28 19:23:53,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741979_1155, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-28 19:23:53,177 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741980_1156, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:23:53,179 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile19._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1073677807_1
2019-02-28 19:23:53,396 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile13._COPYING_ is closed by DFSClient_NONMAPREDUCE_2087679112_1
2019-02-28 19:23:54,113 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741981_1157, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile14._COPYING_
2019-02-28 19:23:54,124 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-396128852_1
2019-02-28 19:24:00,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741982_1158, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:24:00,595 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 526 Total time for transactions(ms): 34 Number of transactions batched in Syncs: 295 Number of syncs: 229 SyncTimes(ms): 1794 2057 
2019-02-28 19:24:08,783 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741983_1159, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:24:08,877 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile14._COPYING_ is closed by DFSClient_NONMAPREDUCE_-891647917_1
2019-02-28 19:24:08,935 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_1666786793_1
2019-02-28 19:24:13,160 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741982_1158, newGS=1160, newLength=1161728, newNodes=[10.10.1.5:9866, 10.10.1.4:9866], client=DFSClient_NONMAPREDUCE_906408233_1)
2019-02-28 19:24:13,160 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741982_1158 => blk_1073741982_1160) success
2019-02-28 19:24:13,582 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_906408233_1
2019-02-28 19:24:16,451 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741983_1159, newGS=1161, newLength=512, newNodes=[10.10.1.4:9866, 10.10.1.3:9866], client=DFSClient_NONMAPREDUCE_-1034231932_1)
2019-02-28 19:24:16,451 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741983_1159 => blk_1073741983_1161) success
2019-02-28 19:24:28,264 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741984_1162, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:24:31,003 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741985_1163, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:24:37,576 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile6._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1034231932_1
2019-02-28 19:25:08,394 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.10.1.1
2019-02-28 19:25:08,394 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-02-28 19:25:08,394 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1, 549
2019-02-28 19:25:08,394 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 550 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 299 Number of syncs: 250 SyncTimes(ms): 1973 2259 
2019-02-28 19:25:08,415 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 550 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 299 Number of syncs: 251 SyncTimes(ms): 1983 2270 
2019-02-28 19:25:08,447 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000001 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000001-0000000000000000550
2019-02-28 19:25:08,465 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 551
2019-02-28 19:25:56,871 INFO BlockStateChange: BLOCK* processReport 0xd9828c368fbc98c4: from storage DS-b5a56dd1-463d-4258-bdb0-7a30725c5c62 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=d60181cc-6a21-41e2-932d-7bf14d6088ba, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-c9a7a7e3-b3ff-47da-a081-2123ff463a5a;nsid=2007392119;c=1551406967379), blocks: 115, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 1
2019-02-28 19:26:57,287 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 12 54 
2019-02-28 19:27:08,893 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.10.1.1
2019-02-28 19:27:08,893 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-02-28 19:27:08,893 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 551, 554
2019-02-28 19:27:08,912 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 61 95 
2019-02-28 19:27:08,914 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000551 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000551-0000000000000000555
2019-02-28 19:27:08,915 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 556
2019-02-28 19:27:10,128 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741986_1164, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:27:15,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741987_1165, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:27:15,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741988_1166, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:27:15,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741989_1167, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:27:15,742 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741990_1168, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-28 19:27:15,947 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741991_1169, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:27:21,327 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741992_1170, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:27:21,328 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741993_1171, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:27:21,329 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741994_1172, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:27:21,403 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741995_1173, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:27:21,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741996_1174, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:27:22,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741997_1175, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:27:22,321 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741998_1176, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:27:22,453 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741999_1177, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:27:24,623 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742000_1178, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:27:24,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742001_1179, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:27:25,161 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742002_1180, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:27:25,229 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742003_1181, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:27:25,237 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742004_1182, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:27:25,761 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742005_1183, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:27:25,809 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742006_1184, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:27:25,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742007_1185, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:27:26,513 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742008_1186, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-02-28 19:27:26,548 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742009_1187, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:27:28,421 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742010_1188, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:27:28,546 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742011_1189, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:27:28,934 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742012_1190, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-28 19:27:28,997 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742013_1191, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:27:29,106 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742014_1192, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-28 19:27:30,576 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742015_1193, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile10._COPYING_
2019-02-28 19:27:30,965 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742016_1194, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-28 19:27:31,114 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile10._COPYING_ is closed by DFSClient_NONMAPREDUCE_-518057306_1
2019-02-28 19:27:31,145 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile7._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1742978139_1
2019-02-28 19:27:31,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742017_1195, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-28 19:27:31,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742018_1196, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:27:31,186 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742019_1197, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:27:31,359 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742020_1198, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-28 19:27:31,647 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile15._COPYING_ is closed by DFSClient_NONMAPREDUCE_-854075612_1
2019-02-28 19:27:31,716 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742021_1199, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:27:31,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742022_1200, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:27:31,775 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742023_1201, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:27:31,822 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742024_1202, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:27:31,962 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742025_1203, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:27:32,090 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742026_1204, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-28 19:27:32,233 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742027_1205, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:27:32,263 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742028_1206, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:27:32,280 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742029_1207, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:27:32,293 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742030_1208, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:27:32,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742031_1209, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:27:32,781 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742032_1210, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-28 19:27:32,847 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742033_1211, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-28 19:27:32,876 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742034_1212, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:27:34,328 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742035_1213, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-28 19:27:34,521 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742036_1214, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:27:35,431 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742037_1215, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:27:35,433 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742038_1216, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:27:35,434 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742039_1217, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:27:35,980 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742040_1218, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:27:36,030 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742041_1219, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:27:36,034 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742042_1220, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:27:36,256 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742043_1221, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:27:36,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742044_1222, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:27:36,292 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742045_1223, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:27:36,572 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742046_1224, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:27:36,649 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742047_1225, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-28 19:27:36,701 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742048_1226, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:27:36,705 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742049_1227, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:27:36,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742050_1228, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:27:36,940 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742051_1229, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-28 19:27:37,164 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742052_1230, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-28 19:27:37,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742053_1231, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:27:37,195 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742054_1232, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:27:38,623 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742055_1233, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:27:38,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742056_1234, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:27:38,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742057_1235, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:27:38,625 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742058_1236, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:27:38,626 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742059_1237, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:27:39,004 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=576282d3-c289-4cff-bddf-e9976e482aef, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-c9a7a7e3-b3ff-47da-a081-2123ff463a5a;nsid=2007392119;c=1551406967379) storage 576282d3-c289-4cff-bddf-e9976e482aef
2019-02-28 19:27:39,004 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.10.1.2:9866
2019-02-28 19:27:39,005 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-28 19:27:39,104 INFO BlockStateChange: BLOCK* processReport 0x36558d1bf6ab0d59: Processing first storage report for DS-fd2e57e4-4326-421c-9021-76ec27d8725d from datanode 576282d3-c289-4cff-bddf-e9976e482aef
2019-02-28 19:27:39,110 INFO BlockStateChange: BLOCK* processReport 0x36558d1bf6ab0d59: from storage DS-fd2e57e4-4326-421c-9021-76ec27d8725d node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=576282d3-c289-4cff-bddf-e9976e482aef, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-c9a7a7e3-b3ff-47da-a081-2123ff463a5a;nsid=2007392119;c=1551406967379), blocks: 51, hasStaleStorage: false, processing time: 6 msecs, invalidatedBlocks: 0
2019-02-28 19:27:41,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Rescan of postponedMisreplicatedBlocks completed in 1 msecs. 0 blocks are left. 1 blocks were removed.
2019-02-28 19:27:41,507 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742060_1238, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:27:41,507 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742061_1239, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:27:41,508 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile3._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2115998805_1
2019-02-28 19:27:41,508 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742062_1240, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:27:41,509 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742063_1241, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:27:41,511 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742064_1242, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:27:42,003 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile20._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1218816907_1
2019-02-28 19:27:42,119 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742065_1243, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:27:42,206 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742066_1244, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:27:42,210 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile19._COPYING_ is closed by DFSClient_NONMAPREDUCE_1229545583_1
2019-02-28 19:27:42,415 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile18._COPYING_ is closed by DFSClient_NONMAPREDUCE_797567984_1
2019-02-28 19:27:42,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742067_1245, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile12._COPYING_
2019-02-28 19:27:42,695 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742068_1246, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-28 19:27:42,764 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742069_1247, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:27:43,007 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742070_1248, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:27:43,128 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742071_1249, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-28 19:27:43,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742072_1250, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:27:43,327 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-813918967_1
2019-02-28 19:27:43,515 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742073_1251, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:27:43,743 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742074_1252, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:27:43,912 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742075_1253, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:27:43,983 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742076_1254, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:27:44,226 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile16._COPYING_ is closed by DFSClient_NONMAPREDUCE_608806366_1
2019-02-28 19:27:44,405 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742077_1255, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:27:44,451 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742078_1256, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:27:44,845 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742079_1257, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-28 19:27:44,908 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile12._COPYING_ is closed by DFSClient_NONMAPREDUCE_-659058865_1
2019-02-28 19:27:45,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742080_1258, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:27:45,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742081_1259, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile13._COPYING_
2019-02-28 19:27:46,181 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742082_1260, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:27:46,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742083_1261, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:27:47,066 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile13._COPYING_ is closed by DFSClient_NONMAPREDUCE_-15836359_1
2019-02-28 19:27:48,621 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742084_1262, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:27:49,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742085_1263, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-28 19:27:50,201 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742086_1264, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:27:50,363 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742087_1265, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-28 19:27:50,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742088_1266, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:27:51,103 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742089_1267, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:27:51,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742090_1268, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-28 19:27:51,634 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742091_1269, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-28 19:27:51,843 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742092_1270, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:27:52,165 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742093_1271, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:27:52,178 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742094_1272, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-02-28 19:27:52,442 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742095_1273, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:27:52,639 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742096_1274, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:27:52,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742097_1275, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:27:52,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742098_1276, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile2._COPYING_
2019-02-28 19:27:53,034 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742099_1277, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-28 19:27:53,179 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742100_1278, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:27:53,476 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742101_1279, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:27:53,573 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742102_1280, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:27:53,617 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742103_1281, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:27:54,114 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_860145273_1
2019-02-28 19:27:54,180 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742104_1282, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-28 19:27:54,931 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742105_1283, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:27:54,931 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742106_1284, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:27:54,932 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742107_1285, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-28 19:27:55,467 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742108_1286, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile2._COPYING_
2019-02-28 19:27:55,641 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742109_1287, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:27:55,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742110_1288, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-28 19:27:55,698 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742111_1289, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:27:55,963 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742112_1290, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:27:55,999 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742113_1291, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile2._COPYING_
2019-02-28 19:27:56,190 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742114_1292, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:27:56,191 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile9._COPYING_ is closed by DFSClient_NONMAPREDUCE_-600933685_1
2019-02-28 19:27:56,250 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742115_1293, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-28 19:27:56,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742116_1294, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:27:57,018 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742117_1295, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:27:57,083 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742118_1296, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile14._COPYING_
2019-02-28 19:27:57,207 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742119_1297, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:27:57,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742120_1298, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:27:57,597 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742121_1299, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:27:57,610 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742122_1300, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:27:57,693 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742123_1301, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:27:57,783 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2015454464_1
2019-02-28 19:27:58,102 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742124_1302, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:27:58,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742125_1303, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-28 19:27:58,137 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742126_1304, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:27:58,551 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile14._COPYING_ is closed by DFSClient_NONMAPREDUCE_67001979_1
2019-02-28 19:27:58,553 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742127_1305, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:27:58,579 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742128_1306, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-28 19:27:58,958 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742129_1307, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:27:59,019 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile8._COPYING_ is closed by DFSClient_NONMAPREDUCE_1402922876_1
2019-02-28 19:27:59,363 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742130_1308, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:27:59,761 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742131_1309, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:28:04,105 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile11._COPYING_ is closed by DFSClient_NONMAPREDUCE_123225617_1
2019-02-28 19:28:09,641 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 517 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 224 Number of syncs: 292 SyncTimes(ms): 2124 3000 
2019-02-28 19:28:09,953 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742132_1310, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:28:14,438 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742133_1311, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile17._COPYING_
2019-02-28 19:28:15,639 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742134_1312, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile5._COPYING_
2019-02-28 19:28:20,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742135_1313, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:28:22,667 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742136_1314, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:28:23,994 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742137_1315, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile17._COPYING_
2019-02-28 19:28:23,994 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742138_1316, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-28 19:28:25,169 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742139_1317, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:28:26,076 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742140_1318, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:28:32,390 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742141_1319, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:28:35,998 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742142_1320, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:28:36,000 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742143_1321, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-28 19:28:36,386 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742144_1322, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile17._COPYING_
2019-02-28 19:28:37,693 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742145_1323, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:28:43,104 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742146_1324, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile17._COPYING_
2019-02-28 19:28:43,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742147_1325, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile5._COPYING_
2019-02-28 19:28:43,521 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742148_1326, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:28:43,568 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742149_1327, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:28:49,525 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742150_1328, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:28:49,525 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742151_1329, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:28:53,149 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742152_1330, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile5._COPYING_
2019-02-28 19:28:53,665 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile17._COPYING_ is closed by DFSClient_NONMAPREDUCE_1758667602_1
2019-02-28 19:28:53,776 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742153_1331, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:28:53,827 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742154_1332, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:28:54,389 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile6._COPYING_ is closed by DFSClient_NONMAPREDUCE_910713580_1
2019-02-28 19:28:57,410 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742155_1333, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-28 19:29:09,091 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.10.1.1
2019-02-28 19:29:09,091 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-02-28 19:29:09,091 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 556, 1151
2019-02-28 19:29:09,113 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 597 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 254 Number of syncs: 343 SyncTimes(ms): 2507 3498 
2019-02-28 19:29:09,116 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000556 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000556-0000000000000001152
2019-02-28 19:29:09,116 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1153
2019-02-28 19:29:09,670 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_200831071_1
2019-02-28 19:30:50,244 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 27 74 
2019-02-28 19:31:03,103 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742156_1334, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:31:03,651 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742157_1335, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:31:03,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742158_1336, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:31:06,621 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742159_1337, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:31:07,133 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742160_1338, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:31:07,546 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742161_1339, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:31:07,775 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742162_1340, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile10._COPYING_
2019-02-28 19:31:07,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742163_1341, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:31:07,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742164_1342, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:31:08,586 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742165_1343, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:31:09,344 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.10.1.1
2019-02-28 19:31:09,344 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-02-28 19:31:09,344 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1153, 1195
2019-02-28 19:31:09,355 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 44 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 12 Number of syncs: 32 SyncTimes(ms): 248 195 
2019-02-28 19:31:09,358 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000001153 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000001153-0000000000000001196
2019-02-28 19:31:09,358 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1197
2019-02-28 19:31:14,071 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742166_1344, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile18._COPYING_
2019-02-28 19:31:15,400 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742167_1345, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:31:20,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742168_1346, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:31:20,701 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742169_1347, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:31:20,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742170_1348, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:31:20,798 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742171_1349, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:31:20,814 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742172_1350, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:31:20,842 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742173_1351, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile10._COPYING_
2019-02-28 19:31:20,843 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742174_1352, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:31:23,203 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742175_1353, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:31:23,203 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742176_1354, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:31:23,206 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742177_1355, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:31:23,206 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742178_1356, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:31:23,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742179_1357, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:31:23,787 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742180_1358, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:31:23,822 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742181_1359, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:31:23,834 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile7._COPYING_ is closed by DFSClient_NONMAPREDUCE_38270019_1
2019-02-28 19:31:23,838 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742182_1360, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:31:23,846 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742183_1361, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:31:23,850 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742184_1362, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:31:24,023 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:31:24,024 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:31:24,024 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:31:24,024 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742185_1363, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-28 19:31:24,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-28 19:31:24,301 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:31:24,301 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:31:24,301 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:31:24,301 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742186_1364, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:31:24,391 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742187_1365, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:31:24,424 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742188_1366, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:31:24,478 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742189_1367, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:31:24,592 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742190_1368, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:31:24,879 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742191_1369, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:31:24,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742192_1370, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:31:25,207 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742193_1371, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:31:25,244 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742194_1372, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-28 19:31:25,461 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742195_1373, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:31:25,677 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742196_1374, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:31:25,737 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742197_1375, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:31:25,738 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742198_1376, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-02-28 19:31:28,043 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742199_1377, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-28 19:31:28,169 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:31:28,169 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:31:28,169 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:31:28,169 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742200_1378, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-28 19:31:28,826 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742201_1379, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:31:28,983 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-28 19:31:28,983 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:31:28,983 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:31:28,983 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:31:28,983 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742202_1380, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:31:29,585 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:31:29,585 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:31:29,585 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:31:29,586 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742203_1381, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:31:29,617 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:31:29,618 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:31:29,618 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:31:29,618 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742204_1382, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:31:30,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742205_1383, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:31:30,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742206_1384, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:31:32,019 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742207_1385, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:31:32,020 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742208_1386, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:31:32,021 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742209_1387, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:31:32,022 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742210_1388, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile10._COPYING_
2019-02-28 19:31:32,025 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742211_1389, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:31:35,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742212_1390, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:31:35,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742213_1391, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:31:35,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742214_1392, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:31:35,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742215_1393, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:31:35,395 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile18._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1087312429_1
2019-02-28 19:31:35,395 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile15._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1020703841_1
2019-02-28 19:31:35,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742216_1394, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile12._COPYING_
2019-02-28 19:31:35,897 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742217_1395, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:31:36,020 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742218_1396, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:31:36,415 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742219_1397, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:31:36,931 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile10._COPYING_ is closed by DFSClient_NONMAPREDUCE_1258123738_1
2019-02-28 19:31:36,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742220_1398, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile12._COPYING_
2019-02-28 19:31:36,953 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742221_1399, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:31:37,171 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742222_1400, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:31:37,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742223_1401, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-28 19:31:37,342 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742224_1402, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:31:37,475 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742225_1403, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:31:39,907 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile12._COPYING_ is closed by DFSClient_NONMAPREDUCE_1017689801_1
2019-02-28 19:31:39,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742226_1404, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:31:39,908 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile3._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1057097632_1
2019-02-28 19:31:39,909 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742227_1405, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile14._COPYING_
2019-02-28 19:31:40,771 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742228_1406, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile14._COPYING_
2019-02-28 19:31:42,259 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-28 19:31:42,260 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:31:42,260 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:31:42,260 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:31:42,260 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742229_1407, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:31:42,262 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-28 19:31:42,262 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:31:42,262 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:31:42,262 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:31:42,262 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742230_1408, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:31:42,790 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile8._COPYING_ is closed by DFSClient_NONMAPREDUCE_1338165160_1
2019-02-28 19:31:42,805 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:31:42,805 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:31:42,805 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:31:42,805 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742231_1409, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile13._COPYING_
2019-02-28 19:31:46,477 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742232_1410, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:31:46,482 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile14._COPYING_ is closed by DFSClient_NONMAPREDUCE_361490901_1
2019-02-28 19:31:47,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742233_1411, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile13._COPYING_
2019-02-28 19:31:50,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742234_1412, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile13._COPYING_
2019-02-28 19:31:52,661 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742235_1413, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:31:52,858 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742236_1414, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:31:57,825 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742237_1415, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:31:57,826 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742238_1416, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:32:00,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-28 19:32:00,348 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:32:00,348 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:32:00,348 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:32:00,348 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742239_1417, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:32:00,349 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:32:00,349 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:32:00,349 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:32:00,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742240_1418, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:32:00,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-28 19:32:00,778 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:32:00,778 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:32:00,778 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:32:00,778 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742241_1419, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:32:00,818 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile13._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1276206928_1
2019-02-28 19:32:01,324 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:32:01,324 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:32:01,324 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:32:01,325 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742242_1420, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:32:01,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-28 19:32:01,730 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:32:01,730 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:32:01,730 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:32:01,731 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742243_1421, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:32:02,103 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742244_1422, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:32:02,513 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742245_1423, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:32:02,955 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2070978604_1
2019-02-28 19:32:06,816 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742246_1424, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:32:06,999 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742247_1425, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:32:07,163 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742248_1426, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:32:07,193 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742249_1427, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:32:07,306 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742250_1428, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:32:07,346 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742251_1429, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:32:10,522 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 310 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 151 Number of syncs: 158 SyncTimes(ms): 1230 1638 
2019-02-28 19:32:10,594 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742252_1430, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:32:13,613 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742253_1431, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:32:13,672 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742254_1432, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:32:14,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742255_1433, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-28 19:32:14,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742256_1434, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:32:16,842 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742257_1435, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:32:16,930 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742258_1436, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-28 19:32:16,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742259_1437, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:32:17,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742260_1438, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-28 19:32:17,634 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742261_1439, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:32:17,742 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742262_1440, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:32:17,795 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742263_1441, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:32:17,860 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742264_1442, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:32:21,324 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742265_1443, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:32:22,042 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742266_1444, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-28 19:32:22,042 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742267_1445, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:32:24,986 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:32:24,986 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:32:24,986 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:32:24,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742268_1446, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-28 19:32:26,493 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742269_1447, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:32:28,140 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742270_1448, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:32:28,167 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742271_1449, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:32:28,211 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742272_1450, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:32:28,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742273_1451, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:32:32,150 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742274_1452, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:32:34,831 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742275_1453, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:32:34,832 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742276_1454, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:32:34,834 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742277_1455, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:32:36,254 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742278_1456, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:32:42,820 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-61849828_1
2019-02-28 19:32:45,758 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742279_1457, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:32:45,758 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742280_1458, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-28 19:32:45,760 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile19._COPYING_ is closed by DFSClient_NONMAPREDUCE_1468178496_1
2019-02-28 19:32:45,940 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742281_1459, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-28 19:32:46,139 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742282_1460, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:32:46,389 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742283_1461, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:32:46,412 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_-836815689_1
2019-02-28 19:32:46,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742284_1462, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-28 19:32:46,890 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile9._COPYING_ is closed by DFSClient_NONMAPREDUCE_1593356455_1
2019-02-28 19:32:51,840 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742285_1463, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:32:52,124 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742286_1464, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:32:52,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742287_1465, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile17._COPYING_
2019-02-28 19:32:52,435 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742288_1466, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-28 19:32:53,290 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742289_1467, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-28 19:33:01,453 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742290_1468, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile11._COPYING_
2019-02-28 19:33:01,455 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742291_1469, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:33:02,714 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742292_1470, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:33:03,967 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742293_1471, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-28 19:33:04,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742294_1472, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile17._COPYING_
2019-02-28 19:33:04,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742295_1473, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:33:06,414 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742296_1474, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:33:06,414 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742297_1475, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile17._COPYING_
2019-02-28 19:33:09,642 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.10.1.1
2019-02-28 19:33:09,642 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-02-28 19:33:09,642 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1197, 1664
2019-02-28 19:33:09,666 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 469 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 213 Number of syncs: 256 SyncTimes(ms): 1988 2606 
2019-02-28 19:33:09,669 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000001197 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000001197-0000000000000001665
2019-02-28 19:33:09,669 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1666
2019-02-28 19:33:09,988 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742298_1476, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile11._COPYING_
2019-02-28 19:33:11,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742299_1477, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:33:11,599 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-28 19:33:11,599 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:33:11,599 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:33:11,599 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:33:11,599 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742300_1478, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:33:11,824 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742301_1479, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:33:12,597 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742302_1480, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-28 19:33:12,598 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742303_1481, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:33:12,599 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742304_1482, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:33:13,699 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742305_1483, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:33:14,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-28 19:33:14,085 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:33:14,085 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:33:14,085 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:33:14,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742306_1484, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile17._COPYING_
2019-02-28 19:33:14,214 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-28 19:33:14,214 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:33:14,214 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:33:14,214 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:33:14,214 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742307_1485, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:33:14,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-28 19:33:14,456 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:33:14,456 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:33:14,456 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:33:14,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-28 19:33:14,456 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742308_1486, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile11._COPYING_
2019-02-28 19:33:14,456 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:33:14,456 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:33:14,456 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:33:14,456 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742309_1487, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:33:14,598 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:33:14,598 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:33:14,598 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:33:14,598 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742310_1488, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:33:16,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742311_1489, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:33:16,481 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742312_1490, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-28 19:33:16,481 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742313_1491, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile17._COPYING_
2019-02-28 19:33:16,482 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742314_1492, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:33:16,482 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile11._COPYING_ is closed by DFSClient_NONMAPREDUCE_-172817072_1
2019-02-28 19:33:18,728 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile17._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1167943273_1
2019-02-28 19:33:18,730 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742315_1493, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:33:18,777 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742316_1494, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-28 19:33:18,780 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742317_1495, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:33:19,386 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile16._COPYING_ is closed by DFSClient_NONMAPREDUCE_1937140329_1
2019-02-28 19:33:19,391 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742318_1496, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:33:19,432 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742319_1497, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:33:21,042 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742320_1498, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:33:21,043 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742321_1499, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:33:23,788 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742322_1500, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:33:23,788 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742323_1501, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:33:24,553 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742324_1502, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:33:24,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742325_1503, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:33:26,127 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742326_1504, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:33:26,132 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_1899400227_1
2019-02-28 19:33:27,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742327_1505, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-28 19:33:28,847 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile6._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1310758369_1
2019-02-28 19:33:28,880 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742328_1506, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:33:29,510 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742329_1507, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:33:29,912 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742330_1508, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-28 19:33:30,472 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742331_1509, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:33:34,455 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742332_1510, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-28 19:33:34,923 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742333_1511, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:33:37,367 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742334_1512, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:33:47,554 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742335_1513, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:33:50,593 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile20._COPYING_ is closed by DFSClient_NONMAPREDUCE_1212261500_1
2019-02-28 19:34:25,727 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=576282d3-c289-4cff-bddf-e9976e482aef, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-c9a7a7e3-b3ff-47da-a081-2123ff463a5a;nsid=2007392119;c=1551406967379) storage 576282d3-c289-4cff-bddf-e9976e482aef
2019-02-28 19:34:25,727 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.10.1.2:9866
2019-02-28 19:34:25,728 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-28 19:34:25,825 INFO BlockStateChange: BLOCK* processReport 0xf86a860877f28962: Processing first storage report for DS-fd2e57e4-4326-421c-9021-76ec27d8725d from datanode 576282d3-c289-4cff-bddf-e9976e482aef
2019-02-28 19:34:25,825 INFO BlockStateChange: BLOCK* processReport 0xf86a860877f28962: from storage DS-fd2e57e4-4326-421c-9021-76ec27d8725d node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=576282d3-c289-4cff-bddf-e9976e482aef, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-c9a7a7e3-b3ff-47da-a081-2123ff463a5a;nsid=2007392119;c=1551406967379), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-28 19:35:06,670 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 135 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 63 Number of syncs: 71 SyncTimes(ms): 581 480 
2019-02-28 19:35:09,880 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.10.1.1
2019-02-28 19:35:09,880 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-02-28 19:35:09,880 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1666, 1800
2019-02-28 19:35:09,897 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 136 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 63 Number of syncs: 73 SyncTimes(ms): 603 495 
2019-02-28 19:35:09,900 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000001666 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000001666-0000000000000001801
2019-02-28 19:35:09,900 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1802
2019-02-28 19:35:19,419 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742336_1514, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:35:23,023 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742337_1515, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:35:24,331 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742338_1516, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-28 19:35:24,881 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742339_1517, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-28 19:35:25,423 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742340_1518, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:35:25,968 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742341_1519, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:35:26,521 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742342_1520, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:35:29,834 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742343_1521, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-28 19:35:29,890 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742344_1522, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:35:32,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742345_1523, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:35:32,525 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742346_1524, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:35:32,575 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile7._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1034846901_1
2019-02-28 19:35:32,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742347_1525, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:35:33,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742348_1526, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:35:33,099 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742349_1527, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:35:33,262 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742350_1528, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:35:33,460 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742351_1529, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:35:33,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742352_1530, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-28 19:35:33,803 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742353_1531, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:35:33,925 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742354_1532, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:35:34,050 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742355_1533, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-28 19:35:34,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742356_1534, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:35:34,473 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742357_1535, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile10._COPYING_
2019-02-28 19:35:34,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742358_1536, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:35:34,844 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742359_1537, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:35:34,852 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742360_1538, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-02-28 19:35:34,946 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742361_1539, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:35:35,054 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742362_1540, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:35:35,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742363_1541, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-02-28 19:35:35,556 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742364_1542, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:35:35,983 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742365_1543, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:35:39,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742366_1544, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile10._COPYING_
2019-02-28 19:35:39,806 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742367_1545, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:35:40,241 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742368_1546, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:35:40,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742369_1547, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:35:41,633 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742370_1548, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile14._COPYING_
2019-02-28 19:35:42,431 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile3._COPYING_ is closed by DFSClient_NONMAPREDUCE_1015802372_1
2019-02-28 19:35:42,449 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile8._COPYING_ is closed by DFSClient_NONMAPREDUCE_1968095090_1
2019-02-28 19:35:42,477 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742371_1549, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:35:42,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742372_1550, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-28 19:35:44,524 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742373_1551, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:35:44,527 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile10._COPYING_ is closed by DFSClient_NONMAPREDUCE_1987632343_1
2019-02-28 19:35:45,529 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742374_1552, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-28 19:35:45,547 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742375_1553, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:35:46,063 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742376_1554, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile12._COPYING_
2019-02-28 19:35:46,138 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742377_1555, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:35:46,556 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742378_1556, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:35:47,934 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742379_1557, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-28 19:35:49,400 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742380_1558, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile13._COPYING_
2019-02-28 19:35:50,199 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile14._COPYING_ is closed by DFSClient_NONMAPREDUCE_-555004207_1
2019-02-28 19:35:50,311 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742381_1559, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-28 19:35:50,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742382_1560, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:35:50,816 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742383_1561, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:35:50,969 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742384_1562, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile12._COPYING_
2019-02-28 19:35:55,086 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742385_1563, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-28 19:35:56,883 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742386_1564, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:36:03,105 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742387_1565, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:36:05,881 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742388_1566, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-28 19:36:06,333 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742389_1567, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:36:06,347 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742390_1568, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:36:06,763 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742391_1569, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:36:06,790 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742392_1570, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:36:06,794 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742393_1571, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:36:12,380 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 205 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 70 Number of syncs: 134 SyncTimes(ms): 1169 1093 
2019-02-28 19:36:12,436 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742394_1572, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:36:13,338 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742395_1573, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-02-28 19:36:14,133 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile12._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1043195953_1
2019-02-28 19:36:14,769 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742396_1574, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:36:15,536 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742397_1575, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:36:16,860 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742398_1576, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:36:16,865 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742399_1577, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:36:17,835 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742400_1578, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:36:17,836 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile13._COPYING_ is closed by DFSClient_NONMAPREDUCE_1397233214_1
2019-02-28 19:36:18,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742401_1579, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:36:21,547 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742402_1580, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-28 19:36:22,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742403_1581, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile18._COPYING_
2019-02-28 19:36:24,213 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742404_1582, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:36:24,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742405_1583, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-02-28 19:36:24,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742406_1584, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:36:25,208 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742407_1585, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-02-28 19:36:26,822 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742408_1586, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:36:30,143 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742409_1587, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:36:30,145 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742410_1588, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:36:31,549 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742411_1589, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:36:35,805 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742412_1590, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:36:35,805 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742413_1591, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-28 19:36:35,805 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742414_1592, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-28 19:36:35,810 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile15._COPYING_ is closed by DFSClient_NONMAPREDUCE_901272891_1
2019-02-28 19:36:36,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742415_1593, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:36:36,717 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742416_1594, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:36:36,732 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742417_1595, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:36:36,829 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742418_1596, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:36:36,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742419_1597, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:36:36,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742420_1598, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile19._COPYING_
2019-02-28 19:36:37,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742421_1599, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:36:37,376 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742422_1600, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile19._COPYING_
2019-02-28 19:36:37,389 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742423_1601, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:36:37,440 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742424_1602, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:36:37,512 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742425_1603, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:36:40,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742426_1604, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile18._COPYING_
2019-02-28 19:36:40,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742427_1605, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile19._COPYING_
2019-02-28 19:36:42,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742428_1606, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:36:42,463 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742429_1607, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile19._COPYING_
2019-02-28 19:36:42,664 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742430_1608, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:36:42,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742431_1609, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:36:42,666 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742432_1610, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:36:46,385 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742433_1611, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:36:46,716 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742434_1612, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:36:47,254 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_684807945_1
2019-02-28 19:36:47,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742435_1613, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:36:48,140 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742436_1614, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:36:48,140 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742437_1615, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:36:48,143 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile18._COPYING_ is closed by DFSClient_NONMAPREDUCE_1163719418_1
2019-02-28 19:36:49,299 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile9._COPYING_ is closed by DFSClient_NONMAPREDUCE_1414700691_1
2019-02-28 19:36:51,754 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742438_1616, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-28 19:36:54,342 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_871023260_1
2019-02-28 19:37:01,938 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742439_1617, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:37:02,409 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile19._COPYING_ is closed by DFSClient_NONMAPREDUCE_1840343910_1
2019-02-28 19:37:10,090 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.10.1.1
2019-02-28 19:37:10,090 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-02-28 19:37:10,090 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1802, 2168
2019-02-28 19:37:10,104 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 368 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 145 Number of syncs: 223 SyncTimes(ms): 2022 1646 
2019-02-28 19:37:10,107 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000001802 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000001802-0000000000000002169
2019-02-28 19:37:10,107 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2170
2019-02-28 19:37:15,578 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742440_1618, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile11._COPYING_
2019-02-28 19:37:16,099 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742441_1619, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile2._COPYING_
2019-02-28 19:37:16,141 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742442_1620, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:37:16,625 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742443_1621, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:37:16,768 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742444_1622, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile2._COPYING_
2019-02-28 19:37:17,046 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742445_1623, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:37:17,197 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742446_1624, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:37:17,704 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742447_1625, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-28 19:37:17,872 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742448_1626, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-02-28 19:37:22,187 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742449_1627, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:37:22,342 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742450_1628, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:37:26,201 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742451_1629, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-28 19:37:27,314 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742452_1630, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile5._COPYING_
2019-02-28 19:37:28,654 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742453_1631, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-28 19:37:28,655 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742454_1632, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:37:29,392 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742455_1633, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:37:30,423 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742456_1634, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile20._COPYING_
2019-02-28 19:37:32,843 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile11._COPYING_ is closed by DFSClient_NONMAPREDUCE_99260672_1
2019-02-28 19:37:32,843 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742457_1635, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:37:42,434 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742458_1636, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile2._COPYING_
2019-02-28 19:37:42,435 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742459_1637, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:37:42,436 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742460_1638, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:37:42,941 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742461_1639, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:37:45,358 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742462_1640, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:37:45,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742463_1641, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-28 19:37:45,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742464_1642, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:37:45,515 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742465_1643, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:37:45,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742466_1644, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile20._COPYING_
2019-02-28 19:37:45,879 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742467_1645, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:37:45,917 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_1763490773_1
2019-02-28 19:37:46,017 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742468_1646, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:37:47,311 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742469_1647, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile20._COPYING_
2019-02-28 19:37:47,311 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742470_1648, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:37:47,311 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742471_1649, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:37:51,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742472_1650, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:37:51,320 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742473_1651, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:37:51,321 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742474_1652, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-28 19:37:56,616 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742475_1653, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:37:56,616 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742476_1654, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:37:57,219 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742477_1655, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:38:00,247 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742478_1656, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:38:00,276 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_1465378997_1
2019-02-28 19:38:04,795 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742479_1657, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:38:04,797 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile20._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1411520875_1
2019-02-28 19:38:05,192 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile6._COPYING_ is closed by DFSClient_NONMAPREDUCE_-429302014_1
2019-02-28 19:38:21,206 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 153 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 60 Number of syncs: 92 SyncTimes(ms): 768 863 
