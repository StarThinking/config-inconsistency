2019-03-03 21:35:57,506 WARN hdfs.DataStreamer: Exception for BP-1347934262-130.127.133.59-1551674086240:blk_1073741969_1145
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:547)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:213)
	at org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run(DataStreamer.java:1086)
2019-03-03 21:35:57,507 WARN hdfs.DataStreamer: DataStreamer Exception
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.hdfs.DFSPacket.writeTo(DFSPacket.java:194)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:774)
2019-03-03 21:35:57,517 WARN hdfs.DataStreamer: Error Recovery for BP-1347934262-130.127.133.59-1551674086240:blk_1073741969_1145 in pipeline [DatanodeInfoWithStorage[10.10.1.2:9866,DS-7a79aab3-df2b-4f1f-ae5e-838703dd12b3,DISK], DatanodeInfoWithStorage[10.10.1.4:9866,DS-cd40a583-2b03-4996-9a80-26594012b0da,DISK], DatanodeInfoWithStorage[10.10.1.3:9866,DS-502b0fe6-a85e-46dd-8a82-d06037e064dc,DISK]]: datanode 0(DatanodeInfoWithStorage[10.10.1.2:9866,DS-7a79aab3-df2b-4f1f-ae5e-838703dd12b3,DISK]) is bad.
Found 20 items
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:36 /myfile1
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:36 /myfile10
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile11
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile12
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile13
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile14
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile15
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile16
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:36 /myfile17
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:36 /myfile18
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:36 /myfile19
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:36 /myfile2
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:36 /myfile20
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile3
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile4
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:36 /myfile5
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile6
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile7
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:36 /myfile8
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile9
file 18 has been put into HDFS
file 18 has been read from HDFS for 1 time
diff succeed!
file 18 has been read from HDFS for 2 time
diff succeed!
file 18 has been read from HDFS for 3 time
diff succeed!
file 18 has been read from HDFS for 4 time
diff succeed!
file 18 has been read from HDFS for 5 time
diff succeed!
file 18 has been read from HDFS for 6 time
diff succeed!
file 18 has been read from HDFS for 7 time
diff succeed!
file 18 has been read from HDFS for 8 time
diff succeed!
2019-03-03 21:39:23,856 WARN impl.BlockReaderFactory: I/O error constructing remote block reader.
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:547)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:407)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:641)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:572)
	at org.apache.hadoop.hdfs.DFSInputStream.seekToBlockSource(DFSInputStream.java:1484)
	at org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:725)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:763)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:820)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:303)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:285)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:269)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:176)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391)
2019-03-03 21:39:23,865 WARN hdfs.DFSClient: Failed to connect to /10.10.1.2:9866 for block BP-1347934262-130.127.133.59-1551674086240:blk_1073741936_1112, add to deadNodes and continue. 
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:547)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:407)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:853)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:749)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:641)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:572)
	at org.apache.hadoop.hdfs.DFSInputStream.seekToBlockSource(DFSInputStream.java:1484)
	at org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:725)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:763)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:820)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:303)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:285)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:269)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:176)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391)
2019-03-03 21:39:23,870 INFO hdfs.DFSClient: Successfully connected to /10.10.1.4:9866 for BP-1347934262-130.127.133.59-1551674086240:blk_1073741936_1112
file 18 has been read from HDFS for 9 time
diff succeed!
file 18 has been read from HDFS for 10 time
diff succeed!
Deleted /myfile18
file 18 has been removed from HDFS
Found 20 items
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:40 /myfile1
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:36 /myfile10
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:40 /myfile11
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile12
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile13
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile14
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:40 /myfile15
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:39 /myfile16
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:39 /myfile17
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:40 /myfile18
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:40 /myfile19
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:40 /myfile2
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:40 /myfile20
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile3
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:40 /myfile4
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:36 /myfile5
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile6
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:35 /myfile7
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:40 /myfile8
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:39 /myfile9
file 18 has been put into HDFS
file 18 has been read from HDFS for 1 time
diff succeed!
file 18 has been read from HDFS for 2 time
diff succeed!
file 18 has been read from HDFS for 3 time
diff succeed!
file 18 has been read from HDFS for 4 time
diff succeed!
file 18 has been read from HDFS for 5 time
diff succeed!
file 18 has been read from HDFS for 6 time
diff succeed!
file 18 has been read from HDFS for 7 time
diff succeed!
file 18 has been read from HDFS for 8 time
diff succeed!
file 18 has been read from HDFS for 9 time
diff succeed!
file 18 has been read from HDFS for 10 time
diff succeed!
Deleted /myfile18
file 18 has been removed from HDFS
Found 20 items
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:44 /myfile1
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:41 /myfile10
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:44 /myfile11
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:41 /myfile12
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:41 /myfile13
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:40 /myfile14
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:44 /myfile15
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:43 /myfile16
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:44 /myfile17
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:44 /myfile18
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:40 /myfile19
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:40 /myfile2
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:44 /myfile20
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:41 /myfile3
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:44 /myfile4
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:42 /myfile5
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:41 /myfile6
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:42 /myfile7
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:44 /myfile8
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:43 /myfile9
file 18 has been put into HDFS
file 18 has been read from HDFS for 1 time
diff succeed!
file 18 has been read from HDFS for 2 time
diff succeed!
file 18 has been read from HDFS for 3 time
diff succeed!
file 18 has been read from HDFS for 4 time
diff succeed!
2019-03-03 21:46:11,165 WARN impl.BlockReaderFactory: I/O error constructing remote block reader.
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2924)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:641)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:572)
	at org.apache.hadoop.hdfs.DFSInputStream.seekToBlockSource(DFSInputStream.java:1484)
	at org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:725)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:763)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:820)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:303)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:285)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:269)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:176)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391)
2019-03-03 21:46:11,171 WARN hdfs.DFSClient: Failed to connect to /10.10.1.2:9866 for block BP-1347934262-130.127.133.59-1551674086240:blk_1073742220_1407, add to deadNodes and continue. 
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:2924)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:821)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:746)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:379)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:641)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:572)
	at org.apache.hadoop.hdfs.DFSInputStream.seekToBlockSource(DFSInputStream.java:1484)
	at org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:725)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:763)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:820)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129)
	at org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:485)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:407)
	at org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:342)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:277)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:262)
	at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:331)
	at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:303)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:257)
	at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:285)
	at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:269)
	at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:228)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:120)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:176)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:328)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:391)
2019-03-03 21:46:11,174 INFO hdfs.DFSClient: Successfully connected to /10.10.1.5:9866 for BP-1347934262-130.127.133.59-1551674086240:blk_1073742220_1407
file 18 has been read from HDFS for 5 time
diff succeed!
file 18 has been read from HDFS for 6 time
diff succeed!
file 18 has been read from HDFS for 7 time
diff succeed!
file 18 has been read from HDFS for 8 time
diff succeed!
file 18 has been read from HDFS for 9 time
diff succeed!
file 18 has been read from HDFS for 10 time
diff succeed!
Deleted /myfile18
file 18 has been removed from HDFS
Found 17 items
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:48 /myfile1
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:46 /myfile10
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:48 /myfile11
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:45 /myfile12
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:49 /myfile13
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:49 /myfile15
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:48 /myfile16
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:49 /myfile17
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:49 /myfile18
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:45 /myfile19
-rw-r--r--   3 root supergroup  805306368 2019-03-03 21:49 /myfile2._COPYING_
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:49 /myfile20
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:49 /myfile4
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:47 /myfile5
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:47 /myfile7
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:49 /myfile8
-rw-r--r--   3 root supergroup 1073741824 2019-03-03 21:47 /myfile9
file 18 has been put into HDFS
sub_benchmark 1 signal TERM catched and let quit gracefully
file 18 has been read from HDFS for 1 time
diff succeed!
Deleted /myfile18
file 18 has been removed from HDFS
