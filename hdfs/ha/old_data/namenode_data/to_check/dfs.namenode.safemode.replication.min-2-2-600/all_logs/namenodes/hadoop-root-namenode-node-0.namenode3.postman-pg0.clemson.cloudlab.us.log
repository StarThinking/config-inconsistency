2019-02-20 18:08:37,839 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode058.clemson.cloudlab.us/130.127.133.67
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-18T22:18Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-20 18:08:37,848 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 18:08:37,853 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-20 18:08:38,137 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 18:08:38,240 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 18:08:38,240 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-20 18:08:38,291 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-20 18:08:38,291 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-20 18:08:38,454 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 18:08:38,481 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-20 18:08:38,498 INFO org.eclipse.jetty.util.log: Logging initialized @1198ms
2019-02-20 18:08:38,603 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 18:08:38,617 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-20 18:08:38,628 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 18:08:38,631 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-20 18:08:38,631 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 18:08:38,631 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 18:08:38,658 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-20 18:08:38,658 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-20 18:08:38,667 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-20 18:08:38,668 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-20 18:08:38,703 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-20 18:08:38,704 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-20 18:08:38,779 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-20 18:08:38,801 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-20 18:08:38,801 INFO org.eclipse.jetty.server.Server: Started @1503ms
2019-02-20 18:08:39,142 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-20 18:08:39,198 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-20 18:08:39,213 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-20 18:08:39,214 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-20 18:08:39,217 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-20 18:08:39,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-20 18:08:39,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-20 18:08:39,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-20 18:08:39,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-20 18:08:39,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-20 18:08:39,267 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-20 18:08:39,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-20 18:08:39,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-20 18:08:39,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-20 18:08:39,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 20 18:08:39
2019-02-20 18:08:39,286 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-20 18:08:39,286 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:08:39,288 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-20 18:08:39,288 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-20 18:08:39,430 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-20 18:08:39,439 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-20 18:08:39,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-20 18:08:39,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-20 18:08:39,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-20 18:08:39,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-20 18:08:39,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-20 18:08:39,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-20 18:08:39,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-20 18:08:39,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-20 18:08:39,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-20 18:08:39,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-20 18:08:39,522 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-20 18:08:39,522 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:08:39,523 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-20 18:08:39,523 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-20 18:08:39,596 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-20 18:08:39,596 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-20 18:08:39,596 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-20 18:08:39,596 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-20 18:08:39,603 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-20 18:08:39,606 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-20 18:08:39,611 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-20 18:08:39,611 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:08:39,611 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-20 18:08:39,611 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-20 18:08:39,639 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-20 18:08:39,639 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-20 18:08:39,639 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-20 18:08:39,643 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-20 18:08:39,643 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-20 18:08:39,646 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-20 18:08:39,646 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:08:39,646 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-20 18:08:39,646 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-20 18:08:39,697 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 54148@clnode058.clemson.cloudlab.us
2019-02-20 18:08:40,891 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2019-02-20 18:08:40,891 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-20 18:08:40,954 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-20 18:08:40,956 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-20 18:08:40,987 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-20 18:08:40,987 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-20 18:08:40,992 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-20 18:08:40,992 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-20 18:08:40,992 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1338 msecs
2019-02-20 18:08:41,172 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-20 18:08:41,177 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 18:08:41,190 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-20 18:08:41,374 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-20 18:08:41,383 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-20 18:08:41,394 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2019-02-20 18:08:41,394 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2019-02-20 18:08:41,394 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-20 18:08:41,428 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-20 18:08:41,428 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-20 18:08:41,431 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-20 18:08:41,434 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-20 18:08:41,439 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-20 18:08:41,445 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-20 18:08:47,260 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, fileSize: 389. Sent total: 389 bytes. Size of last segment intended to send: -1 bytes.
2019-02-20 18:08:47,426 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-20 18:08:47,428 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode058.clemson.cloudlab.us/130.127.133.67
************************************************************/
2019-02-20 18:08:58,109 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode058.clemson.cloudlab.us/130.127.133.67
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-18T22:18Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-20 18:08:58,119 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 18:08:58,124 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-20 18:08:58,412 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 18:08:58,518 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 18:08:58,519 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-20 18:08:58,570 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-20 18:08:58,571 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-20 18:08:58,733 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 18:08:58,761 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-20 18:08:58,778 INFO org.eclipse.jetty.util.log: Logging initialized @1201ms
2019-02-20 18:08:58,885 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 18:08:58,899 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-20 18:08:58,909 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 18:08:58,912 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-20 18:08:58,913 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 18:08:58,913 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 18:08:58,939 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-20 18:08:58,939 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-20 18:08:58,948 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-20 18:08:58,949 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-20 18:08:58,985 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-20 18:08:58,986 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-20 18:08:59,061 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-20 18:08:59,081 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@76fc6a34{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-20 18:08:59,081 INFO org.eclipse.jetty.server.Server: Started @1506ms
2019-02-20 18:08:59,434 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-20 18:08:59,491 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-20 18:08:59,506 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-20 18:08:59,507 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-20 18:08:59,510 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-20 18:08:59,516 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-20 18:08:59,517 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-20 18:08:59,517 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-20 18:08:59,517 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-20 18:08:59,517 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-20 18:08:59,560 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-20 18:08:59,572 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-20 18:08:59,572 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-20 18:08:59,577 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-20 18:08:59,577 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 20 18:08:59
2019-02-20 18:08:59,579 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-20 18:08:59,580 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:08:59,581 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-20 18:08:59,581 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-20 18:08:59,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-20 18:08:59,727 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-20 18:08:59,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-20 18:08:59,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-20 18:08:59,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-20 18:08:59,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-20 18:08:59,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-20 18:08:59,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-20 18:08:59,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-20 18:08:59,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-20 18:08:59,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-20 18:08:59,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-20 18:08:59,813 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-20 18:08:59,813 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:08:59,814 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-20 18:08:59,814 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-20 18:08:59,887 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-20 18:08:59,888 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-20 18:08:59,888 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-20 18:08:59,888 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-20 18:08:59,895 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-20 18:08:59,898 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-20 18:08:59,903 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-20 18:08:59,903 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:08:59,903 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-20 18:08:59,903 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-20 18:08:59,931 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-20 18:08:59,931 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-20 18:08:59,931 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-20 18:08:59,936 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-20 18:08:59,936 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-20 18:08:59,938 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-20 18:08:59,938 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:08:59,938 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-20 18:08:59,939 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-20 18:08:59,994 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 54837@clnode058.clemson.cloudlab.us
2019-02-20 18:09:02,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:02,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:02,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:03,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:03,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:03,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:04,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:04,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:04,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:05,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:05,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:05,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:06,098 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-02-20 18:09:06,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:06,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:06,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:09:06,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2019-02-20 18:09:06,799 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-20 18:09:06,860 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-20 18:09:06,862 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-20 18:09:06,893 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-20 18:09:06,893 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-20 18:09:06,898 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-20 18:09:06,899 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-20 18:09:06,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 6952 msecs
2019-02-20 18:09:07,080 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-20 18:09:07,084 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 18:09:07,097 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-20 18:09:07,287 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-20 18:09:07,296 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-20 18:09:07,307 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2019-02-20 18:09:07,307 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2019-02-20 18:09:07,307 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-20 18:09:07,341 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-20 18:09:07,341 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-20 18:09:07,344 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-20 18:09:07,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-20 18:09:07,352 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-20 18:09:07,358 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-20 18:09:07,850 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=e0817042-f3cb-4b7c-a859-901603b299c7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage e0817042-f3cb-4b7c-a859-901603b299c7
2019-02-20 18:09:07,852 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-20 18:09:07,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e0817042-f3cb-4b7c-a859-901603b299c7 (10.10.1.2:9866).
2019-02-20 18:09:07,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-fb7779e9-8d96-4814-84e7-0856c705fa09 for DN 10.10.1.2:9866
2019-02-20 18:09:08,462 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=0aafc93e-1b02-4c5b-9540-0075464bc9a8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage 0aafc93e-1b02-4c5b-9540-0075464bc9a8
2019-02-20 18:09:08,462 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-20 18:09:08,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 0aafc93e-1b02-4c5b-9540-0075464bc9a8 (10.10.1.5:9866).
2019-02-20 18:09:08,464 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=29984e1f-b62e-4d76-94cb-b87f59987a8a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage 29984e1f-b62e-4d76-94cb-b87f59987a8a
2019-02-20 18:09:08,465 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-20 18:09:08,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 29984e1f-b62e-4d76-94cb-b87f59987a8a (10.10.1.3:9866).
2019-02-20 18:09:08,467 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-55cb0859-d395-4226-b6fa-d0b50b678f15 for DN 10.10.1.5:9866
2019-02-20 18:09:08,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f for DN 10.10.1.3:9866
2019-02-20 18:09:08,488 INFO BlockStateChange: BLOCK* processReport 0x935aa37154201618: Processing first storage report for DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f from datanode 29984e1f-b62e-4d76-94cb-b87f59987a8a
2019-02-20 18:09:08,490 INFO BlockStateChange: BLOCK* processReport 0x935aa37154201618: from storage DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=29984e1f-b62e-4d76-94cb-b87f59987a8a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-02-20 18:09:08,490 INFO BlockStateChange: BLOCK* processReport 0x189a033de397df14: Processing first storage report for DS-fb7779e9-8d96-4814-84e7-0856c705fa09 from datanode e0817042-f3cb-4b7c-a859-901603b299c7
2019-02-20 18:09:08,490 INFO BlockStateChange: BLOCK* processReport 0x189a033de397df14: from storage DS-fb7779e9-8d96-4814-84e7-0856c705fa09 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=e0817042-f3cb-4b7c-a859-901603b299c7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-20 18:09:08,490 INFO BlockStateChange: BLOCK* processReport 0xe952d94c8958ee5e: Processing first storage report for DS-55cb0859-d395-4226-b6fa-d0b50b678f15 from datanode 0aafc93e-1b02-4c5b-9540-0075464bc9a8
2019-02-20 18:09:08,490 INFO BlockStateChange: BLOCK* processReport 0xe952d94c8958ee5e: from storage DS-55cb0859-d395-4226-b6fa-d0b50b678f15 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=0aafc93e-1b02-4c5b-9540-0075464bc9a8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-20 18:10:15,955 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-02-20 18:10:15,957 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-02-20 18:10:16,060 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-20 18:10:16,068 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-02-20 18:10:16,153 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 2
2019-02-20 18:10:16,153 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 1
2019-02-20 18:10:16,187 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.3:8485: segmentState { startTxId: 1 endTxId: 541 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 540
10.10.1.2:8485: segmentState { startTxId: 1 endTxId: 541 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 540
2019-02-20 18:10:16,190 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.3:8485=segmentState {
  startTxId: 1
  endTxId: 541
  isInProgress: true
}
lastWriterEpoch: 1
lastCommittedTxId: 540

2019-02-20 18:10:16,266 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-02-20 18:10:16,267 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-02-20 18:10:16,282 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4d6073b8 expecting start txid #1
2019-02-20 18:10:16,282 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:10:16,285 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:10:16,285 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:10:16,509 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-02-20 18:10:16,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-02-20 18:10:16,510 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-02-20 18:10:16,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-20 18:10:16,510 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 542
2019-02-20 18:10:16,513 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 542
2019-02-20 18:10:16,755 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 55 
2019-02-20 18:10:16,780 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-20 18:10:16,784 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=21
storage space=64424509440
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-02-20 18:10:16,789 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-20 18:10:16,852 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 160
2019-02-20 18:10:16,852 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-20 18:10:16,852 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-20 18:10:16,852 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-20 18:10:16,852 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-02-20 18:10:16,852 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 342 msec
2019-02-20 18:10:50,170 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-20 18:10:50,172 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode058.clemson.cloudlab.us/130.127.133.67
************************************************************/
2019-02-20 18:11:07,207 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode058.clemson.cloudlab.us/130.127.133.67
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-18T22:18Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-20 18:11:07,217 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 18:11:07,222 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-20 18:11:07,510 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 18:11:07,615 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 18:11:07,615 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-20 18:11:07,666 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-20 18:11:07,666 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-20 18:11:07,828 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 18:11:07,855 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-20 18:11:07,872 INFO org.eclipse.jetty.util.log: Logging initialized @1178ms
2019-02-20 18:11:07,981 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 18:11:07,995 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-20 18:11:08,006 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 18:11:08,009 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-20 18:11:08,009 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 18:11:08,009 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 18:11:08,039 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-20 18:11:08,040 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-20 18:11:08,049 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-20 18:11:08,050 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-20 18:11:08,085 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-20 18:11:08,086 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-20 18:11:08,160 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-20 18:11:08,181 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-20 18:11:08,181 INFO org.eclipse.jetty.server.Server: Started @1489ms
2019-02-20 18:11:08,525 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-20 18:11:08,576 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-20 18:11:08,590 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-20 18:11:08,591 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-20 18:11:08,594 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-20 18:11:08,601 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-20 18:11:08,601 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-20 18:11:08,601 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-20 18:11:08,601 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-20 18:11:08,601 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-20 18:11:08,644 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-20 18:11:08,656 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-20 18:11:08,656 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-20 18:11:08,661 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-20 18:11:08,661 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 20 18:11:08
2019-02-20 18:11:08,663 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-20 18:11:08,664 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:11:08,665 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-20 18:11:08,665 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-20 18:11:08,808 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-20 18:11:08,818 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-20 18:11:08,818 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-20 18:11:08,818 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-20 18:11:08,818 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-20 18:11:08,818 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-20 18:11:08,818 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-20 18:11:08,818 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-20 18:11:08,818 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-20 18:11:08,818 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-20 18:11:08,819 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-20 18:11:08,819 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-20 18:11:08,902 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-20 18:11:08,903 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:11:08,903 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-20 18:11:08,903 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-20 18:11:08,976 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-20 18:11:08,976 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-20 18:11:08,976 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-20 18:11:08,976 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-20 18:11:08,983 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-20 18:11:08,986 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-20 18:11:08,991 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-20 18:11:08,991 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:11:08,992 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-20 18:11:08,992 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-20 18:11:09,019 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-20 18:11:09,019 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-20 18:11:09,019 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-20 18:11:09,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-20 18:11:09,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-20 18:11:09,026 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-20 18:11:09,026 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:11:09,026 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-20 18:11:09,026 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-20 18:11:09,091 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 56220@clnode058.clemson.cloudlab.us
2019-02-20 18:11:10,333 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-20 18:11:10,396 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-20 18:11:10,398 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-20 18:11:10,429 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-20 18:11:10,429 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-20 18:11:10,434 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-02-20 18:11:10,434 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:11:10,438 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:11:10,438 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:11:10,557 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-02-20 18:11:10,557 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #542
2019-02-20 18:11:10,557 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:11:10,557 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:11:10,557 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:11:10,564 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-20 18:11:10,564 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-20 18:11:10,565 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-20 18:11:10,565 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1531 msecs
2019-02-20 18:11:10,750 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-20 18:11:10,755 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 18:11:10,767 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-20 18:11:10,955 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-20 18:11:10,965 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-20 18:11:10,976 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 159 blocks to reach the threshold 0.9990 of total blocks 160.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-02-20 18:11:11,006 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-20 18:11:11,007 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-20 18:11:11,009 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-20 18:11:11,011 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-20 18:11:11,018 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-20 18:11:11,024 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-20 18:11:11,657 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=29984e1f-b62e-4d76-94cb-b87f59987a8a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage 29984e1f-b62e-4d76-94cb-b87f59987a8a
2019-02-20 18:11:11,658 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-20 18:11:11,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 29984e1f-b62e-4d76-94cb-b87f59987a8a (10.10.1.3:9866).
2019-02-20 18:11:11,659 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=e0817042-f3cb-4b7c-a859-901603b299c7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage e0817042-f3cb-4b7c-a859-901603b299c7
2019-02-20 18:11:11,660 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-20 18:11:11,660 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e0817042-f3cb-4b7c-a859-901603b299c7 (10.10.1.2:9866).
2019-02-20 18:11:11,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=0aafc93e-1b02-4c5b-9540-0075464bc9a8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage 0aafc93e-1b02-4c5b-9540-0075464bc9a8
2019-02-20 18:11:11,660 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-20 18:11:11,660 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 0aafc93e-1b02-4c5b-9540-0075464bc9a8 (10.10.1.5:9866).
2019-02-20 18:11:11,671 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-fb7779e9-8d96-4814-84e7-0856c705fa09 for DN 10.10.1.2:9866
2019-02-20 18:11:11,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-55cb0859-d395-4226-b6fa-d0b50b678f15 for DN 10.10.1.5:9866
2019-02-20 18:11:11,674 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f for DN 10.10.1.3:9866
2019-02-20 18:11:11,688 INFO BlockStateChange: BLOCK* processReport 0x189a033de397df15: Processing first storage report for DS-fb7779e9-8d96-4814-84e7-0856c705fa09 from datanode e0817042-f3cb-4b7c-a859-901603b299c7
2019-02-20 18:11:11,698 INFO BlockStateChange: BLOCK* processReport 0x189a033de397df15: from storage DS-fb7779e9-8d96-4814-84e7-0856c705fa09 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=e0817042-f3cb-4b7c-a859-901603b299c7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 160, hasStaleStorage: false, processing time: 9 msecs, invalidatedBlocks: 0
2019-02-20 18:11:11,698 INFO BlockStateChange: BLOCK* processReport 0xe952d94c8958ee5f: Processing first storage report for DS-55cb0859-d395-4226-b6fa-d0b50b678f15 from datanode 0aafc93e-1b02-4c5b-9540-0075464bc9a8
2019-02-20 18:11:11,703 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 159 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 30 seconds.
2019-02-20 18:11:11,703 INFO BlockStateChange: BLOCK* processReport 0xe952d94c8958ee5f: from storage DS-55cb0859-d395-4226-b6fa-d0b50b678f15 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=0aafc93e-1b02-4c5b-9540-0075464bc9a8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 160, hasStaleStorage: false, processing time: 5 msecs, invalidatedBlocks: 0
2019-02-20 18:11:11,704 INFO BlockStateChange: BLOCK* processReport 0x935aa37154201619: Processing first storage report for DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f from datanode 29984e1f-b62e-4d76-94cb-b87f59987a8a
2019-02-20 18:11:11,707 INFO BlockStateChange: BLOCK* processReport 0x935aa37154201619: from storage DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=29984e1f-b62e-4d76-94cb-b87f59987a8a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 160, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2019-02-20 18:11:31,706 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 160 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-02-20 18:11:41,707 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2019-02-20 18:11:41,707 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 30 secs
2019-02-20 18:11:41,708 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2019-02-20 18:11:41,708 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-20 18:13:11,034 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:13:11,283 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5b70aa0f expecting start txid #543
2019-02-20 18:13:11,283 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:13:11,284 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 543
2019-02-20 18:13:11,284 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 543
2019-02-20 18:13:11,296 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 215 edits # 5 loaded in 0 seconds
2019-02-20 18:15:11,303 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:15:11,493 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7a18d4a5 expecting start txid #548
2019-02-20 18:15:11,493 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:15:11,493 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 548
2019-02-20 18:15:11,493 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 548
2019-02-20 18:15:11,545 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 30929 edits # 557 loaded in 0 seconds
2019-02-20 18:17:11,553 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:17:11,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@722a87a1 expecting start txid #1105
2019-02-20 18:17:11,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:17:11,752 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1105
2019-02-20 18:17:11,752 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1105
2019-02-20 18:17:11,757 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 519 edits # 6 loaded in 0 seconds
2019-02-20 18:19:11,764 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:19:11,958 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@403fe03 expecting start txid #1111
2019-02-20 18:19:11,958 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:19:11,958 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1111
2019-02-20 18:19:11,958 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1111
2019-02-20 18:19:11,988 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 25050 edits # 458 loaded in 0 seconds
2019-02-20 18:21:11,995 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:21:12,182 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@74ed92f expecting start txid #1569
2019-02-20 18:21:12,182 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:21:12,182 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1569
2019-02-20 18:21:12,182 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1569
2019-02-20 18:21:12,193 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 8020 edits # 134 loaded in 0 seconds
2019-02-20 18:21:19,405 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-02-20 18:21:19,406 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-02-20 18:21:19,409 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-20 18:21:19,416 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-02-20 18:21:19,455 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 4
2019-02-20 18:21:19,455 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 1703
2019-02-20 18:21:19,477 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.2:8485: segmentState { startTxId: 1703 endTxId: 1703 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 1702
10.10.1.3:8485: segmentState { startTxId: 1703 endTxId: 1703 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 1702
2019-02-20 18:21:19,478 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.2:8485=segmentState {
  startTxId: 1703
  endTxId: 1703
  isInProgress: true
}
lastWriterEpoch: 3
lastCommittedTxId: 1702

2019-02-20 18:21:19,517 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-02-20 18:21:19,546 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000542 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000542-0000000000000000542
2019-02-20 18:21:19,562 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-02-20 18:21:19,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@34192bd1 expecting start txid #1703
2019-02-20 18:21:19,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:21:19,566 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1703
2019-02-20 18:21:19,566 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1703
2019-02-20 18:21:19,573 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-20 18:21:19,573 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-02-20 18:21:19,574 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-02-20 18:21:19,574 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-20 18:21:19,574 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 1704
2019-02-20 18:21:19,576 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1704
2019-02-20 18:21:19,843 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 62 
2019-02-20 18:21:19,869 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-20 18:21:19,872 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 3 milliseconds
name space=19
storage space=57982058496
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-02-20 18:21:19,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-20 18:21:19,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 144
2019-02-20 18:21:19,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-20 18:21:19,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-20 18:21:19,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-20 18:21:19,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-02-20 18:21:19,941 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 367 msec
2019-02-20 18:21:22,464 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742313_1489, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-20 18:21:23,849 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742314_1490, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-20 18:21:24,374 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742315_1491, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-20 18:21:24,398 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742316_1492, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-20 18:21:24,789 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742317_1493, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-20 18:21:24,835 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742318_1494, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-20 18:21:25,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742319_1495, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-20 18:21:25,281 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742320_1496, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-20 18:21:25,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742321_1497, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-20 18:21:25,705 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742322_1498, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-20 18:21:25,993 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742323_1499, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-20 18:21:26,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742324_1500, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-20 18:21:26,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742325_1501, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-20 18:21:26,522 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742326_1502, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-20 18:21:26,839 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742327_1503, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-20 18:21:27,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742328_1504, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-20 18:21:27,299 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile6._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1851627024_1
2019-02-20 18:21:27,459 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile7._COPYING_ is closed by DFSClient_NONMAPREDUCE_944968760_1
2019-02-20 18:21:35,153 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742329_1505, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-20 18:21:37,409 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742330_1506, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-20 18:21:38,006 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742331_1507, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-20 18:21:43,802 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742332_1508, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-20 18:21:45,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742333_1509, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-20 18:21:46,513 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742334_1510, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-20 18:21:47,041 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742335_1511, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-20 18:21:47,534 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742336_1512, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-20 18:21:48,054 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-372597655_1
2019-02-20 18:21:54,194 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-20 18:21:54,196 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode058.clemson.cloudlab.us/130.127.133.67
************************************************************/
2019-02-20 18:22:11,230 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode058.clemson.cloudlab.us/130.127.133.67
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-18T22:18Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-20 18:22:11,240 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 18:22:11,245 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-20 18:22:11,534 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 18:22:11,641 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 18:22:11,641 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-20 18:22:11,691 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-20 18:22:11,692 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-20 18:22:11,852 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 18:22:11,880 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-20 18:22:11,898 INFO org.eclipse.jetty.util.log: Logging initialized @1178ms
2019-02-20 18:22:12,005 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 18:22:12,019 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-20 18:22:12,030 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 18:22:12,033 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-20 18:22:12,033 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 18:22:12,033 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 18:22:12,059 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-20 18:22:12,060 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-20 18:22:12,069 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-20 18:22:12,070 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-20 18:22:12,106 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-20 18:22:12,107 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-20 18:22:12,182 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-20 18:22:12,209 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-20 18:22:12,210 INFO org.eclipse.jetty.server.Server: Started @1492ms
2019-02-20 18:22:12,545 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-20 18:22:12,603 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-20 18:22:12,618 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-20 18:22:12,619 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-20 18:22:12,622 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-20 18:22:12,628 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-20 18:22:12,628 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-20 18:22:12,628 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-20 18:22:12,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-20 18:22:12,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-20 18:22:12,672 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-20 18:22:12,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-20 18:22:12,684 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-20 18:22:12,689 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-20 18:22:12,689 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 20 18:22:12
2019-02-20 18:22:12,691 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-20 18:22:12,691 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:22:12,693 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-20 18:22:12,693 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-20 18:22:12,833 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-20 18:22:12,843 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-20 18:22:12,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-20 18:22:12,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-20 18:22:12,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-20 18:22:12,844 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-20 18:22:12,844 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-20 18:22:12,844 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-20 18:22:12,844 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-20 18:22:12,844 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-20 18:22:12,844 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-20 18:22:12,844 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-20 18:22:12,928 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-20 18:22:12,928 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:22:12,928 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-20 18:22:12,928 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-20 18:22:13,002 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-20 18:22:13,002 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-20 18:22:13,002 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-20 18:22:13,002 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-20 18:22:13,009 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-20 18:22:13,012 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-20 18:22:13,017 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-20 18:22:13,017 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:22:13,017 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-20 18:22:13,017 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-20 18:22:13,045 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-20 18:22:13,045 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-20 18:22:13,045 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-20 18:22:13,049 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-20 18:22:13,050 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-20 18:22:13,052 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-20 18:22:13,052 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:22:13,052 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-20 18:22:13,052 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-20 18:22:13,129 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 57249@clnode058.clemson.cloudlab.us
2019-02-20 18:22:14,544 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1187ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=326ms
GC pool 'PS Scavenge' had collection(s): count=1 time=959ms
2019-02-20 18:22:14,712 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-20 18:22:14,776 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-20 18:22:14,778 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-20 18:22:14,809 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-20 18:22:14,809 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-20 18:22:14,814 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-02-20 18:22:14,814 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:22:14,818 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:14,818 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:14,937 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-02-20 18:22:14,937 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #542
2019-02-20 18:22:14,937 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:22:14,937 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:14,937 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:14,941 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-20 18:22:14,942 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a7288a3 expecting start txid #543
2019-02-20 18:22:14,942 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:22:14,942 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:14,942 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:14,954 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 215 edits # 5 loaded in 0 seconds
2019-02-20 18:22:14,954 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2974f221 expecting start txid #548
2019-02-20 18:22:14,954 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:22:14,954 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:14,954 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:14,990 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 30929 edits # 557 loaded in 0 seconds
2019-02-20 18:22:14,991 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@58fe0499 expecting start txid #1105
2019-02-20 18:22:14,991 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:22:14,991 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:14,991 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:14,993 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 519 edits # 6 loaded in 0 seconds
2019-02-20 18:22:14,993 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@686449f9 expecting start txid #1111
2019-02-20 18:22:14,993 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:22:14,993 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:14,993 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:15,017 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 25050 edits # 458 loaded in 0 seconds
2019-02-20 18:22:15,017 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@665df3c6 expecting start txid #1569
2019-02-20 18:22:15,017 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:22:15,017 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:15,017 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:15,024 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 8020 edits # 134 loaded in 0 seconds
2019-02-20 18:22:15,025 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68b6f0d6 expecting start txid #1703
2019-02-20 18:22:15,025 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:22:15,025 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:15,025 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:15,031 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-20 18:22:15,031 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4044fb95 expecting start txid #1704
2019-02-20 18:22:15,031 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:22:15,032 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:15,032 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:22:15,039 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 84 loaded in 0 seconds
2019-02-20 18:22:15,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-20 18:22:15,039 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-20 18:22:15,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1979 msecs
2019-02-20 18:22:15,221 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-20 18:22:15,226 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 18:22:15,239 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-20 18:22:15,431 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-20 18:22:15,441 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-20 18:22:15,453 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 151 blocks to reach the threshold 0.9990 of total blocks 152.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-02-20 18:22:15,483 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-20 18:22:15,484 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-20 18:22:15,486 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-20 18:22:15,489 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-20 18:22:15,495 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-20 18:22:15,501 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-20 18:22:15,819 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=e0817042-f3cb-4b7c-a859-901603b299c7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage e0817042-f3cb-4b7c-a859-901603b299c7
2019-02-20 18:22:15,820 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-20 18:22:15,821 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e0817042-f3cb-4b7c-a859-901603b299c7 (10.10.1.2:9866).
2019-02-20 18:22:15,822 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=0aafc93e-1b02-4c5b-9540-0075464bc9a8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage 0aafc93e-1b02-4c5b-9540-0075464bc9a8
2019-02-20 18:22:15,822 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-20 18:22:15,823 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 0aafc93e-1b02-4c5b-9540-0075464bc9a8 (10.10.1.5:9866).
2019-02-20 18:22:15,823 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=29984e1f-b62e-4d76-94cb-b87f59987a8a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage 29984e1f-b62e-4d76-94cb-b87f59987a8a
2019-02-20 18:22:15,823 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-20 18:22:15,823 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 29984e1f-b62e-4d76-94cb-b87f59987a8a (10.10.1.3:9866).
2019-02-20 18:22:15,833 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-fb7779e9-8d96-4814-84e7-0856c705fa09 for DN 10.10.1.2:9866
2019-02-20 18:22:15,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f for DN 10.10.1.3:9866
2019-02-20 18:22:15,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-55cb0859-d395-4226-b6fa-d0b50b678f15 for DN 10.10.1.5:9866
2019-02-20 18:22:15,851 INFO BlockStateChange: BLOCK* processReport 0xe952d94c8958ee60: Processing first storage report for DS-55cb0859-d395-4226-b6fa-d0b50b678f15 from datanode 0aafc93e-1b02-4c5b-9540-0075464bc9a8
2019-02-20 18:22:15,863 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 151 has reached the threshold 0.9990 of total blocks 152. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2019-02-20 18:22:15,863 INFO BlockStateChange: BLOCK* processReport 0xe952d94c8958ee60: from storage DS-55cb0859-d395-4226-b6fa-d0b50b678f15 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=0aafc93e-1b02-4c5b-9540-0075464bc9a8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 168, hasStaleStorage: false, processing time: 12 msecs, invalidatedBlocks: 0
2019-02-20 18:22:15,863 INFO BlockStateChange: BLOCK* processReport 0x935aa3715420161a: Processing first storage report for DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f from datanode 29984e1f-b62e-4d76-94cb-b87f59987a8a
2019-02-20 18:22:15,867 INFO BlockStateChange: BLOCK* processReport 0x935aa3715420161a: from storage DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=29984e1f-b62e-4d76-94cb-b87f59987a8a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 160, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2019-02-20 18:22:15,867 INFO BlockStateChange: BLOCK* processReport 0x189a033de397df16: Processing first storage report for DS-fb7779e9-8d96-4814-84e7-0856c705fa09 from datanode e0817042-f3cb-4b7c-a859-901603b299c7
2019-02-20 18:22:15,869 INFO BlockStateChange: BLOCK* processReport 0x189a033de397df16: from storage DS-fb7779e9-8d96-4814-84e7-0856c705fa09 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=e0817042-f3cb-4b7c-a859-901603b299c7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 152, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-02-20 18:22:35,865 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 152 has reached the threshold 0.9990 of total blocks 152. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-02-20 18:22:45,866 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2019-02-20 18:22:45,866 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 30 secs
2019-02-20 18:22:45,866 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2019-02-20 18:22:45,866 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-20 18:24:15,516 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:24:16,338 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7c4fd511 expecting start txid #1788
2019-02-20 18:24:16,338 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:24:16,339 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1788
2019-02-20 18:24:16,339 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1788
2019-02-20 18:24:16,367 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 16494 edits # 296 loaded in 0 seconds
2019-02-20 18:26:16,375 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:26:16,576 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a219042 expecting start txid #2084
2019-02-20 18:26:16,577 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:26:16,577 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 2084
2019-02-20 18:26:16,577 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 2084
2019-02-20 18:26:16,594 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 14653 edits # 266 loaded in 0 seconds
2019-02-20 18:28:16,603 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:28:16,792 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@56391bfc expecting start txid #2350
2019-02-20 18:28:16,792 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:28:16,793 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 2350
2019-02-20 18:28:16,793 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 2350
2019-02-20 18:28:16,814 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 18175 edits # 320 loaded in 0 seconds
2019-02-20 18:30:16,821 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:30:17,023 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@62e2d33e expecting start txid #2670
2019-02-20 18:30:17,023 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:30:17,023 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 2670
2019-02-20 18:30:17,023 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 2670
2019-02-20 18:30:17,037 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 13747 edits # 247 loaded in 0 seconds
2019-02-20 18:32:17,045 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:32:17,238 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@e0a5658 expecting start txid #2917
2019-02-20 18:32:17,238 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:32:17,239 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 2917
2019-02-20 18:32:17,239 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 2917
2019-02-20 18:32:17,256 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 18073 edits # 325 loaded in 0 seconds
2019-02-20 18:32:23,247 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-02-20 18:32:23,248 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-02-20 18:32:23,250 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-20 18:32:23,259 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-02-20 18:32:23,295 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 6
2019-02-20 18:32:23,295 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 3242
2019-02-20 18:32:23,315 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.5:8485: segmentState { startTxId: 3242 endTxId: 3248 isInProgress: true } lastWriterEpoch: 5 lastCommittedTxId: 3247
10.10.1.2:8485: segmentState { startTxId: 3242 endTxId: 3248 isInProgress: true } lastWriterEpoch: 5 lastCommittedTxId: 3247
10.10.1.3:8485: segmentState { startTxId: 3242 endTxId: 3248 isInProgress: true } lastWriterEpoch: 5 lastCommittedTxId: 3247
2019-02-20 18:32:23,317 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.5:8485=segmentState {
  startTxId: 3242
  endTxId: 3248
  isInProgress: true
}
lastWriterEpoch: 5
lastCommittedTxId: 3247

2019-02-20 18:32:23,350 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-02-20 18:32:23,369 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000001704 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000001704-0000000000000001787
2019-02-20 18:32:23,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-02-20 18:32:23,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@537e7016 expecting start txid #3242
2019-02-20 18:32:23,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:32:23,390 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 3242
2019-02-20 18:32:23,390 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 3242
2019-02-20 18:32:23,397 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 7 loaded in 0 seconds
2019-02-20 18:32:23,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-02-20 18:32:23,398 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-02-20 18:32:23,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-20 18:32:23,398 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 3249
2019-02-20 18:32:23,400 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3249
2019-02-20 18:32:23,654 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 61 
2019-02-20 18:32:23,679 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-20 18:32:23,682 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 3 milliseconds
name space=21
storage space=64021856256
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-02-20 18:32:23,688 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-20 18:32:23,753 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 159
2019-02-20 18:32:23,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-20 18:32:23,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-20 18:32:23,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-20 18:32:23,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 1
2019-02-20 18:32:23,754 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 356 msec
2019-02-20 18:32:25,589 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742752_1928, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-20 18:32:27,846 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile15._COPYING_ is closed by DFSClient_NONMAPREDUCE_-384538385_1
2019-02-20 18:32:50,038 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742753_1929, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-20 18:32:52,659 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742754_1930, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-20 18:32:54,806 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742755_1931, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-20 18:32:55,188 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742756_1932, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-20 18:32:58,199 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-20 18:32:58,201 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode058.clemson.cloudlab.us/130.127.133.67
************************************************************/
2019-02-20 18:33:15,245 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode058.clemson.cloudlab.us/130.127.133.67
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-18T22:18Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-20 18:33:15,255 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 18:33:15,260 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-20 18:33:15,547 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 18:33:15,652 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 18:33:15,653 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-20 18:33:15,704 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-20 18:33:15,705 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-20 18:33:15,872 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 18:33:15,900 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-20 18:33:15,917 INFO org.eclipse.jetty.util.log: Logging initialized @1189ms
2019-02-20 18:33:16,023 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 18:33:16,037 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-20 18:33:16,048 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 18:33:16,050 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-20 18:33:16,051 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 18:33:16,051 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 18:33:16,077 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-20 18:33:16,077 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-20 18:33:16,086 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-20 18:33:16,088 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-20 18:33:16,123 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-20 18:33:16,124 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-20 18:33:16,199 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-20 18:33:16,217 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-20 18:33:16,218 INFO org.eclipse.jetty.server.Server: Started @1491ms
2019-02-20 18:33:16,595 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-20 18:33:16,652 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-20 18:33:16,667 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-20 18:33:16,668 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-20 18:33:16,671 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-20 18:33:16,677 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-20 18:33:16,677 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-20 18:33:16,677 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-20 18:33:16,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-20 18:33:16,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-20 18:33:16,720 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-20 18:33:16,732 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-20 18:33:16,733 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-20 18:33:16,737 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-20 18:33:16,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 20 18:33:16
2019-02-20 18:33:16,740 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-20 18:33:16,740 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:33:16,741 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-20 18:33:16,741 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-20 18:33:16,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-20 18:33:16,886 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-20 18:33:16,886 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-20 18:33:16,886 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-20 18:33:16,886 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-20 18:33:16,886 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-20 18:33:16,886 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-20 18:33:16,886 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-20 18:33:16,886 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-20 18:33:16,886 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-20 18:33:16,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-20 18:33:16,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-20 18:33:16,970 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-20 18:33:16,970 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:33:16,970 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-20 18:33:16,970 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-20 18:33:17,043 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-20 18:33:17,043 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-20 18:33:17,043 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-20 18:33:17,043 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-20 18:33:17,050 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-20 18:33:17,053 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-20 18:33:17,058 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-20 18:33:17,058 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:33:17,058 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-20 18:33:17,059 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-20 18:33:17,086 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-20 18:33:17,086 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-20 18:33:17,086 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-20 18:33:17,090 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-20 18:33:17,091 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-20 18:33:17,093 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-20 18:33:17,093 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:33:17,093 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-20 18:33:17,093 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-20 18:33:17,173 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 58251@clnode058.clemson.cloudlab.us
2019-02-20 18:33:18,742 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1366ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=371ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1073ms
2019-02-20 18:33:18,919 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-20 18:33:18,981 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-20 18:33:18,984 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-20 18:33:19,014 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-20 18:33:19,015 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-20 18:33:19,020 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-02-20 18:33:19,020 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,024 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,024 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,142 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-02-20 18:33:19,142 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #542
2019-02-20 18:33:19,142 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,143 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,143 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,146 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-20 18:33:19,146 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a7288a3 expecting start txid #543
2019-02-20 18:33:19,146 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,146 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,146 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,158 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 215 edits # 5 loaded in 0 seconds
2019-02-20 18:33:19,158 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2974f221 expecting start txid #548
2019-02-20 18:33:19,158 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,158 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,158 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,194 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 30929 edits # 557 loaded in 0 seconds
2019-02-20 18:33:19,194 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@58fe0499 expecting start txid #1105
2019-02-20 18:33:19,194 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,194 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,194 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,197 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 519 edits # 6 loaded in 0 seconds
2019-02-20 18:33:19,197 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@686449f9 expecting start txid #1111
2019-02-20 18:33:19,197 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,197 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,197 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,221 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 25050 edits # 458 loaded in 0 seconds
2019-02-20 18:33:19,221 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@665df3c6 expecting start txid #1569
2019-02-20 18:33:19,221 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,221 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,221 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,229 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 8020 edits # 134 loaded in 0 seconds
2019-02-20 18:33:19,229 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68b6f0d6 expecting start txid #1703
2019-02-20 18:33:19,229 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,229 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,229 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,232 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-20 18:33:19,232 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4044fb95 expecting start txid #1704
2019-02-20 18:33:19,232 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,232 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,232 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 84 loaded in 0 seconds
2019-02-20 18:33:19,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@aa549e5 expecting start txid #1788
2019-02-20 18:33:19,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,239 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,239 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,252 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 16494 edits # 296 loaded in 0 seconds
2019-02-20 18:33:19,252 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@36f48b4 expecting start txid #2084
2019-02-20 18:33:19,252 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,252 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,252 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,264 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 14653 edits # 266 loaded in 0 seconds
2019-02-20 18:33:19,264 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5c00384f expecting start txid #2350
2019-02-20 18:33:19,264 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,264 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,264 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,276 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 18175 edits # 320 loaded in 0 seconds
2019-02-20 18:33:19,277 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3b7ff809 expecting start txid #2670
2019-02-20 18:33:19,277 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,277 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,277 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,289 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 13747 edits # 247 loaded in 0 seconds
2019-02-20 18:33:19,289 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1bb564e2 expecting start txid #2917
2019-02-20 18:33:19,289 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,289 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,289 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,304 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 18073 edits # 325 loaded in 0 seconds
2019-02-20 18:33:19,304 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@62e6b5c8 expecting start txid #3242
2019-02-20 18:33:19,304 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,304 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,304 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,309 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 7 loaded in 0 seconds
2019-02-20 18:33:19,309 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3f792b9b expecting start txid #3249
2019-02-20 18:33:19,309 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:33:19,310 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,310 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:33:19,315 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 24 loaded in 0 seconds
2019-02-20 18:33:19,315 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-20 18:33:19,315 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-20 18:33:19,316 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 2215 msecs
2019-02-20 18:33:19,498 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-20 18:33:19,503 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 18:33:19,515 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-20 18:33:19,700 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-20 18:33:19,709 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 3
2019-02-20 18:33:19,720 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 136 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-02-20 18:33:19,750 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-20 18:33:19,750 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-20 18:33:19,753 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-20 18:33:19,756 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-20 18:33:19,761 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-20 18:33:19,767 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-20 18:33:19,938 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=e0817042-f3cb-4b7c-a859-901603b299c7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage e0817042-f3cb-4b7c-a859-901603b299c7
2019-02-20 18:33:19,939 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-20 18:33:19,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e0817042-f3cb-4b7c-a859-901603b299c7 (10.10.1.2:9866).
2019-02-20 18:33:19,941 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=29984e1f-b62e-4d76-94cb-b87f59987a8a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage 29984e1f-b62e-4d76-94cb-b87f59987a8a
2019-02-20 18:33:19,941 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-20 18:33:19,942 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 29984e1f-b62e-4d76-94cb-b87f59987a8a (10.10.1.3:9866).
2019-02-20 18:33:19,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=0aafc93e-1b02-4c5b-9540-0075464bc9a8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage 0aafc93e-1b02-4c5b-9540-0075464bc9a8
2019-02-20 18:33:19,942 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-20 18:33:19,942 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 0aafc93e-1b02-4c5b-9540-0075464bc9a8 (10.10.1.5:9866).
2019-02-20 18:33:19,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-fb7779e9-8d96-4814-84e7-0856c705fa09 for DN 10.10.1.2:9866
2019-02-20 18:33:19,955 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-55cb0859-d395-4226-b6fa-d0b50b678f15 for DN 10.10.1.5:9866
2019-02-20 18:33:19,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f for DN 10.10.1.3:9866
2019-02-20 18:33:19,968 INFO BlockStateChange: BLOCK* processReport 0x189a033de397df17: Processing first storage report for DS-fb7779e9-8d96-4814-84e7-0856c705fa09 from datanode e0817042-f3cb-4b7c-a859-901603b299c7
2019-02-20 18:33:19,978 INFO BlockStateChange: BLOCK* processReport 0x189a033de397df17: from storage DS-fb7779e9-8d96-4814-84e7-0856c705fa09 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=e0817042-f3cb-4b7c-a859-901603b299c7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 140, hasStaleStorage: false, processing time: 10 msecs, invalidatedBlocks: 0
2019-02-20 18:33:19,978 INFO BlockStateChange: BLOCK* processReport 0xe952d94c8958ee61: Processing first storage report for DS-55cb0859-d395-4226-b6fa-d0b50b678f15 from datanode 0aafc93e-1b02-4c5b-9540-0075464bc9a8
2019-02-20 18:33:19,983 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 136 has reached the threshold 0.9990 of total blocks 137. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 30 seconds.
2019-02-20 18:33:19,983 INFO BlockStateChange: BLOCK* processReport 0xe952d94c8958ee61: from storage DS-55cb0859-d395-4226-b6fa-d0b50b678f15 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=0aafc93e-1b02-4c5b-9540-0075464bc9a8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 156, hasStaleStorage: false, processing time: 5 msecs, invalidatedBlocks: 0
2019-02-20 18:33:19,984 INFO BlockStateChange: BLOCK* processReport 0x935aa3715420161b: Processing first storage report for DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f from datanode 29984e1f-b62e-4d76-94cb-b87f59987a8a
2019-02-20 18:33:19,986 INFO BlockStateChange: BLOCK* processReport 0x935aa3715420161b: from storage DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=29984e1f-b62e-4d76-94cb-b87f59987a8a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 148, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-02-20 18:33:39,986 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 137 has reached the threshold 0.9990 of total blocks 137. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-02-20 18:33:49,987 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2019-02-20 18:33:49,987 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 30 secs
2019-02-20 18:33:49,987 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2019-02-20 18:33:49,987 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-20 18:35:19,777 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:35:19,832 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.util.concurrent.ExecutionException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -126 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -126 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:381)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -126 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -126 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:150)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:366)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:363)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$MultipleNameNodeProxy.call(EditLogTailer.java:513)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-02-20 18:36:19,839 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:36:19,842 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.util.concurrent.ExecutionException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -186 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -186 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:381)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -186 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -186 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:150)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:366)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:363)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$MultipleNameNodeProxy.call(EditLogTailer.java:513)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-02-20 18:37:19,847 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:37:19,851 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.util.concurrent.ExecutionException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -246 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -246 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:381)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -246 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -246 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:150)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:366)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:363)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$MultipleNameNodeProxy.call(EditLogTailer.java:513)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-02-20 18:38:19,858 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:38:19,862 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.util.concurrent.ExecutionException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -306 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -306 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:381)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -306 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -306 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:150)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:366)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:363)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$MultipleNameNodeProxy.call(EditLogTailer.java:513)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-02-20 18:39:19,869 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:39:19,873 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.util.concurrent.ExecutionException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -366 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -366 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:381)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -366 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -366 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:150)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:366)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:363)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$MultipleNameNodeProxy.call(EditLogTailer.java:513)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-02-20 18:40:19,880 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:40:19,883 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.util.concurrent.ExecutionException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -426 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -426 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:381)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -426 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -426 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:150)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:366)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:363)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$MultipleNameNodeProxy.call(EditLogTailer.java:513)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-02-20 18:41:19,889 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:41:19,892 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.util.concurrent.ExecutionException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -486 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -486 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:381)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -486 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -486 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:150)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:366)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:363)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$MultipleNameNodeProxy.call(EditLogTailer.java:513)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-02-20 18:42:19,902 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:42:19,906 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.util.concurrent.ExecutionException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -546 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -546 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:381)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -546 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -546 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:150)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:366)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:363)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$MultipleNameNodeProxy.call(EditLogTailer.java:513)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-02-20 18:43:19,912 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:43:19,916 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.util.concurrent.ExecutionException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -606 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -606 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:206)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:381)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -606 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 134 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 137.
The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in -606 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:150)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:366)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$2.doWork(EditLogTailer.java:363)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$MultipleNameNodeProxy.call(EditLogTailer.java:513)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-02-20 18:43:27,006 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-02-20 18:43:27,007 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-02-20 18:43:27,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-20 18:43:27,018 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-02-20 18:43:27,072 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 8
2019-02-20 18:43:27,072 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 3273
2019-02-20 18:43:27,092 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.3:8485: segmentState { startTxId: 3273 endTxId: 3273 isInProgress: true } lastWriterEpoch: 7 lastCommittedTxId: 3271
10.10.1.5:8485: segmentState { startTxId: 3273 endTxId: 3273 isInProgress: true } lastWriterEpoch: 7 lastCommittedTxId: 3271
10.10.1.2:8485: segmentState { startTxId: 3273 endTxId: 3273 isInProgress: true } lastWriterEpoch: 7 lastCommittedTxId: 3271
2019-02-20 18:43:27,095 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.3:8485=segmentState {
  startTxId: 3273
  endTxId: 3273
  isInProgress: true
}
lastWriterEpoch: 7
lastCommittedTxId: 3271

2019-02-20 18:43:27,130 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-02-20 18:43:27,149 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000003249 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000003249-0000000000000003272
2019-02-20 18:43:27,167 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-02-20 18:43:27,172 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@22e44f44 expecting start txid #3273
2019-02-20 18:43:27,172 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:43:27,173 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 3273
2019-02-20 18:43:27,173 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 3273
2019-02-20 18:43:27,180 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-20 18:43:27,180 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-02-20 18:43:27,181 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-02-20 18:43:27,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-20 18:43:27,181 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 3274
2019-02-20 18:43:27,184 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3274
2019-02-20 18:43:27,450 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 63 
2019-02-20 18:43:27,472 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-20 18:43:27,476 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 3 milliseconds
name space=21
storage space=56371445760
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-02-20 18:43:27,481 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-20 18:43:27,548 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 140
2019-02-20 18:43:27,548 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-20 18:43:27,548 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-20 18:43:27,548 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-20 18:43:27,548 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 3
2019-02-20 18:43:27,549 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 368 msec
2019-02-20 18:43:50,186 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742757_1933, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-20 18:43:50,841 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742758_1934, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-20 18:43:51,241 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742759_1935, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-20 18:43:51,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742760_1936, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-20 18:43:51,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742761_1937, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-20 18:43:52,069 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742762_1938, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-20 18:43:52,531 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742763_1939, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-20 18:43:52,600 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742764_1940, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-20 18:43:53,009 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742765_1941, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-20 18:43:53,130 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742766_1942, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-20 18:43:53,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742767_1943, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-20 18:43:53,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742768_1944, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-20 18:43:53,879 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_-647154727_1
2019-02-20 18:43:54,000 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742769_1945, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-20 18:43:54,404 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742770_1946, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-20 18:43:54,777 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742771_1947, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-20 18:43:54,849 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742772_1948, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-20 18:43:55,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742773_1949, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-20 18:43:55,355 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742774_1950, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-20 18:43:55,697 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1862192984_1
2019-02-20 18:43:55,796 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742775_1951, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-20 18:43:56,194 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742776_1952, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-20 18:43:56,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742777_1953, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-20 18:43:56,985 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742778_1954, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-20 18:43:57,421 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742779_1955, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-20 18:43:57,818 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742780_1956, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-20 18:43:58,232 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile6._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1612063351_1
2019-02-20 18:43:58,514 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742781_1957, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-20 18:43:59,061 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742782_1958, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-20 18:43:59,479 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742783_1959, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-20 18:43:59,490 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742784_1960, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-02-20 18:44:00,007 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742785_1961, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-20 18:44:01,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742786_1962, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-20 18:44:01,847 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742787_1963, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-20 18:44:02,634 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-20 18:44:02,636 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode058.clemson.cloudlab.us/130.127.133.67
************************************************************/
2019-02-20 18:44:19,672 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode058.clemson.cloudlab.us/130.127.133.67
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-18T22:18Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-20 18:44:19,682 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 18:44:19,687 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-20 18:44:19,972 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 18:44:20,075 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 18:44:20,076 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-20 18:44:20,127 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-20 18:44:20,127 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-20 18:44:20,292 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 18:44:20,319 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-20 18:44:20,337 INFO org.eclipse.jetty.util.log: Logging initialized @1179ms
2019-02-20 18:44:20,444 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 18:44:20,458 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-20 18:44:20,469 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 18:44:20,472 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-20 18:44:20,472 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 18:44:20,472 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 18:44:20,499 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-20 18:44:20,499 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-20 18:44:20,508 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-20 18:44:20,510 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-20 18:44:20,544 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-20 18:44:20,545 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-20 18:44:20,620 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-20 18:44:20,641 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-20 18:44:20,641 INFO org.eclipse.jetty.server.Server: Started @1485ms
2019-02-20 18:44:20,983 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-20 18:44:21,042 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-20 18:44:21,057 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-20 18:44:21,058 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-20 18:44:21,061 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-20 18:44:21,067 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-20 18:44:21,067 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-20 18:44:21,067 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-20 18:44:21,068 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-20 18:44:21,068 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-20 18:44:21,111 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-20 18:44:21,123 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-20 18:44:21,124 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-20 18:44:21,128 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-20 18:44:21,129 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 20 18:44:21
2019-02-20 18:44:21,130 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-20 18:44:21,131 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:44:21,132 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-20 18:44:21,132 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-20 18:44:21,269 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-20 18:44:21,279 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-20 18:44:21,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-20 18:44:21,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-20 18:44:21,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-20 18:44:21,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-20 18:44:21,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-20 18:44:21,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-20 18:44:21,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-20 18:44:21,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-20 18:44:21,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-20 18:44:21,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-20 18:44:21,364 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-20 18:44:21,364 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:44:21,364 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-20 18:44:21,364 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-20 18:44:21,438 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-20 18:44:21,438 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-20 18:44:21,438 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-20 18:44:21,439 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-20 18:44:21,445 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-20 18:44:21,448 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-20 18:44:21,453 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-20 18:44:21,453 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:44:21,454 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-20 18:44:21,454 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-20 18:44:21,481 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-20 18:44:21,481 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-20 18:44:21,481 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-20 18:44:21,485 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-20 18:44:21,486 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-20 18:44:21,488 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-20 18:44:21,488 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:44:21,488 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-20 18:44:21,488 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-20 18:44:21,560 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 59247@clnode058.clemson.cloudlab.us
2019-02-20 18:44:22,963 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1167ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=295ms
GC pool 'PS Scavenge' had collection(s): count=1 time=984ms
2019-02-20 18:44:23,138 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-20 18:44:23,201 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-20 18:44:23,203 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-20 18:44:23,234 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-20 18:44:23,234 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-20 18:44:23,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-02-20 18:44:23,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,243 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,243 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-02-20 18:44:23,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #542
2019-02-20 18:44:23,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,362 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,362 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,366 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-20 18:44:23,366 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a7288a3 expecting start txid #543
2019-02-20 18:44:23,366 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,366 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,366 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,377 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 215 edits # 5 loaded in 0 seconds
2019-02-20 18:44:23,378 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2974f221 expecting start txid #548
2019-02-20 18:44:23,378 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,378 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,378 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,413 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=548&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 30929 edits # 557 loaded in 0 seconds
2019-02-20 18:44:23,413 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@58fe0499 expecting start txid #1105
2019-02-20 18:44:23,413 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,413 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,413 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,416 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1105&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 519 edits # 6 loaded in 0 seconds
2019-02-20 18:44:23,416 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@686449f9 expecting start txid #1111
2019-02-20 18:44:23,416 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,416 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,416 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,437 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1111&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 25050 edits # 458 loaded in 0 seconds
2019-02-20 18:44:23,437 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@665df3c6 expecting start txid #1569
2019-02-20 18:44:23,437 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,437 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,437 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,444 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1569&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 8020 edits # 134 loaded in 0 seconds
2019-02-20 18:44:23,445 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68b6f0d6 expecting start txid #1703
2019-02-20 18:44:23,445 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,445 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,445 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,448 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1703&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-20 18:44:23,448 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4044fb95 expecting start txid #1704
2019-02-20 18:44:23,448 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,448 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,448 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,454 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1704&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 84 loaded in 0 seconds
2019-02-20 18:44:23,454 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@aa549e5 expecting start txid #1788
2019-02-20 18:44:23,454 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,455 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,455 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,466 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1788&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 16494 edits # 296 loaded in 0 seconds
2019-02-20 18:44:23,466 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@36f48b4 expecting start txid #2084
2019-02-20 18:44:23,466 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,466 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,466 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2084&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 14653 edits # 266 loaded in 0 seconds
2019-02-20 18:44:23,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5c00384f expecting start txid #2350
2019-02-20 18:44:23,477 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,478 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,478 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,490 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2350&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 18175 edits # 320 loaded in 0 seconds
2019-02-20 18:44:23,490 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3b7ff809 expecting start txid #2670
2019-02-20 18:44:23,490 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,491 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,491 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,500 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2670&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 13747 edits # 247 loaded in 0 seconds
2019-02-20 18:44:23,501 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1bb564e2 expecting start txid #2917
2019-02-20 18:44:23,501 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,501 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,501 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,511 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2917&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 18073 edits # 325 loaded in 0 seconds
2019-02-20 18:44:23,511 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@62e6b5c8 expecting start txid #3242
2019-02-20 18:44:23,512 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,512 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,512 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,516 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3242&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 7 loaded in 0 seconds
2019-02-20 18:44:23,517 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3f792b9b expecting start txid #3249
2019-02-20 18:44:23,517 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,517 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,517 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,522 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3249&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 24 loaded in 0 seconds
2019-02-20 18:44:23,522 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7b8233cd expecting start txid #3273
2019-02-20 18:44:23,522 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,522 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,522 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,525 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3273&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-20 18:44:23,526 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4b20ca2b expecting start txid #3274
2019-02-20 18:44:23,526 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3274&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3274&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3274&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:44:23,526 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3274&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3274&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3274&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,526 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3274&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 1
2019-02-20 18:44:23,532 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3274&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3274&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3274&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 1048576 edits # 112 loaded in 0 seconds
2019-02-20 18:44:23,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-20 18:44:23,532 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-20 18:44:23,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 2036 msecs
2019-02-20 18:44:23,715 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-20 18:44:23,720 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 18:44:23,733 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-20 18:44:23,928 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-20 18:44:23,939 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 6
2019-02-20 18:44:23,950 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 116 blocks to reach the threshold 0.9990 of total blocks 117.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-02-20 18:44:23,981 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-20 18:44:23,981 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-20 18:44:23,983 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-20 18:44:23,986 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-20 18:44:23,991 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-20 18:44:23,998 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-20 18:44:24,206 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=29984e1f-b62e-4d76-94cb-b87f59987a8a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage 29984e1f-b62e-4d76-94cb-b87f59987a8a
2019-02-20 18:44:24,208 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-20 18:44:24,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 29984e1f-b62e-4d76-94cb-b87f59987a8a (10.10.1.3:9866).
2019-02-20 18:44:24,210 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=e0817042-f3cb-4b7c-a859-901603b299c7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage e0817042-f3cb-4b7c-a859-901603b299c7
2019-02-20 18:44:24,210 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-20 18:44:24,210 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e0817042-f3cb-4b7c-a859-901603b299c7 (10.10.1.2:9866).
2019-02-20 18:44:24,210 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=0aafc93e-1b02-4c5b-9540-0075464bc9a8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024) storage 0aafc93e-1b02-4c5b-9540-0075464bc9a8
2019-02-20 18:44:24,210 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-20 18:44:24,210 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 0aafc93e-1b02-4c5b-9540-0075464bc9a8 (10.10.1.5:9866).
2019-02-20 18:44:24,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-fb7779e9-8d96-4814-84e7-0856c705fa09 for DN 10.10.1.2:9866
2019-02-20 18:44:24,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-55cb0859-d395-4226-b6fa-d0b50b678f15 for DN 10.10.1.5:9866
2019-02-20 18:44:24,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f for DN 10.10.1.3:9866
2019-02-20 18:44:24,237 INFO BlockStateChange: BLOCK* processReport 0x189a033de397df18: Processing first storage report for DS-fb7779e9-8d96-4814-84e7-0856c705fa09 from datanode e0817042-f3cb-4b7c-a859-901603b299c7
2019-02-20 18:44:24,249 INFO BlockStateChange: BLOCK* processReport 0x189a033de397df18: from storage DS-fb7779e9-8d96-4814-84e7-0856c705fa09 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=e0817042-f3cb-4b7c-a859-901603b299c7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 125, hasStaleStorage: false, processing time: 12 msecs, invalidatedBlocks: 0
2019-02-20 18:44:24,249 INFO BlockStateChange: BLOCK* processReport 0x935aa3715420161c: Processing first storage report for DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f from datanode 29984e1f-b62e-4d76-94cb-b87f59987a8a
2019-02-20 18:44:24,252 INFO BlockStateChange: BLOCK* processReport 0x935aa3715420161c: from storage DS-87277538-2c2c-4d0f-81b0-3796cba1cd4f node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=29984e1f-b62e-4d76-94cb-b87f59987a8a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 117, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2019-02-20 18:44:24,252 INFO BlockStateChange: BLOCK* processReport 0xe952d94c8958ee62: Processing first storage report for DS-55cb0859-d395-4226-b6fa-d0b50b678f15 from datanode 0aafc93e-1b02-4c5b-9540-0075464bc9a8
2019-02-20 18:44:24,254 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 116 has reached the threshold 0.9990 of total blocks 117. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 30 seconds.
2019-02-20 18:44:24,257 INFO BlockStateChange: BLOCK* processReport 0xe952d94c8958ee62: from storage DS-55cb0859-d395-4226-b6fa-d0b50b678f15 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=0aafc93e-1b02-4c5b-9540-0075464bc9a8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa;nsid=1470706885;c=1550711316024), blocks: 149, hasStaleStorage: false, processing time: 5 msecs, invalidatedBlocks: 0
2019-02-20 18:44:44,259 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 117 has reached the threshold 0.9990 of total blocks 117. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-02-20 18:44:54,260 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2019-02-20 18:44:54,260 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 30 secs
2019-02-20 18:44:54,260 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2019-02-20 18:44:54,260 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-20 18:46:24,013 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:46:24,801 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@49a15cec expecting start txid #3386
2019-02-20 18:46:24,801 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3386&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3386&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:46:24,802 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3386&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3386&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 3386
2019-02-20 18:46:24,802 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3386&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 3386
2019-02-20 18:46:24,835 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3386&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3386&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 22639 edits # 416 loaded in 0 seconds
2019-02-20 18:48:24,842 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:48:25,043 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1db427e expecting start txid #3802
2019-02-20 18:48:25,043 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3802&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3802&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:48:25,043 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3802&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3802&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 3802
2019-02-20 18:48:25,043 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3802&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 3802
2019-02-20 18:48:25,050 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3802&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3802&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 4118 edits # 63 loaded in 0 seconds
2019-02-20 18:50:25,057 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:50:25,241 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@56c456fa expecting start txid #3865
2019-02-20 18:50:25,241 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3865&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3865&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:25,241 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3865&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3865&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 3865
2019-02-20 18:50:25,241 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3865&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 3865
2019-02-20 18:50:25,263 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3865&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3865&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 24785 edits # 451 loaded in 0 seconds
2019-02-20 18:52:25,271 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:52:25,457 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@193bcab5 expecting start txid #4316
2019-02-20 18:52:25,457 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4316&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4316&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4316&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:52:25,457 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4316&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4316&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4316&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 4316
2019-02-20 18:52:25,457 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4316&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 4316
2019-02-20 18:52:25,464 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4316&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4316&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4316&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 6660 edits # 112 loaded in 0 seconds
2019-02-20 18:54:25,472 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:54:25,652 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@201e73f9 expecting start txid #4428
2019-02-20 18:54:25,652 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4428&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4428&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4428&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:54:25,652 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4428&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4428&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4428&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 4428
2019-02-20 18:54:25,652 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4428&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true' to transaction ID 4428
2019-02-20 18:54:25,671 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4428&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4428&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4428&storageInfo=-64%3A1470706885%3A1550711316024%3ACID-2316b9f7-a4d8-43f6-b752-18d08de7f5aa&inProgressOk=true of size 20271 edits # 367 loaded in 0 seconds
