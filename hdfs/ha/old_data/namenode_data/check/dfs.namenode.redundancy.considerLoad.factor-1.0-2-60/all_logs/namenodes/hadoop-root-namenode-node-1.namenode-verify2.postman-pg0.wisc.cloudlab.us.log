2019-03-01 00:13:46,399 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = c220g2-011319.wisc.cloudlab.us/128.104.222.139
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-01T04:08Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-01 00:13:46,414 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-01 00:13:46,420 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-03-01 00:13:46,674 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-03-01 00:13:46,766 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-03-01 00:13:46,766 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-03-01 00:13:46,845 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-03-01 00:13:46,846 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-03-01 00:13:46,986 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-03-01 00:13:47,023 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-03-01 00:13:47,044 INFO org.eclipse.jetty.util.log: Logging initialized @1263ms
2019-03-01 00:13:47,153 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-01 00:13:47,171 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-03-01 00:13:47,186 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-01 00:13:47,190 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-03-01 00:13:47,190 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-01 00:13:47,190 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-01 00:13:47,224 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-03-01 00:13:47,224 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-03-01 00:13:47,234 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-03-01 00:13:47,235 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-03-01 00:13:47,285 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-01 00:13:47,286 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-01 00:13:47,379 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-03-01 00:13:47,404 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-03-01 00:13:47,404 INFO org.eclipse.jetty.server.Server: Started @1625ms
2019-03-01 00:13:47,766 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-03-01 00:13:47,812 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-03-01 00:13:47,824 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-03-01 00:13:47,825 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-03-01 00:13:47,827 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-03-01 00:13:47,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-03-01 00:13:47,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-03-01 00:13:47,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-03-01 00:13:47,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-03-01 00:13:47,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-03-01 00:13:47,867 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-01 00:13:47,876 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-03-01 00:13:47,876 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-03-01 00:13:47,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-03-01 00:13:47,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Mar 01 00:13:47
2019-03-01 00:13:47,882 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-03-01 00:13:47,882 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:13:47,883 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-03-01 00:13:47,883 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-03-01 00:13:48,025 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-03-01 00:13:48,033 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-03-01 00:13:48,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-03-01 00:13:48,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-03-01 00:13:48,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-03-01 00:13:48,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-03-01 00:13:48,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-03-01 00:13:48,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-03-01 00:13:48,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-03-01 00:13:48,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-03-01 00:13:48,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-03-01 00:13:48,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-03-01 00:13:48,096 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-03-01 00:13:48,096 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:13:48,096 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-03-01 00:13:48,096 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-03-01 00:13:48,170 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-03-01 00:13:48,170 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-03-01 00:13:48,170 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-03-01 00:13:48,170 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-03-01 00:13:48,176 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-03-01 00:13:48,178 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-03-01 00:13:48,182 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-03-01 00:13:48,182 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:13:48,183 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-03-01 00:13:48,183 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-03-01 00:13:48,209 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-03-01 00:13:48,209 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-03-01 00:13:48,209 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-03-01 00:13:48,212 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-03-01 00:13:48,212 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-03-01 00:13:48,214 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-03-01 00:13:48,214 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:13:48,214 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-03-01 00:13:48,215 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-03-01 00:13:48,262 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 33470@c220g2-011319.wisc.cloudlab.us
2019-03-01 00:13:49,610 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1120ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=285ms
GC pool 'PS Scavenge' had collection(s): count=1 time=894ms
2019-03-01 00:13:50,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:50,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:50,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:51,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:51,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:51,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:52,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:52,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:52,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:53,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:53,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:53,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:54,403 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-03-01 00:13:54,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:54,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:54,752 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:55,403 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-03-01 00:13:55,655 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2019-03-01 00:13:55,655 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-03-01 00:13:55,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-01 00:13:55,751 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-03-01 00:13:55,756 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-03-01 00:13:55,802 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-03-01 00:13:55,802 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-03-01 00:13:55,809 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-03-01 00:13:55,810 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-03-01 00:13:55,810 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 7588 msecs
2019-03-01 00:13:55,976 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-1-link-0:8020
2019-03-01 00:13:55,980 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-01 00:13:55,990 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-03-01 00:13:56,186 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-03-01 00:13:56,196 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-03-01 00:13:56,211 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2019-03-01 00:13:56,211 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2019-03-01 00:13:56,211 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-03-01 00:13:56,250 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-03-01 00:13:56,251 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-03-01 00:13:56,254 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-1-link-0/10.10.1.4:8020
2019-03-01 00:13:56,258 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-03-01 00:13:56,269 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-03-01 00:13:56,280 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-03-01 00:13:56,828 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=5a8d9380-9eaf-405f-b526-11106cb349b7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage 5a8d9380-9eaf-405f-b526-11106cb349b7
2019-03-01 00:13:56,831 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-03-01 00:13:56,833 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 5a8d9380-9eaf-405f-b526-11106cb349b7 (10.10.1.5:9866).
2019-03-01 00:13:56,836 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e01372d1-0745-4c89-9fe7-e5d932e31fb6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage e01372d1-0745-4c89-9fe7-e5d932e31fb6
2019-03-01 00:13:56,837 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-03-01 00:13:56,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e01372d1-0745-4c89-9fe7-e5d932e31fb6 (10.10.1.3:9866).
2019-03-01 00:13:56,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 for DN 10.10.1.3:9866
2019-03-01 00:13:56,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-c172e123-b020-451c-aa00-65bd69771af0 for DN 10.10.1.5:9866
2019-03-01 00:13:56,962 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=5992f680-a97f-467f-aa39-9017c671a8b8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage 5992f680-a97f-467f-aa39-9017c671a8b8
2019-03-01 00:13:56,962 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-03-01 00:13:56,962 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 5992f680-a97f-467f-aa39-9017c671a8b8 (10.10.1.2:9866).
2019-03-01 00:13:57,019 INFO BlockStateChange: BLOCK* processReport 0xffd07e1b704b4353: Processing first storage report for DS-c172e123-b020-451c-aa00-65bd69771af0 from datanode 5a8d9380-9eaf-405f-b526-11106cb349b7
2019-03-01 00:13:57,022 INFO BlockStateChange: BLOCK* processReport 0xffd07e1b704b4353: from storage DS-c172e123-b020-451c-aa00-65bd69771af0 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=5a8d9380-9eaf-405f-b526-11106cb349b7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 0, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2019-03-01 00:13:57,022 INFO BlockStateChange: BLOCK* processReport 0x4ae55c5c59e194ec: Processing first storage report for DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 from datanode e01372d1-0745-4c89-9fe7-e5d932e31fb6
2019-03-01 00:13:57,023 INFO BlockStateChange: BLOCK* processReport 0x4ae55c5c59e194ec: from storage DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e01372d1-0745-4c89-9fe7-e5d932e31fb6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-03-01 00:13:57,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 for DN 10.10.1.2:9866
2019-03-01 00:13:57,064 INFO BlockStateChange: BLOCK* processReport 0x127710ca93b30e4a: Processing first storage report for DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 from datanode 5992f680-a97f-467f-aa39-9017c671a8b8
2019-03-01 00:13:57,065 INFO BlockStateChange: BLOCK* processReport 0x127710ca93b30e4a: from storage DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=5992f680-a97f-467f-aa39-9017c671a8b8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-03-01 00:15:04,691 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-03-01 00:15:04,693 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-03-01 00:15:04,799 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-03-01 00:15:04,814 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-03-01 00:15:04,900 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 2
2019-03-01 00:15:04,900 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 1
2019-03-01 00:15:04,938 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.5:8485: segmentState { startTxId: 1 endTxId: 541 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 540
10.10.1.3:8485: segmentState { startTxId: 1 endTxId: 541 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 540
2019-03-01 00:15:04,942 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.5:8485=segmentState {
  startTxId: 1
  endTxId: 541
  isInProgress: true
}
lastWriterEpoch: 1
lastCommittedTxId: 540

2019-03-01 00:15:05,017 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-03-01 00:15:05,018 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-03-01 00:15:05,041 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6bc4f7cc expecting start txid #1
2019-03-01 00:15:05,042 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:15:05,047 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:15:05,047 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:15:05,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-03-01 00:15:05,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-03-01 00:15:05,357 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-03-01 00:15:05,357 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-03-01 00:15:05,357 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 542
2019-03-01 00:15:05,362 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 542
2019-03-01 00:15:05,607 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 43 
2019-03-01 00:15:05,625 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-03-01 00:15:05,631 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 6 milliseconds
name space=21
storage space=64424509440
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-03-01 00:15:05,639 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-03-01 00:15:05,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 160
2019-03-01 00:15:05,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-03-01 00:15:05,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-03-01 00:15:05,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-03-01 00:15:05,731 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-03-01 00:15:05,732 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 374 msec
2019-03-01 00:15:39,528 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-03-01 00:15:39,532 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at c220g2-011319.wisc.cloudlab.us/128.104.222.139
************************************************************/
2019-03-01 00:15:56,802 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = c220g2-011319.wisc.cloudlab.us/128.104.222.139
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-01T04:08Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-01 00:15:56,814 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-01 00:15:56,820 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-03-01 00:15:57,151 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-03-01 00:15:57,282 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-03-01 00:15:57,282 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-03-01 00:15:57,358 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-03-01 00:15:57,359 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-03-01 00:15:57,497 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-03-01 00:15:57,534 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-03-01 00:15:57,555 INFO org.eclipse.jetty.util.log: Logging initialized @1350ms
2019-03-01 00:15:57,677 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-01 00:15:57,697 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-03-01 00:15:57,713 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-01 00:15:57,717 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-03-01 00:15:57,717 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-01 00:15:57,717 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-01 00:15:57,753 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-03-01 00:15:57,753 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-03-01 00:15:57,764 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-03-01 00:15:57,765 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-03-01 00:15:57,816 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-01 00:15:57,817 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-01 00:15:57,913 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-03-01 00:15:57,948 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@6fa5672a{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-03-01 00:15:57,948 INFO org.eclipse.jetty.server.Server: Started @1745ms
2019-03-01 00:15:58,312 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-03-01 00:15:58,375 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-03-01 00:15:58,388 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-03-01 00:15:58,390 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-03-01 00:15:58,392 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-03-01 00:15:58,398 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-03-01 00:15:58,398 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-03-01 00:15:58,398 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-03-01 00:15:58,398 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-03-01 00:15:58,399 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-03-01 00:15:58,435 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-01 00:15:58,445 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-03-01 00:15:58,445 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-03-01 00:15:58,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-03-01 00:15:58,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Mar 01 00:15:58
2019-03-01 00:15:58,451 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-03-01 00:15:58,451 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:15:58,452 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-03-01 00:15:58,453 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-03-01 00:15:58,588 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-03-01 00:15:58,596 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-03-01 00:15:58,596 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-03-01 00:15:58,596 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-03-01 00:15:58,596 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-03-01 00:15:58,596 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-03-01 00:15:58,596 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-03-01 00:15:58,596 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-03-01 00:15:58,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-03-01 00:15:58,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-03-01 00:15:58,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-03-01 00:15:58,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-03-01 00:15:58,664 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-03-01 00:15:58,664 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:15:58,664 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-03-01 00:15:58,665 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-03-01 00:15:58,739 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-03-01 00:15:58,739 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-03-01 00:15:58,739 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-03-01 00:15:58,739 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-03-01 00:15:58,745 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-03-01 00:15:58,748 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-03-01 00:15:58,752 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-03-01 00:15:58,752 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:15:58,753 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-03-01 00:15:58,753 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-03-01 00:15:58,779 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-03-01 00:15:58,779 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-03-01 00:15:58,780 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-03-01 00:15:58,783 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-03-01 00:15:58,783 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-03-01 00:15:58,785 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-03-01 00:15:58,785 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:15:58,786 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-03-01 00:15:58,786 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-03-01 00:15:58,827 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 33917@c220g2-011319.wisc.cloudlab.us
2019-03-01 00:16:00,131 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1131ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=242ms
GC pool 'PS Scavenge' had collection(s): count=1 time=893ms
2019-03-01 00:16:00,310 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-03-01 00:16:00,389 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-03-01 00:16:00,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-03-01 00:16:00,435 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-03-01 00:16:00,435 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-03-01 00:16:00,441 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-03-01 00:16:00,441 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:16:00,446 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:16:00,446 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:16:00,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-03-01 00:16:00,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #542
2019-03-01 00:16:00,556 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:16:00,557 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:16:00,557 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:16:00,700 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:16:00,700 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-03-01 00:16:00,700 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-03-01 00:16:00,700 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1908 msecs
2019-03-01 00:16:00,865 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-1-link-0:8020
2019-03-01 00:16:00,869 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-01 00:16:00,877 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-03-01 00:16:01,089 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-03-01 00:16:01,100 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-03-01 00:16:01,117 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 159 blocks to reach the threshold 0.9990 of total blocks 160.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-03-01 00:16:01,150 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-03-01 00:16:01,151 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-03-01 00:16:01,154 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-1-link-0/10.10.1.4:8020
2019-03-01 00:16:01,158 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-03-01 00:16:01,167 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-03-01 00:16:01,174 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-03-01 00:16:01,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e01372d1-0745-4c89-9fe7-e5d932e31fb6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage e01372d1-0745-4c89-9fe7-e5d932e31fb6
2019-03-01 00:16:01,369 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-03-01 00:16:01,370 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e01372d1-0745-4c89-9fe7-e5d932e31fb6 (10.10.1.3:9866).
2019-03-01 00:16:01,371 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=5992f680-a97f-467f-aa39-9017c671a8b8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage 5992f680-a97f-467f-aa39-9017c671a8b8
2019-03-01 00:16:01,372 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-03-01 00:16:01,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 5992f680-a97f-467f-aa39-9017c671a8b8 (10.10.1.2:9866).
2019-03-01 00:16:01,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 for DN 10.10.1.3:9866
2019-03-01 00:16:01,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 for DN 10.10.1.2:9866
2019-03-01 00:16:01,402 INFO BlockStateChange: BLOCK* processReport 0x127710ca93b30e4b: Processing first storage report for DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 from datanode 5992f680-a97f-467f-aa39-9017c671a8b8
2019-03-01 00:16:01,418 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 159 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 2 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2019-03-01 00:16:01,418 INFO BlockStateChange: BLOCK* processReport 0x127710ca93b30e4b: from storage DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=5992f680-a97f-467f-aa39-9017c671a8b8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 160, hasStaleStorage: false, processing time: 15 msecs, invalidatedBlocks: 0
2019-03-01 00:16:01,418 INFO BlockStateChange: BLOCK* processReport 0x4ae55c5c59e194ed: Processing first storage report for DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 from datanode e01372d1-0745-4c89-9fe7-e5d932e31fb6
2019-03-01 00:16:01,422 INFO BlockStateChange: BLOCK* processReport 0x4ae55c5c59e194ed: from storage DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e01372d1-0745-4c89-9fe7-e5d932e31fb6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 160, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2019-03-01 00:16:01,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=5a8d9380-9eaf-405f-b526-11106cb349b7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage 5a8d9380-9eaf-405f-b526-11106cb349b7
2019-03-01 00:16:01,878 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-03-01 00:16:01,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 5a8d9380-9eaf-405f-b526-11106cb349b7 (10.10.1.5:9866).
2019-03-01 00:16:01,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-c172e123-b020-451c-aa00-65bd69771af0 for DN 10.10.1.5:9866
2019-03-01 00:16:01,883 INFO BlockStateChange: BLOCK* processReport 0xffd07e1b704b4354: Processing first storage report for DS-c172e123-b020-451c-aa00-65bd69771af0 from datanode 5a8d9380-9eaf-405f-b526-11106cb349b7
2019-03-01 00:16:01,885 INFO BlockStateChange: BLOCK* processReport 0xffd07e1b704b4354: from storage DS-c172e123-b020-451c-aa00-65bd69771af0 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=5a8d9380-9eaf-405f-b526-11106cb349b7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 160, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2019-03-01 00:16:21,422 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 160 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-03-01 00:16:31,423 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2019-03-01 00:16:31,423 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 30 secs
2019-03-01 00:16:31,424 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2019-03-01 00:16:31,424 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-03-01 00:17:09,165 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-03-01 00:17:09,167 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-03-01 00:17:09,272 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-03-01 00:17:09,286 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-03-01 00:17:09,335 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 4
2019-03-01 00:17:09,336 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 543
2019-03-01 00:17:09,369 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.3:8485: segmentState { startTxId: 543 endTxId: 543 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 540
10.10.1.2:8485: segmentState { startTxId: 543 endTxId: 543 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 540
10.10.1.5:8485: segmentState { startTxId: 543 endTxId: 543 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 540
2019-03-01 00:17:09,372 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.3:8485=segmentState {
  startTxId: 543
  endTxId: 543
  isInProgress: true
}
lastWriterEpoch: 3
lastCommittedTxId: 540

2019-03-01 00:17:09,409 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-03-01 00:17:09,451 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000542 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000542-0000000000000000542
2019-03-01 00:17:09,473 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-03-01 00:17:09,478 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7f87e6f4 expecting start txid #543
2019-03-01 00:17:09,478 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:17:09,480 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 543
2019-03-01 00:17:09,480 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 543
2019-03-01 00:17:09,490 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:17:09,490 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-03-01 00:17:09,491 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-03-01 00:17:09,491 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-03-01 00:17:09,492 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 544
2019-03-01 00:17:09,496 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 544
2019-03-01 00:17:09,722 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 34 
2019-03-01 00:17:09,738 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-03-01 00:17:09,744 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 6 milliseconds
name space=21
storage space=64424509440
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-03-01 00:17:09,752 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-03-01 00:17:09,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 160
2019-03-01 00:17:09,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-03-01 00:17:09,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-03-01 00:17:09,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-03-01 00:17:09,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-03-01 00:17:09,849 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 356 msec
2019-03-01 00:17:44,326 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-03-01 00:17:44,328 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at c220g2-011319.wisc.cloudlab.us/128.104.222.139
************************************************************/
2019-03-01 00:18:01,501 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = c220g2-011319.wisc.cloudlab.us/128.104.222.139
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-01T04:08Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-01 00:18:01,515 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-01 00:18:01,521 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-03-01 00:18:01,779 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-03-01 00:18:01,859 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-03-01 00:18:01,859 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-03-01 00:18:01,925 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-03-01 00:18:01,926 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-03-01 00:18:02,099 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-03-01 00:18:02,138 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-03-01 00:18:02,159 INFO org.eclipse.jetty.util.log: Logging initialized @1185ms
2019-03-01 00:18:02,268 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-01 00:18:02,287 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-03-01 00:18:02,302 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-01 00:18:02,306 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-03-01 00:18:02,306 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-01 00:18:02,306 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-01 00:18:02,341 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-03-01 00:18:02,341 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-03-01 00:18:02,352 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-03-01 00:18:02,353 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-03-01 00:18:02,403 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-01 00:18:02,404 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-01 00:18:02,513 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-03-01 00:18:02,536 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-03-01 00:18:02,536 INFO org.eclipse.jetty.server.Server: Started @1563ms
2019-03-01 00:18:02,993 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-03-01 00:18:03,059 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-03-01 00:18:03,076 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-03-01 00:18:03,078 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-03-01 00:18:03,081 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-03-01 00:18:03,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-03-01 00:18:03,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-03-01 00:18:03,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-03-01 00:18:03,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-03-01 00:18:03,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-03-01 00:18:03,130 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-01 00:18:03,141 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-03-01 00:18:03,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-03-01 00:18:03,146 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-03-01 00:18:03,146 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Mar 01 00:18:03
2019-03-01 00:18:03,148 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-03-01 00:18:03,148 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:18:03,149 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-03-01 00:18:03,149 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-03-01 00:18:03,284 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-03-01 00:18:03,291 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-03-01 00:18:03,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-03-01 00:18:03,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-03-01 00:18:03,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-03-01 00:18:03,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-03-01 00:18:03,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-03-01 00:18:03,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-03-01 00:18:03,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-03-01 00:18:03,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-03-01 00:18:03,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-03-01 00:18:03,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-03-01 00:18:03,355 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-03-01 00:18:03,355 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:18:03,355 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-03-01 00:18:03,355 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-03-01 00:18:03,429 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-03-01 00:18:03,429 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-03-01 00:18:03,429 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-03-01 00:18:03,429 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-03-01 00:18:03,435 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-03-01 00:18:03,437 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-03-01 00:18:03,441 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-03-01 00:18:03,441 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:18:03,441 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-03-01 00:18:03,441 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-03-01 00:18:03,467 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-03-01 00:18:03,468 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-03-01 00:18:03,468 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-03-01 00:18:03,471 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-03-01 00:18:03,471 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-03-01 00:18:03,473 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-03-01 00:18:03,473 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:18:03,473 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-03-01 00:18:03,473 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-03-01 00:18:03,523 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 34243@c220g2-011319.wisc.cloudlab.us
2019-03-01 00:18:04,995 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-03-01 00:18:05,068 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-03-01 00:18:05,070 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-03-01 00:18:05,100 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-03-01 00:18:05,100 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-03-01 00:18:05,104 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-03-01 00:18:05,105 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:18:05,108 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:18:05,108 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:18:05,255 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-03-01 00:18:05,255 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #542
2019-03-01 00:18:05,255 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:18:05,256 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:18:05,256 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:18:05,262 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:18:05,262 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a7288a3 expecting start txid #543
2019-03-01 00:18:05,262 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:18:05,262 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:18:05,262 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:18:05,271 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:18:05,271 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2974f221 expecting start txid #544
2019-03-01 00:18:05,271 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:18:05,271 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:18:05,271 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:18:05,278 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:18:05,279 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-03-01 00:18:05,279 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-03-01 00:18:05,279 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1799 msecs
2019-03-01 00:18:05,490 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-1-link-0:8020
2019-03-01 00:18:05,496 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-01 00:18:05,510 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-03-01 00:18:05,754 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-03-01 00:18:05,767 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-03-01 00:18:05,783 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 159 blocks to reach the threshold 0.9990 of total blocks 160.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-03-01 00:18:05,822 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-03-01 00:18:05,826 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-03-01 00:18:05,828 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-1-link-0/10.10.1.4:8020
2019-03-01 00:18:05,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-03-01 00:18:05,839 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-03-01 00:18:05,848 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-03-01 00:18:06,073 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=5a8d9380-9eaf-405f-b526-11106cb349b7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage 5a8d9380-9eaf-405f-b526-11106cb349b7
2019-03-01 00:18:06,074 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-03-01 00:18:06,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 5a8d9380-9eaf-405f-b526-11106cb349b7 (10.10.1.5:9866).
2019-03-01 00:18:06,092 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-c172e123-b020-451c-aa00-65bd69771af0 for DN 10.10.1.5:9866
2019-03-01 00:18:06,113 INFO BlockStateChange: BLOCK* processReport 0xffd07e1b704b4355: Processing first storage report for DS-c172e123-b020-451c-aa00-65bd69771af0 from datanode 5a8d9380-9eaf-405f-b526-11106cb349b7
2019-03-01 00:18:06,129 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 159 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 30 seconds.
2019-03-01 00:18:06,130 INFO BlockStateChange: BLOCK* processReport 0xffd07e1b704b4355: from storage DS-c172e123-b020-451c-aa00-65bd69771af0 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=5a8d9380-9eaf-405f-b526-11106cb349b7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 160, hasStaleStorage: false, processing time: 17 msecs, invalidatedBlocks: 0
2019-03-01 00:18:06,406 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=5992f680-a97f-467f-aa39-9017c671a8b8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage 5992f680-a97f-467f-aa39-9017c671a8b8
2019-03-01 00:18:06,406 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-03-01 00:18:06,406 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 5992f680-a97f-467f-aa39-9017c671a8b8 (10.10.1.2:9866).
2019-03-01 00:18:06,407 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e01372d1-0745-4c89-9fe7-e5d932e31fb6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage e01372d1-0745-4c89-9fe7-e5d932e31fb6
2019-03-01 00:18:06,407 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-03-01 00:18:06,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e01372d1-0745-4c89-9fe7-e5d932e31fb6 (10.10.1.3:9866).
2019-03-01 00:18:06,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 for DN 10.10.1.2:9866
2019-03-01 00:18:06,410 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 for DN 10.10.1.3:9866
2019-03-01 00:18:06,411 INFO BlockStateChange: BLOCK* processReport 0x127710ca93b30e4c: Processing first storage report for DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 from datanode 5992f680-a97f-467f-aa39-9017c671a8b8
2019-03-01 00:18:06,415 INFO BlockStateChange: BLOCK* processReport 0x127710ca93b30e4c: from storage DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=5992f680-a97f-467f-aa39-9017c671a8b8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 136, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2019-03-01 00:18:06,415 INFO BlockStateChange: BLOCK* processReport 0x4ae55c5c59e194ee: Processing first storage report for DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 from datanode e01372d1-0745-4c89-9fe7-e5d932e31fb6
2019-03-01 00:18:06,418 INFO BlockStateChange: BLOCK* processReport 0x4ae55c5c59e194ee: from storage DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e01372d1-0745-4c89-9fe7-e5d932e31fb6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 160, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2019-03-01 00:18:26,134 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 160 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-03-01 00:18:36,135 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2019-03-01 00:18:36,135 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 30 secs
2019-03-01 00:18:36,136 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2019-03-01 00:18:36,136 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-03-01 00:19:13,886 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-03-01 00:19:13,888 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-03-01 00:19:13,994 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-03-01 00:19:14,009 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-03-01 00:19:14,060 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 6
2019-03-01 00:19:14,060 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 545
2019-03-01 00:19:14,090 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.5:8485: segmentState { startTxId: 545 endTxId: 1105 isInProgress: true } lastWriterEpoch: 5 lastCommittedTxId: 1104
10.10.1.3:8485: segmentState { startTxId: 545 endTxId: 1105 isInProgress: true } lastWriterEpoch: 5 lastCommittedTxId: 1104
10.10.1.2:8485: segmentState { startTxId: 545 endTxId: 1105 isInProgress: true } lastWriterEpoch: 5 lastCommittedTxId: 1104
2019-03-01 00:19:14,093 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.5:8485=segmentState {
  startTxId: 545
  endTxId: 1105
  isInProgress: true
}
lastWriterEpoch: 5
lastCommittedTxId: 1104

2019-03-01 00:19:14,132 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-03-01 00:19:14,174 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000544 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000544-0000000000000000544
2019-03-01 00:19:14,201 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-03-01 00:19:14,206 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4ace4c04 expecting start txid #545
2019-03-01 00:19:14,206 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:19:14,208 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 545
2019-03-01 00:19:14,208 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 545
2019-03-01 00:19:14,295 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 561 loaded in 0 seconds
2019-03-01 00:19:14,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-03-01 00:19:14,296 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-03-01 00:19:14,296 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-03-01 00:19:14,297 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 1106
2019-03-01 00:19:14,300 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1106
2019-03-01 00:19:14,532 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 31 
2019-03-01 00:19:14,553 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-03-01 00:19:14,558 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 5 milliseconds
name space=21
storage space=64424509440
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-03-01 00:19:14,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-03-01 00:19:14,655 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 160
2019-03-01 00:19:14,655 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-03-01 00:19:14,655 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-03-01 00:19:14,655 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-03-01 00:19:14,655 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-03-01 00:19:14,655 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 358 msec
2019-03-01 00:19:49,302 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-03-01 00:19:49,304 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at c220g2-011319.wisc.cloudlab.us/128.104.222.139
************************************************************/
2019-03-01 00:20:06,555 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = c220g2-011319.wisc.cloudlab.us/128.104.222.139
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-01T04:08Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-01 00:20:06,570 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-01 00:20:06,576 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-03-01 00:20:06,890 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-03-01 00:20:07,021 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-03-01 00:20:07,021 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-03-01 00:20:07,095 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-03-01 00:20:07,095 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-03-01 00:20:07,267 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-03-01 00:20:07,305 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-03-01 00:20:07,327 INFO org.eclipse.jetty.util.log: Logging initialized @1353ms
2019-03-01 00:20:07,450 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-01 00:20:07,469 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-03-01 00:20:07,485 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-01 00:20:07,490 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-03-01 00:20:07,490 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-01 00:20:07,490 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-01 00:20:07,525 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-03-01 00:20:07,525 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-03-01 00:20:07,535 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-03-01 00:20:07,537 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-03-01 00:20:07,587 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-01 00:20:07,588 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-01 00:20:07,692 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-03-01 00:20:07,720 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-03-01 00:20:07,720 INFO org.eclipse.jetty.server.Server: Started @1748ms
2019-03-01 00:20:08,116 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-03-01 00:20:08,183 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-03-01 00:20:08,200 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-03-01 00:20:08,202 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-03-01 00:20:08,204 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-03-01 00:20:08,211 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-03-01 00:20:08,211 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-03-01 00:20:08,211 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-03-01 00:20:08,211 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-03-01 00:20:08,212 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-03-01 00:20:08,253 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-01 00:20:08,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-03-01 00:20:08,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-03-01 00:20:08,267 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-03-01 00:20:08,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Mar 01 00:20:08
2019-03-01 00:20:08,269 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-03-01 00:20:08,269 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:20:08,271 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-03-01 00:20:08,271 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-03-01 00:20:08,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-03-01 00:20:08,422 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-03-01 00:20:08,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-03-01 00:20:08,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-03-01 00:20:08,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-03-01 00:20:08,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-03-01 00:20:08,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-03-01 00:20:08,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-03-01 00:20:08,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-03-01 00:20:08,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-03-01 00:20:08,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-03-01 00:20:08,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-03-01 00:20:08,494 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-03-01 00:20:08,494 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:20:08,494 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-03-01 00:20:08,494 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-03-01 00:20:08,569 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-03-01 00:20:08,569 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-03-01 00:20:08,569 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-03-01 00:20:08,569 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-03-01 00:20:08,575 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-03-01 00:20:08,577 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-03-01 00:20:08,581 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-03-01 00:20:08,581 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:20:08,581 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-03-01 00:20:08,581 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-03-01 00:20:08,607 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-03-01 00:20:08,607 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-03-01 00:20:08,607 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-03-01 00:20:08,611 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-03-01 00:20:08,611 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-03-01 00:20:08,613 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-03-01 00:20:08,613 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:20:08,613 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-03-01 00:20:08,613 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-03-01 00:20:08,674 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 34567@c220g2-011319.wisc.cloudlab.us
2019-03-01 00:20:10,092 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-03-01 00:20:10,166 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-03-01 00:20:10,168 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-03-01 00:20:10,198 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-03-01 00:20:10,198 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-03-01 00:20:10,203 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-03-01 00:20:10,203 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:20:10,207 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:20:10,207 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:20:10,331 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-03-01 00:20:10,331 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #542
2019-03-01 00:20:10,331 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:20:10,331 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:20:10,331 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:20:10,336 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:20:10,337 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a7288a3 expecting start txid #543
2019-03-01 00:20:10,337 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:20:10,337 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:20:10,337 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:20:10,345 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:20:10,345 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2974f221 expecting start txid #544
2019-03-01 00:20:10,346 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:20:10,346 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:20:10,346 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:20:10,350 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:20:10,350 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@58fe0499 expecting start txid #545
2019-03-01 00:20:10,350 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:20:10,350 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:20:10,350 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:20:10,400 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 561 loaded in 0 seconds
2019-03-01 00:20:10,400 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@686449f9 expecting start txid #1106
2019-03-01 00:20:10,400 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:20:10,400 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:20:10,400 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:20:10,404 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:20:10,405 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-03-01 00:20:10,405 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-03-01 00:20:10,405 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1784 msecs
2019-03-01 00:20:10,589 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-1-link-0:8020
2019-03-01 00:20:10,595 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-01 00:20:10,608 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-03-01 00:20:10,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-03-01 00:20:10,818 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-03-01 00:20:10,832 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 159 blocks to reach the threshold 0.9990 of total blocks 160.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-03-01 00:20:10,857 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-03-01 00:20:10,857 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-03-01 00:20:10,862 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-1-link-0/10.10.1.4:8020
2019-03-01 00:20:10,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-03-01 00:20:10,874 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-03-01 00:20:10,883 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-03-01 00:20:11,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=5a8d9380-9eaf-405f-b526-11106cb349b7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage 5a8d9380-9eaf-405f-b526-11106cb349b7
2019-03-01 00:20:11,272 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-03-01 00:20:11,273 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 5a8d9380-9eaf-405f-b526-11106cb349b7 (10.10.1.5:9866).
2019-03-01 00:20:11,288 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-c172e123-b020-451c-aa00-65bd69771af0 for DN 10.10.1.5:9866
2019-03-01 00:20:11,308 INFO BlockStateChange: BLOCK* processReport 0xffd07e1b704b4356: Processing first storage report for DS-c172e123-b020-451c-aa00-65bd69771af0 from datanode 5a8d9380-9eaf-405f-b526-11106cb349b7
2019-03-01 00:20:11,321 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 159 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2019-03-01 00:20:11,322 INFO BlockStateChange: BLOCK* processReport 0xffd07e1b704b4356: from storage DS-c172e123-b020-451c-aa00-65bd69771af0 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=5a8d9380-9eaf-405f-b526-11106cb349b7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 160, hasStaleStorage: false, processing time: 14 msecs, invalidatedBlocks: 0
2019-03-01 00:20:11,437 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e01372d1-0745-4c89-9fe7-e5d932e31fb6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage e01372d1-0745-4c89-9fe7-e5d932e31fb6
2019-03-01 00:20:11,437 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-03-01 00:20:11,437 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e01372d1-0745-4c89-9fe7-e5d932e31fb6 (10.10.1.3:9866).
2019-03-01 00:20:11,438 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=5992f680-a97f-467f-aa39-9017c671a8b8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage 5992f680-a97f-467f-aa39-9017c671a8b8
2019-03-01 00:20:11,438 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-03-01 00:20:11,438 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 5992f680-a97f-467f-aa39-9017c671a8b8 (10.10.1.2:9866).
2019-03-01 00:20:11,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 for DN 10.10.1.3:9866
2019-03-01 00:20:11,441 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 for DN 10.10.1.2:9866
2019-03-01 00:20:11,442 INFO BlockStateChange: BLOCK* processReport 0x4ae55c5c59e194ef: Processing first storage report for DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 from datanode e01372d1-0745-4c89-9fe7-e5d932e31fb6
2019-03-01 00:20:11,445 INFO BlockStateChange: BLOCK* processReport 0x4ae55c5c59e194ef: from storage DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e01372d1-0745-4c89-9fe7-e5d932e31fb6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 160, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2019-03-01 00:20:11,446 INFO BlockStateChange: BLOCK* processReport 0x127710ca93b30e4d: Processing first storage report for DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 from datanode 5992f680-a97f-467f-aa39-9017c671a8b8
2019-03-01 00:20:11,448 INFO BlockStateChange: BLOCK* processReport 0x127710ca93b30e4d: from storage DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=5992f680-a97f-467f-aa39-9017c671a8b8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 160, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-03-01 00:20:31,325 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 160 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-03-01 00:20:41,327 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2019-03-01 00:20:41,327 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 30 secs
2019-03-01 00:20:41,328 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2019-03-01 00:20:41,328 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-03-01 00:21:19,312 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-03-01 00:21:19,313 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-03-01 00:21:19,419 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-03-01 00:21:19,432 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-03-01 00:21:19,480 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 8
2019-03-01 00:21:19,480 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 1107
2019-03-01 00:21:19,509 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.2:8485: segmentState { startTxId: 1107 endTxId: 1107 isInProgress: true } lastWriterEpoch: 7 lastCommittedTxId: 1104
10.10.1.5:8485: segmentState { startTxId: 1107 endTxId: 1107 isInProgress: true } lastWriterEpoch: 7 lastCommittedTxId: 1104
10.10.1.3:8485: segmentState { startTxId: 1107 endTxId: 1107 isInProgress: true } lastWriterEpoch: 7 lastCommittedTxId: 1104
2019-03-01 00:21:19,512 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.2:8485=segmentState {
  startTxId: 1107
  endTxId: 1107
  isInProgress: true
}
lastWriterEpoch: 7
lastCommittedTxId: 1104

2019-03-01 00:21:19,553 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-03-01 00:21:19,595 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000001106 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000001106-0000000000000001106
2019-03-01 00:21:19,616 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-03-01 00:21:19,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1b4ddb25 expecting start txid #1107
2019-03-01 00:21:19,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:21:19,623 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1107
2019-03-01 00:21:19,623 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1107
2019-03-01 00:21:19,632 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:21:19,633 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-03-01 00:21:19,634 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-03-01 00:21:19,634 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-03-01 00:21:19,634 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 1108
2019-03-01 00:21:19,639 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1108
2019-03-01 00:21:19,857 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 29 
2019-03-01 00:21:19,872 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-03-01 00:21:19,877 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 5 milliseconds
name space=21
storage space=64424509440
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-03-01 00:21:19,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-03-01 00:21:19,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 160
2019-03-01 00:21:19,967 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-03-01 00:21:19,967 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-03-01 00:21:19,967 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-03-01 00:21:19,967 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-03-01 00:21:19,967 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 332 msec
2019-03-01 00:21:40,602 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742145_1321, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-03-01 00:21:41,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742146_1322, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-03-01 00:21:41,515 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742147_1323, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-03-01 00:21:41,639 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742148_1324, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-03-01 00:21:41,931 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742149_1325, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-03-01 00:21:42,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742150_1326, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-03-01 00:21:42,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742151_1327, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-03-01 00:21:42,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742152_1328, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-03-01 00:21:42,872 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742153_1329, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-03-01 00:21:42,947 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742154_1330, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-03-01 00:21:43,009 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742155_1331, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-03-01 00:21:43,324 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742156_1332, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-03-01 00:21:43,402 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742157_1333, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-03-01 00:21:43,421 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742158_1334, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-03-01 00:21:43,782 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742159_1335, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-03-01 00:21:43,790 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742160_1336, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-03-01 00:21:43,880 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742161_1337, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-03-01 00:21:44,279 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742162_1338, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-03-01 00:21:44,372 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile15._COPYING_ is closed by DFSClient_NONMAPREDUCE_985495866_1
2019-03-01 00:21:44,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-03-01 00:21:44,473 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:44,473 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 2 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:44,474 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:44,474 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742163_1339, replicas=10.10.1.5:9866 for /myfile7._COPYING_
2019-03-01 00:21:44,739 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:44,739 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 2 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:44,740 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:44,740 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742164_1340, replicas=10.10.1.5:9866 for /myfile14._COPYING_
2019-03-01 00:21:44,821 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:44,821 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 2 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:44,821 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:44,821 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742165_1341, replicas=10.10.1.5:9866 for /myfile7._COPYING_
2019-03-01 00:21:45,067 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-03-01 00:21:45,067 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:45,067 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 2 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:45,067 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:45,067 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742166_1342, replicas=10.10.1.5:9866 for /myfile14._COPYING_
2019-03-01 00:21:45,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-03-01 00:21:45,108 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:45,108 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 2 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:45,108 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:45,108 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742167_1343, replicas=10.10.1.5:9866 for /myfile7._COPYING_
2019-03-01 00:21:45,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-03-01 00:21:45,384 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:45,384 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 2 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:45,385 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:45,385 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742168_1344, replicas=10.10.1.5:9866 for /myfile14._COPYING_
2019-03-01 00:21:45,421 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile7._COPYING_ is closed by DFSClient_NONMAPREDUCE_1901116552_1
2019-03-01 00:21:45,646 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile14._COPYING_ is closed by DFSClient_NONMAPREDUCE_231547874_1
2019-03-01 00:21:47,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=2}
2019-03-01 00:21:47,002 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:47,003 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:47,003 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 2 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:47,003 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:47,003 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=2}
2019-03-01 00:21:47,004 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:47,004 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:47,004 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 2 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:47,004 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:47,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=2}
2019-03-01 00:21:47,005 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:47,005 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:47,005 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 2 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:47,006 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:47,006 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=2}
2019-03-01 00:21:47,006 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:47,007 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:47,007 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 2 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:47,007 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 2 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:53,009 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:53,009 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:53,009 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:53,010 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:53,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-03-01 00:21:53,010 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:53,011 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:53,011 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:53,011 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:53,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-03-01 00:21:53,012 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:53,012 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:53,012 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:53,012 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:53,013 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-03-01 00:21:53,013 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:53,013 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:53,013 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:53,013 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:53,370 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-03-01 00:21:53,370 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:53,371 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:53,371 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:53,371 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742169_1345, replicas=10.10.1.5:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-03-01 00:21:53,608 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-03-01 00:21:53,609 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:53,609 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:53,609 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:53,609 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742170_1346, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-03-01 00:21:53,938 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:53,938 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:53,939 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:53,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742171_1347, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-03-01 00:21:54,149 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-03-01 00:21:54,149 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-03-01 00:21:54,149 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-03-01 00:21:54,150 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742172_1348, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-03-01 00:21:54,260 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-03-01 00:21:54,263 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at c220g2-011319.wisc.cloudlab.us/128.104.222.139
************************************************************/
2019-03-01 00:22:11,483 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = c220g2-011319.wisc.cloudlab.us/128.104.222.139
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-01T04:08Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-01 00:22:11,497 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-01 00:22:11,504 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-03-01 00:22:11,844 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-03-01 00:22:12,001 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-03-01 00:22:12,001 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-03-01 00:22:12,080 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-03-01 00:22:12,080 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-03-01 00:22:12,214 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-03-01 00:22:12,252 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-03-01 00:22:12,273 INFO org.eclipse.jetty.util.log: Logging initialized @1332ms
2019-03-01 00:22:12,380 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-01 00:22:12,398 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-03-01 00:22:12,413 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-01 00:22:12,418 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-03-01 00:22:12,418 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-01 00:22:12,418 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-01 00:22:12,452 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-03-01 00:22:12,453 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-03-01 00:22:12,463 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-03-01 00:22:12,465 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-03-01 00:22:12,512 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-01 00:22:12,513 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-01 00:22:12,608 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-03-01 00:22:12,631 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-03-01 00:22:12,631 INFO org.eclipse.jetty.server.Server: Started @1692ms
2019-03-01 00:22:13,025 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-03-01 00:22:13,065 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-03-01 00:22:13,077 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-03-01 00:22:13,078 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-03-01 00:22:13,080 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-03-01 00:22:13,085 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-03-01 00:22:13,085 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-03-01 00:22:13,085 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-03-01 00:22:13,085 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-03-01 00:22:13,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-03-01 00:22:13,119 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-01 00:22:13,129 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-03-01 00:22:13,129 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-03-01 00:22:13,133 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-03-01 00:22:13,133 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Mar 01 00:22:13
2019-03-01 00:22:13,135 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-03-01 00:22:13,135 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:22:13,136 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-03-01 00:22:13,136 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-03-01 00:22:13,272 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-03-01 00:22:13,285 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-03-01 00:22:13,285 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-03-01 00:22:13,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-03-01 00:22:13,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-03-01 00:22:13,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-03-01 00:22:13,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-03-01 00:22:13,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-03-01 00:22:13,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-03-01 00:22:13,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-03-01 00:22:13,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-03-01 00:22:13,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-03-01 00:22:13,386 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-03-01 00:22:13,386 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:22:13,387 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-03-01 00:22:13,387 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-03-01 00:22:13,470 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-03-01 00:22:13,470 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-03-01 00:22:13,470 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-03-01 00:22:13,470 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-03-01 00:22:13,476 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-03-01 00:22:13,478 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-03-01 00:22:13,482 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-03-01 00:22:13,482 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:22:13,482 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-03-01 00:22:13,483 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-03-01 00:22:13,509 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-03-01 00:22:13,509 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-03-01 00:22:13,509 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-03-01 00:22:13,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-03-01 00:22:13,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-03-01 00:22:13,514 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-03-01 00:22:13,514 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-03-01 00:22:13,514 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-03-01 00:22:13,514 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-03-01 00:22:13,586 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 34897@c220g2-011319.wisc.cloudlab.us
2019-03-01 00:22:15,006 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-03-01 00:22:15,077 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-03-01 00:22:15,079 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-03-01 00:22:15,107 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-03-01 00:22:15,107 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-03-01 00:22:15,114 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-03-01 00:22:15,114 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:22:15,120 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,120 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,275 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-03-01 00:22:15,275 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #542
2019-03-01 00:22:15,275 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:22:15,275 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,276 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,280 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:22:15,280 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a7288a3 expecting start txid #543
2019-03-01 00:22:15,281 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:22:15,281 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,281 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,287 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:22:15,288 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2974f221 expecting start txid #544
2019-03-01 00:22:15,288 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:22:15,288 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,288 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,293 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=544&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:22:15,293 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@58fe0499 expecting start txid #545
2019-03-01 00:22:15,293 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:22:15,293 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,293 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,344 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 561 loaded in 0 seconds
2019-03-01 00:22:15,344 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@686449f9 expecting start txid #1106
2019-03-01 00:22:15,344 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:22:15,344 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,344 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,349 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1106&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:22:15,349 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@665df3c6 expecting start txid #1107
2019-03-01 00:22:15,349 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:22:15,349 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,349 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,353 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-01 00:22:15,354 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68b6f0d6 expecting start txid #1108
2019-03-01 00:22:15,354 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1108&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1108&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1108&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-01 00:22:15,354 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1108&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1108&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1108&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,354 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1108&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true' to transaction ID 1
2019-03-01 00:22:15,365 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1108&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1108&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1108&storageInfo=-64%3A2096054662%3A1551424402956%3ACID-9dd62186-9d1d-474e-b762-1cada747e3c9&inProgressOk=true of size 1048576 edits # 110 loaded in 0 seconds
2019-03-01 00:22:15,366 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-03-01 00:22:15,366 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-03-01 00:22:15,366 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1844 msecs
2019-03-01 00:22:15,536 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-1-link-0:8020
2019-03-01 00:22:15,540 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-01 00:22:15,548 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-03-01 00:22:15,740 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-03-01 00:22:15,750 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 2
2019-03-01 00:22:15,759 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 73 blocks to reach the threshold 0.9990 of total blocks 74.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-03-01 00:22:15,781 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-03-01 00:22:15,781 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-03-01 00:22:15,787 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-1-link-0/10.10.1.4:8020
2019-03-01 00:22:15,790 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-03-01 00:22:15,795 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-03-01 00:22:15,800 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-03-01 00:22:16,041 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e01372d1-0745-4c89-9fe7-e5d932e31fb6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage e01372d1-0745-4c89-9fe7-e5d932e31fb6
2019-03-01 00:22:16,042 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-03-01 00:22:16,043 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e01372d1-0745-4c89-9fe7-e5d932e31fb6 (10.10.1.3:9866).
2019-03-01 00:22:16,045 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=5a8d9380-9eaf-405f-b526-11106cb349b7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage 5a8d9380-9eaf-405f-b526-11106cb349b7
2019-03-01 00:22:16,045 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-03-01 00:22:16,045 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 5a8d9380-9eaf-405f-b526-11106cb349b7 (10.10.1.5:9866).
2019-03-01 00:22:16,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 for DN 10.10.1.3:9866
2019-03-01 00:22:16,065 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-c172e123-b020-451c-aa00-65bd69771af0 for DN 10.10.1.5:9866
2019-03-01 00:22:16,083 INFO BlockStateChange: BLOCK* processReport 0xffd07e1b704b4357: Processing first storage report for DS-c172e123-b020-451c-aa00-65bd69771af0 from datanode 5a8d9380-9eaf-405f-b526-11106cb349b7
2019-03-01 00:22:16,094 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 73 has reached the threshold 0.9990 of total blocks 74. The number of live datanodes 2 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2019-03-01 00:22:16,094 INFO BlockStateChange: BLOCK* processReport 0xffd07e1b704b4357: from storage DS-c172e123-b020-451c-aa00-65bd69771af0 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=5a8d9380-9eaf-405f-b526-11106cb349b7, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 84, hasStaleStorage: false, processing time: 11 msecs, invalidatedBlocks: 0
2019-03-01 00:22:16,095 INFO BlockStateChange: BLOCK* processReport 0x4ae55c5c59e194f0: Processing first storage report for DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 from datanode e01372d1-0745-4c89-9fe7-e5d932e31fb6
2019-03-01 00:22:16,099 INFO BlockStateChange: BLOCK* processReport 0x4ae55c5c59e194f0: from storage DS-3029cdbc-e9e6-4964-b6dc-947d2c2e4a13 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e01372d1-0745-4c89-9fe7-e5d932e31fb6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 157, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2019-03-01 00:22:16,468 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=5992f680-a97f-467f-aa39-9017c671a8b8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956) storage 5992f680-a97f-467f-aa39-9017c671a8b8
2019-03-01 00:22:16,468 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-03-01 00:22:16,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 5992f680-a97f-467f-aa39-9017c671a8b8 (10.10.1.2:9866).
2019-03-01 00:22:16,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 for DN 10.10.1.2:9866
2019-03-01 00:22:16,473 INFO BlockStateChange: BLOCK* processReport 0x127710ca93b30e4e: Processing first storage report for DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 from datanode 5992f680-a97f-467f-aa39-9017c671a8b8
2019-03-01 00:22:16,474 INFO BlockStateChange: BLOCK* processReport 0x127710ca93b30e4e: from storage DS-5a66c6b8-2e61-4f72-aea4-b7c6e0be7d07 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=5992f680-a97f-467f-aa39-9017c671a8b8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-9dd62186-9d1d-474e-b762-1cada747e3c9;nsid=2096054662;c=1551424402956), blocks: 77, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-03-01 00:22:36,098 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 74 has reached the threshold 0.9990 of total blocks 74. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-03-01 00:22:46,100 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2019-03-01 00:22:46,100 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 30 secs
2019-03-01 00:22:46,100 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2019-03-01 00:22:46,100 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
