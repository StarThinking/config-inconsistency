2019-02-20 18:14:54,867 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode050.clemson.cloudlab.us/130.127.133.59
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-17T02:52Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-20 18:14:54,876 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 18:14:54,881 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-20 18:14:55,168 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 18:14:55,274 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 18:14:55,274 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-20 18:14:55,325 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-20 18:14:55,326 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-20 18:14:55,489 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 18:14:55,516 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-20 18:14:55,534 INFO org.eclipse.jetty.util.log: Logging initialized @1183ms
2019-02-20 18:14:55,641 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 18:14:55,654 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-20 18:14:55,665 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 18:14:55,668 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-20 18:14:55,668 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 18:14:55,668 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 18:14:55,695 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-20 18:14:55,695 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-20 18:14:55,704 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-20 18:14:55,705 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-20 18:14:55,741 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-20 18:14:55,741 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-20 18:14:55,815 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-20 18:14:55,836 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-20 18:14:55,836 INFO org.eclipse.jetty.server.Server: Started @1487ms
2019-02-20 18:14:56,165 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-20 18:14:56,216 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-20 18:14:56,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-20 18:14:56,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-20 18:14:56,235 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-20 18:14:56,241 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-20 18:14:56,241 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-20 18:14:56,241 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-20 18:14:56,242 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-20 18:14:56,242 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-20 18:14:56,284 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-20 18:14:56,297 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-20 18:14:56,297 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-20 18:14:56,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-20 18:14:56,302 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 20 18:14:56
2019-02-20 18:14:56,304 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-20 18:14:56,304 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:14:56,305 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-20 18:14:56,306 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-20 18:14:56,448 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-20 18:14:56,457 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-20 18:14:56,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-20 18:14:56,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-20 18:14:56,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-20 18:14:56,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-20 18:14:56,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-20 18:14:56,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-20 18:14:56,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-20 18:14:56,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-20 18:14:56,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-20 18:14:56,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-20 18:14:56,542 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-20 18:14:56,542 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:14:56,542 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-20 18:14:56,542 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-20 18:14:56,615 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-20 18:14:56,615 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-20 18:14:56,615 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-20 18:14:56,615 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-20 18:14:56,622 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-20 18:14:56,625 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-20 18:14:56,630 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-20 18:14:56,630 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:14:56,630 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-20 18:14:56,630 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-20 18:14:56,658 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-20 18:14:56,658 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-20 18:14:56,658 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-20 18:14:56,662 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-20 18:14:56,662 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-20 18:14:56,664 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-20 18:14:56,664 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:14:56,665 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-20 18:14:56,665 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-20 18:14:56,727 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 65074@clnode050.clemson.cloudlab.us
2019-02-20 18:14:58,129 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1136ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=328ms
GC pool 'PS Scavenge' had collection(s): count=1 time=951ms
2019-02-20 18:14:58,289 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2019-02-20 18:14:58,289 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-20 18:14:58,352 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-20 18:14:58,355 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-20 18:14:58,386 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-20 18:14:58,386 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-20 18:14:58,391 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-20 18:14:58,392 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-20 18:14:58,392 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1719 msecs
2019-02-20 18:14:58,576 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-20 18:14:58,581 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 18:14:58,594 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-20 18:14:58,781 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-20 18:14:58,789 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-20 18:14:58,799 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2019-02-20 18:14:58,799 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2019-02-20 18:14:58,800 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-20 18:14:58,834 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-20 18:14:58,834 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-20 18:14:58,837 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-20 18:14:58,839 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-20 18:14:58,844 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-20 18:14:58,850 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-20 18:15:03,821 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, fileSize: 389. Sent total: 389 bytes. Size of last segment intended to send: -1 bytes.
2019-02-20 18:15:03,987 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-20 18:15:03,989 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode050.clemson.cloudlab.us/130.127.133.59
************************************************************/
2019-02-20 18:15:14,707 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode050.clemson.cloudlab.us/130.127.133.59
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-17T02:52Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-20 18:15:14,717 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 18:15:14,722 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-20 18:15:15,006 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 18:15:15,116 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 18:15:15,116 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-20 18:15:15,169 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-20 18:15:15,169 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-20 18:15:15,331 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 18:15:15,359 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-20 18:15:15,376 INFO org.eclipse.jetty.util.log: Logging initialized @1182ms
2019-02-20 18:15:15,483 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 18:15:15,498 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-20 18:15:15,509 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 18:15:15,512 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-20 18:15:15,512 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 18:15:15,512 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 18:15:15,539 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-20 18:15:15,539 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-20 18:15:15,548 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-20 18:15:15,550 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-20 18:15:15,586 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-20 18:15:15,586 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-20 18:15:15,661 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-20 18:15:15,684 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-20 18:15:15,684 INFO org.eclipse.jetty.server.Server: Started @1492ms
2019-02-20 18:15:16,041 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-20 18:15:16,091 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-20 18:15:16,105 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-20 18:15:16,107 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-20 18:15:16,110 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-20 18:15:16,116 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-20 18:15:16,116 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-20 18:15:16,116 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-20 18:15:16,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-20 18:15:16,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-20 18:15:16,160 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-20 18:15:16,172 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-20 18:15:16,172 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-20 18:15:16,177 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-20 18:15:16,177 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 20 18:15:16
2019-02-20 18:15:16,179 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-20 18:15:16,179 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:15:16,181 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-20 18:15:16,181 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-20 18:15:16,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-20 18:15:16,325 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-20 18:15:16,325 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-20 18:15:16,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-20 18:15:16,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-20 18:15:16,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-20 18:15:16,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-20 18:15:16,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-20 18:15:16,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-20 18:15:16,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-20 18:15:16,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-20 18:15:16,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-20 18:15:16,411 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-20 18:15:16,411 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:15:16,411 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-20 18:15:16,411 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-20 18:15:16,484 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-20 18:15:16,484 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-20 18:15:16,484 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-20 18:15:16,484 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-20 18:15:16,491 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-20 18:15:16,494 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-20 18:15:16,499 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-20 18:15:16,500 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:15:16,500 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-20 18:15:16,500 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-20 18:15:16,527 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-20 18:15:16,527 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-20 18:15:16,528 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-20 18:15:16,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-20 18:15:16,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-20 18:15:16,534 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-20 18:15:16,534 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:15:16,534 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-20 18:15:16,535 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-20 18:15:16,599 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 65758@clnode050.clemson.cloudlab.us
2019-02-20 18:15:18,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:18,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:18,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:19,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:19,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:19,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:20,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:20,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:20,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:21,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:21,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:21,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:22,705 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-02-20 18:15:22,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:22,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:22,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-20 18:15:23,532 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2019-02-20 18:15:23,532 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-20 18:15:23,595 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-20 18:15:23,597 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-20 18:15:23,628 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-20 18:15:23,628 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-20 18:15:23,633 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-20 18:15:23,633 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-20 18:15:23,634 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 7091 msecs
2019-02-20 18:15:23,815 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-20 18:15:23,820 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 18:15:23,832 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-20 18:15:24,021 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-20 18:15:24,030 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-20 18:15:24,040 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2019-02-20 18:15:24,040 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2019-02-20 18:15:24,040 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-20 18:15:24,074 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-20 18:15:24,074 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-20 18:15:24,076 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-20 18:15:24,079 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-20 18:15:24,084 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-20 18:15:24,090 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-20 18:15:24,787 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=51d461cb-7c6e-476d-ab0f-839504cf72ad, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage 51d461cb-7c6e-476d-ab0f-839504cf72ad
2019-02-20 18:15:24,789 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-20 18:15:24,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 51d461cb-7c6e-476d-ab0f-839504cf72ad (10.10.1.3:9866).
2019-02-20 18:15:24,792 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=0d0a0955-6b8a-4f32-9438-2d3b39b35dab, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage 0d0a0955-6b8a-4f32-9438-2d3b39b35dab
2019-02-20 18:15:24,792 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-20 18:15:24,793 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 0d0a0955-6b8a-4f32-9438-2d3b39b35dab (10.10.1.2:9866).
2019-02-20 18:15:25,382 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=ba18f7c4-135d-4cb1-9251-cc80bd21778d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage ba18f7c4-135d-4cb1-9251-cc80bd21778d
2019-02-20 18:15:25,382 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-20 18:15:25,383 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN ba18f7c4-135d-4cb1-9251-cc80bd21778d (10.10.1.5:9866).
2019-02-20 18:15:25,385 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 for DN 10.10.1.3:9866
2019-02-20 18:15:25,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 for DN 10.10.1.5:9866
2019-02-20 18:15:25,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-39048a22-e14f-4fa4-91cf-2b951903fd70 for DN 10.10.1.2:9866
2019-02-20 18:15:25,413 INFO BlockStateChange: BLOCK* processReport 0x164dadc5045cc475: Processing first storage report for DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 from datanode ba18f7c4-135d-4cb1-9251-cc80bd21778d
2019-02-20 18:15:25,415 INFO BlockStateChange: BLOCK* processReport 0x164dadc5045cc475: from storage DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=ba18f7c4-135d-4cb1-9251-cc80bd21778d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-02-20 18:15:25,415 INFO BlockStateChange: BLOCK* processReport 0x5a55ea3f5c705f0f: Processing first storage report for DS-39048a22-e14f-4fa4-91cf-2b951903fd70 from datanode 0d0a0955-6b8a-4f32-9438-2d3b39b35dab
2019-02-20 18:15:25,415 INFO BlockStateChange: BLOCK* processReport 0x5a55ea3f5c705f0f: from storage DS-39048a22-e14f-4fa4-91cf-2b951903fd70 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=0d0a0955-6b8a-4f32-9438-2d3b39b35dab, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-02-20 18:15:25,415 INFO BlockStateChange: BLOCK* processReport 0xdf1a5e81ee885bac: Processing first storage report for DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 from datanode 51d461cb-7c6e-476d-ab0f-839504cf72ad
2019-02-20 18:15:25,415 INFO BlockStateChange: BLOCK* processReport 0xdf1a5e81ee885bac: from storage DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=51d461cb-7c6e-476d-ab0f-839504cf72ad, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-20 18:16:32,565 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-02-20 18:16:32,566 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-02-20 18:16:32,669 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-20 18:16:32,677 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-02-20 18:16:32,755 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 2
2019-02-20 18:16:32,756 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 1
2019-02-20 18:16:32,788 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.2:8485: segmentState { startTxId: 1 endTxId: 490 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 483
10.10.1.5:8485: segmentState { startTxId: 1 endTxId: 490 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 483
2019-02-20 18:16:32,791 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.2:8485=segmentState {
  startTxId: 1
  endTxId: 490
  isInProgress: true
}
lastWriterEpoch: 1
lastCommittedTxId: 483

2019-02-20 18:16:32,871 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-02-20 18:16:32,872 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-02-20 18:16:32,887 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2195185c expecting start txid #1
2019-02-20 18:16:32,887 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:16:32,890 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:16:32,890 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:16:33,140 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 490 loaded in 0 seconds
2019-02-20 18:16:33,140 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-02-20 18:16:33,141 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-02-20 18:16:33,141 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-20 18:16:33,141 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 491
2019-02-20 18:16:33,145 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 491
2019-02-20 18:16:33,402 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 58 
2019-02-20 18:16:33,419 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-20 18:16:33,423 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 3 milliseconds
name space=21
storage space=62411243520
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-02-20 18:16:33,429 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-20 18:16:33,492 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 155
2019-02-20 18:16:33,492 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-20 18:16:33,492 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-20 18:16:33,492 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-20 18:16:33,492 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 18
2019-02-20 18:16:33,492 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 351 msec
2019-02-20 18:16:33,666 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile7._COPYING_ is closed by DFSClient_NONMAPREDUCE_184612310_1
2019-02-20 18:16:33,736 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_894774860_1
2019-02-20 18:16:33,843 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile12._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1221532739_1
2019-02-20 18:16:33,845 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile8._COPYING_ is closed by DFSClient_NONMAPREDUCE_1363062052_1
2019-02-20 18:16:33,884 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_79583644_1
2019-02-20 18:16:33,896 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile17._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1624297485_1
2019-02-20 18:16:33,910 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741980_1156, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-20 18:16:33,912 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile10._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1015527056_1
2019-02-20 18:16:33,919 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile13._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1207616443_1
2019-02-20 18:16:33,934 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_-160642001_1
2019-02-20 18:16:33,936 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2584168_1
2019-02-20 18:16:33,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741981_1157, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile19._COPYING_
2019-02-20 18:16:33,943 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile15._COPYING_ is closed by DFSClient_NONMAPREDUCE_92226919_1
2019-02-20 18:16:33,944 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741982_1158, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-20 18:16:33,944 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741983_1159, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-20 18:16:33,947 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile18._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1592334761_1
2019-02-20 18:16:33,975 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741984_1160, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-20 18:16:34,064 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile11._COPYING_ is closed by DFSClient_NONMAPREDUCE_572163689_1
2019-02-20 18:16:35,820 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile20._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1157450396_1
2019-02-20 18:16:35,821 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile19._COPYING_ is closed by DFSClient_NONMAPREDUCE_583427484_1
2019-02-20 18:16:35,821 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile6._COPYING_ is closed by DFSClient_NONMAPREDUCE_962750808_1
2019-02-20 18:16:35,822 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile16._COPYING_ is closed by DFSClient_NONMAPREDUCE_91628354_1
2019-02-20 18:16:35,822 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile14._COPYING_ is closed by DFSClient_NONMAPREDUCE_1345271944_1
2019-02-20 18:17:06,885 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-20 18:17:06,887 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode050.clemson.cloudlab.us/130.127.133.59
************************************************************/
2019-02-20 18:17:23,920 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode050.clemson.cloudlab.us/130.127.133.59
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-17T02:52Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-20 18:17:23,930 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 18:17:23,935 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-20 18:17:24,224 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 18:17:24,337 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 18:17:24,337 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-20 18:17:24,390 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-20 18:17:24,391 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-20 18:17:24,557 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 18:17:24,584 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-20 18:17:24,602 INFO org.eclipse.jetty.util.log: Logging initialized @1193ms
2019-02-20 18:17:24,710 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 18:17:24,725 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-20 18:17:24,735 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 18:17:24,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-20 18:17:24,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 18:17:24,739 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 18:17:24,765 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-20 18:17:24,765 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-20 18:17:24,774 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-20 18:17:24,776 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-20 18:17:24,812 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-20 18:17:24,812 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-20 18:17:24,888 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-20 18:17:24,909 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@76fc6a34{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-20 18:17:24,909 INFO org.eclipse.jetty.server.Server: Started @1502ms
2019-02-20 18:17:25,249 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-20 18:17:25,301 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-20 18:17:25,315 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-20 18:17:25,317 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-20 18:17:25,320 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-20 18:17:25,326 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-20 18:17:25,326 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-20 18:17:25,326 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-20 18:17:25,327 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-20 18:17:25,327 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-20 18:17:25,370 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-20 18:17:25,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-20 18:17:25,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-20 18:17:25,387 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-20 18:17:25,387 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 20 18:17:25
2019-02-20 18:17:25,389 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-20 18:17:25,389 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:17:25,391 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-20 18:17:25,391 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-20 18:17:25,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-20 18:17:25,536 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-20 18:17:25,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-20 18:17:25,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-20 18:17:25,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-20 18:17:25,537 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-20 18:17:25,537 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-20 18:17:25,537 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-20 18:17:25,537 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-20 18:17:25,537 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-20 18:17:25,537 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-20 18:17:25,537 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-20 18:17:25,621 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-20 18:17:25,621 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:17:25,621 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-20 18:17:25,621 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-20 18:17:25,696 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-20 18:17:25,696 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-20 18:17:25,696 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-20 18:17:25,696 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-20 18:17:25,703 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-20 18:17:25,706 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-20 18:17:25,711 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-20 18:17:25,711 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:17:25,712 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-20 18:17:25,712 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-20 18:17:25,739 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-20 18:17:25,739 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-20 18:17:25,739 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-20 18:17:25,744 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-20 18:17:25,744 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-20 18:17:25,746 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-20 18:17:25,746 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:17:25,746 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-20 18:17:25,746 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-20 18:17:25,829 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 67143@clnode050.clemson.cloudlab.us
2019-02-20 18:17:27,278 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1217ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=348ms
GC pool 'PS Scavenge' had collection(s): count=1 time=977ms
2019-02-20 18:17:27,445 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-20 18:17:27,508 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-20 18:17:27,510 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-20 18:17:27,543 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-20 18:17:27,543 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-20 18:17:27,548 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-02-20 18:17:27,548 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:17:27,552 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:17:27,552 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:17:27,664 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 490 loaded in 0 seconds
2019-02-20 18:17:27,664 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #491
2019-02-20 18:17:27,664 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:17:27,664 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:17:27,664 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:17:27,677 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 52 loaded in 0 seconds
2019-02-20 18:17:27,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-20 18:17:27,678 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-20 18:17:27,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1923 msecs
2019-02-20 18:17:27,866 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-20 18:17:27,871 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 18:17:27,883 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-20 18:17:28,070 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-20 18:17:28,079 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-20 18:17:28,090 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 159 blocks to reach the threshold 0.9990 of total blocks 160.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-02-20 18:17:28,130 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-20 18:17:28,131 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-20 18:17:28,134 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-20 18:17:28,137 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-20 18:17:28,142 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-20 18:17:28,148 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-20 18:17:28,600 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=ba18f7c4-135d-4cb1-9251-cc80bd21778d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage ba18f7c4-135d-4cb1-9251-cc80bd21778d
2019-02-20 18:17:28,602 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-20 18:17:28,602 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN ba18f7c4-135d-4cb1-9251-cc80bd21778d (10.10.1.5:9866).
2019-02-20 18:17:28,614 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 for DN 10.10.1.5:9866
2019-02-20 18:17:28,630 INFO BlockStateChange: BLOCK* processReport 0x164dadc5045cc476: Processing first storage report for DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 from datanode ba18f7c4-135d-4cb1-9251-cc80bd21778d
2019-02-20 18:17:28,641 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 159 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 30 seconds.
2019-02-20 18:17:28,641 INFO BlockStateChange: BLOCK* processReport 0x164dadc5045cc476: from storage DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=ba18f7c4-135d-4cb1-9251-cc80bd21778d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 160, hasStaleStorage: false, processing time: 11 msecs, invalidatedBlocks: 0
2019-02-20 18:17:28,821 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=51d461cb-7c6e-476d-ab0f-839504cf72ad, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage 51d461cb-7c6e-476d-ab0f-839504cf72ad
2019-02-20 18:17:28,821 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-20 18:17:28,821 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 51d461cb-7c6e-476d-ab0f-839504cf72ad (10.10.1.3:9866).
2019-02-20 18:17:28,823 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 for DN 10.10.1.3:9866
2019-02-20 18:17:28,825 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=0d0a0955-6b8a-4f32-9438-2d3b39b35dab, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage 0d0a0955-6b8a-4f32-9438-2d3b39b35dab
2019-02-20 18:17:28,825 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-20 18:17:28,825 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 0d0a0955-6b8a-4f32-9438-2d3b39b35dab (10.10.1.2:9866).
2019-02-20 18:17:28,826 INFO BlockStateChange: BLOCK* processReport 0xdf1a5e81ee885bad: Processing first storage report for DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 from datanode 51d461cb-7c6e-476d-ab0f-839504cf72ad
2019-02-20 18:17:28,829 INFO BlockStateChange: BLOCK* processReport 0xdf1a5e81ee885bad: from storage DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=51d461cb-7c6e-476d-ab0f-839504cf72ad, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 160, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2019-02-20 18:17:28,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-39048a22-e14f-4fa4-91cf-2b951903fd70 for DN 10.10.1.2:9866
2019-02-20 18:17:28,831 INFO BlockStateChange: BLOCK* processReport 0x5a55ea3f5c705f10: Processing first storage report for DS-39048a22-e14f-4fa4-91cf-2b951903fd70 from datanode 0d0a0955-6b8a-4f32-9438-2d3b39b35dab
2019-02-20 18:17:28,834 INFO BlockStateChange: BLOCK* processReport 0x5a55ea3f5c705f10: from storage DS-39048a22-e14f-4fa4-91cf-2b951903fd70 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=0d0a0955-6b8a-4f32-9438-2d3b39b35dab, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 160, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-02-20 18:17:48,644 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 160 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-02-20 18:17:58,644 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2019-02-20 18:17:58,645 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 30 secs
2019-02-20 18:17:58,645 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2019-02-20 18:17:58,645 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-20 18:19:28,162 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:19:28,400 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2d61bef8 expecting start txid #543
2019-02-20 18:19:28,400 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:19:28,401 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 543
2019-02-20 18:19:28,401 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 543
2019-02-20 18:19:28,484 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 42 edits # 2 loaded in 0 seconds
2019-02-20 18:21:28,491 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:21:28,684 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@755209f8 expecting start txid #545
2019-02-20 18:21:28,684 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:21:28,684 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 545
2019-02-20 18:21:28,684 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 545
2019-02-20 18:21:28,706 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 3598 edits # 38 loaded in 0 seconds
2019-02-20 18:23:28,714 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:23:28,911 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@ce0077d expecting start txid #583
2019-02-20 18:23:28,912 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:23:28,912 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 583
2019-02-20 18:23:28,912 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 583
2019-02-20 18:23:28,925 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 5046 edits # 48 loaded in 0 seconds
2019-02-20 18:25:28,931 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:25:29,104 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6b65f54a expecting start txid #631
2019-02-20 18:25:29,104 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:25:29,104 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 631
2019-02-20 18:25:29,104 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 631
2019-02-20 18:25:29,114 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 4106 edits # 36 loaded in 0 seconds
2019-02-20 18:27:29,121 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:27:29,282 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5c644952 expecting start txid #667
2019-02-20 18:27:29,282 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:27:29,282 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 667
2019-02-20 18:27:29,282 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 667
2019-02-20 18:27:29,290 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 3148 edits # 28 loaded in 0 seconds
2019-02-20 18:27:36,049 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-02-20 18:27:36,050 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-02-20 18:27:36,053 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-20 18:27:36,063 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-02-20 18:27:36,105 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 4
2019-02-20 18:27:36,105 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 695
2019-02-20 18:27:36,129 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.5:8485: segmentState { startTxId: 695 endTxId: 695 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 694
10.10.1.3:8485: segmentState { startTxId: 695 endTxId: 695 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 694
2019-02-20 18:27:36,131 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.5:8485=segmentState {
  startTxId: 695
  endTxId: 695
  isInProgress: true
}
lastWriterEpoch: 3
lastCommittedTxId: 694

2019-02-20 18:27:36,169 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-02-20 18:27:36,198 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000491 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000491-0000000000000000542
2019-02-20 18:27:36,216 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-02-20 18:27:36,220 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@21e000fc expecting start txid #695
2019-02-20 18:27:36,220 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:27:36,220 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 695
2019-02-20 18:27:36,220 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 695
2019-02-20 18:27:36,228 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-20 18:27:36,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-02-20 18:27:36,228 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-02-20 18:27:36,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-20 18:27:36,229 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 696
2019-02-20 18:27:36,232 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 696
2019-02-20 18:27:36,495 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 67 
2019-02-20 18:27:36,522 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-20 18:27:36,526 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-02-20 18:27:36,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2019-02-20 18:27:36,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-20 18:27:36,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-20 18:27:36,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-20 18:27:36,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-20 18:27:36,532 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-02-20 18:27:36,532 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 303 msec
2019-02-20 18:27:39,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=3}
2019-02-20 18:27:39,359 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-20 18:27:39,359 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-20 18:27:39,360 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-20 18:27:39,360 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call Call#5 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 10.10.1.6:46538
java.io.IOException: File /myfile15._COPYING_ could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2117)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2691)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-02-20 18:27:39,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=3}
2019-02-20 18:27:39,878 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-20 18:27:39,878 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-20 18:27:39,878 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-20 18:27:39,878 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call Call#5 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 10.10.1.6:46540
java.io.IOException: File /myfile12._COPYING_ could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2117)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2691)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-02-20 18:27:41,675 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=3}
2019-02-20 18:27:41,675 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-20 18:27:41,675 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-20 18:27:41,675 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-20 18:27:41,675 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020, call Call#5 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 10.10.1.6:46548
java.io.IOException: File /myfile5._COPYING_ could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2117)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2691)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-02-20 18:27:43,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=3}
2019-02-20 18:27:43,476 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-20 18:27:43,477 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-20 18:27:43,477 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-20 18:27:43,477 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020, call Call#5 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 10.10.1.6:46512
java.io.IOException: File /myfile17._COPYING_ could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2117)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2691)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-02-20 18:27:44,172 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=3}
2019-02-20 18:27:44,172 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-20 18:27:44,172 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-20 18:27:44,172 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-20 18:27:44,173 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call Call#5 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 10.10.1.6:46564
java.io.IOException: File /myfile14._COPYING_ could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2117)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2691)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-02-20 18:27:49,062 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=3}
2019-02-20 18:27:49,062 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-20 18:27:49,062 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-20 18:27:49,062 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-20 18:27:49,063 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020, call Call#5 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 10.10.1.6:46584
java.io.IOException: File /myfile18._COPYING_ could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2117)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2691)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-02-20 18:27:49,154 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=3}
2019-02-20 18:27:49,154 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-20 18:27:49,155 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-20 18:27:49,155 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-20 18:27:49,155 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call Call#5 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 10.10.1.6:46586
java.io.IOException: File /myfile4._COPYING_ could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2117)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2691)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-02-20 18:27:54,795 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=3}
2019-02-20 18:27:54,795 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-20 18:27:54,795 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-20 18:27:54,795 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-20 18:27:54,795 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call Call#5 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 10.10.1.6:46610
java.io.IOException: File /myfile7._COPYING_ could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2117)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2691)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-02-20 18:27:55,406 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=3}
2019-02-20 18:27:55,406 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-20 18:27:55,406 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-20 18:27:55,406 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-20 18:27:55,406 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call Call#5 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 10.10.1.6:46612
java.io.IOException: File /myfile11._COPYING_ could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2117)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2691)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-02-20 18:27:55,558 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=3}
2019-02-20 18:27:55,558 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-20 18:27:55,558 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-20 18:27:55,558 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-20 18:27:55,558 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call Call#5 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 10.10.1.6:46616
java.io.IOException: File /myfile16._COPYING_ could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2117)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2691)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-02-20 18:28:10,951 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-20 18:28:10,954 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode050.clemson.cloudlab.us/130.127.133.59
************************************************************/
2019-02-20 18:28:27,989 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode050.clemson.cloudlab.us/130.127.133.59
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-17T02:52Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-20 18:28:27,999 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 18:28:28,004 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-20 18:28:28,290 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 18:28:28,396 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 18:28:28,396 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-20 18:28:28,447 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-20 18:28:28,448 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-20 18:28:28,608 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 18:28:28,638 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-20 18:28:28,656 INFO org.eclipse.jetty.util.log: Logging initialized @1186ms
2019-02-20 18:28:28,763 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 18:28:28,778 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-20 18:28:28,788 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 18:28:28,791 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-20 18:28:28,791 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 18:28:28,791 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 18:28:28,818 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-20 18:28:28,818 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-20 18:28:28,827 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-20 18:28:28,829 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-20 18:28:28,864 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-20 18:28:28,865 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-20 18:28:28,941 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-20 18:28:28,964 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-20 18:28:28,964 INFO org.eclipse.jetty.server.Server: Started @1495ms
2019-02-20 18:28:29,326 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-20 18:28:29,376 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-20 18:28:29,390 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-20 18:28:29,392 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-20 18:28:29,394 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-20 18:28:29,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-20 18:28:29,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-20 18:28:29,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-20 18:28:29,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-20 18:28:29,402 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-20 18:28:29,444 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-20 18:28:29,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-20 18:28:29,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-20 18:28:29,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-20 18:28:29,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 20 18:28:29
2019-02-20 18:28:29,463 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-20 18:28:29,463 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:28:29,465 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-20 18:28:29,465 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-20 18:28:29,600 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-20 18:28:29,609 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-20 18:28:29,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-20 18:28:29,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-20 18:28:29,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-20 18:28:29,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-20 18:28:29,609 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-20 18:28:29,610 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-20 18:28:29,610 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-20 18:28:29,610 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-20 18:28:29,610 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-20 18:28:29,610 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-20 18:28:29,692 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-20 18:28:29,692 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:28:29,692 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-20 18:28:29,692 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-20 18:28:29,766 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-20 18:28:29,766 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-20 18:28:29,766 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-20 18:28:29,766 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-20 18:28:29,773 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-20 18:28:29,776 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-20 18:28:29,781 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-20 18:28:29,781 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:28:29,781 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-20 18:28:29,781 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-20 18:28:29,809 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-20 18:28:29,809 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-20 18:28:29,809 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-20 18:28:29,813 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-20 18:28:29,813 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-20 18:28:29,815 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-20 18:28:29,815 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:28:29,816 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-20 18:28:29,816 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-20 18:28:29,897 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 68140@clnode050.clemson.cloudlab.us
2019-02-20 18:28:31,251 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1139ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=300ms
GC pool 'PS Scavenge' had collection(s): count=1 time=933ms
2019-02-20 18:28:31,426 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-20 18:28:31,488 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-20 18:28:31,490 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-20 18:28:31,521 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-20 18:28:31,521 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-20 18:28:31,526 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-02-20 18:28:31,526 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:28:31,530 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,530 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,643 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 490 loaded in 0 seconds
2019-02-20 18:28:31,643 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #491
2019-02-20 18:28:31,643 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:28:31,643 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,644 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,655 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 52 loaded in 0 seconds
2019-02-20 18:28:31,655 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a7288a3 expecting start txid #543
2019-02-20 18:28:31,655 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:28:31,655 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,655 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,658 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 42 edits # 2 loaded in 0 seconds
2019-02-20 18:28:31,658 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2974f221 expecting start txid #545
2019-02-20 18:28:31,658 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:28:31,658 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,658 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,678 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 3598 edits # 38 loaded in 0 seconds
2019-02-20 18:28:31,678 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@58fe0499 expecting start txid #583
2019-02-20 18:28:31,678 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:28:31,678 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,679 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,691 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 5046 edits # 48 loaded in 0 seconds
2019-02-20 18:28:31,691 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@686449f9 expecting start txid #631
2019-02-20 18:28:31,692 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:28:31,692 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,692 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,700 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 4106 edits # 36 loaded in 0 seconds
2019-02-20 18:28:31,700 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@665df3c6 expecting start txid #667
2019-02-20 18:28:31,700 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:28:31,700 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,700 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,707 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 3148 edits # 28 loaded in 0 seconds
2019-02-20 18:28:31,707 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68b6f0d6 expecting start txid #695
2019-02-20 18:28:31,707 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:28:31,707 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,707 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,713 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-20 18:28:31,713 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4044fb95 expecting start txid #696
2019-02-20 18:28:31,714 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:28:31,714 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,714 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:28:31,722 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 21 loaded in 0 seconds
2019-02-20 18:28:31,722 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-20 18:28:31,722 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-20 18:28:31,722 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1899 msecs
2019-02-20 18:28:31,905 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-20 18:28:31,910 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 18:28:31,923 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-20 18:28:32,108 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-20 18:28:32,117 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-20 18:28:32,132 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2019-02-20 18:28:32,132 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2019-02-20 18:28:32,132 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-20 18:28:32,168 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-20 18:28:32,168 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-20 18:28:32,171 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-20 18:28:32,174 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-20 18:28:32,179 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-20 18:28:32,185 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-20 18:28:32,813 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=ba18f7c4-135d-4cb1-9251-cc80bd21778d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage ba18f7c4-135d-4cb1-9251-cc80bd21778d
2019-02-20 18:28:32,815 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-20 18:28:32,815 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN ba18f7c4-135d-4cb1-9251-cc80bd21778d (10.10.1.5:9866).
2019-02-20 18:28:32,827 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 for DN 10.10.1.5:9866
2019-02-20 18:28:32,841 INFO BlockStateChange: BLOCK* processReport 0x164dadc5045cc477: Processing first storage report for DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 from datanode ba18f7c4-135d-4cb1-9251-cc80bd21778d
2019-02-20 18:28:32,843 INFO BlockStateChange: BLOCK* processReport 0x164dadc5045cc477: from storage DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=ba18f7c4-135d-4cb1-9251-cc80bd21778d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 8, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-02-20 18:28:32,857 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=51d461cb-7c6e-476d-ab0f-839504cf72ad, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage 51d461cb-7c6e-476d-ab0f-839504cf72ad
2019-02-20 18:28:32,858 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-20 18:28:32,858 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 51d461cb-7c6e-476d-ab0f-839504cf72ad (10.10.1.3:9866).
2019-02-20 18:28:32,860 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 for DN 10.10.1.3:9866
2019-02-20 18:28:32,862 INFO BlockStateChange: BLOCK* processReport 0xdf1a5e81ee885bae: Processing first storage report for DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 from datanode 51d461cb-7c6e-476d-ab0f-839504cf72ad
2019-02-20 18:28:32,862 INFO BlockStateChange: BLOCK* processReport 0xdf1a5e81ee885bae: from storage DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=51d461cb-7c6e-476d-ab0f-839504cf72ad, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 8, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-20 18:28:32,869 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=0d0a0955-6b8a-4f32-9438-2d3b39b35dab, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage 0d0a0955-6b8a-4f32-9438-2d3b39b35dab
2019-02-20 18:28:32,869 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-20 18:28:32,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 0d0a0955-6b8a-4f32-9438-2d3b39b35dab (10.10.1.2:9866).
2019-02-20 18:28:32,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-39048a22-e14f-4fa4-91cf-2b951903fd70 for DN 10.10.1.2:9866
2019-02-20 18:28:32,872 INFO BlockStateChange: BLOCK* processReport 0x5a55ea3f5c705f11: Processing first storage report for DS-39048a22-e14f-4fa4-91cf-2b951903fd70 from datanode 0d0a0955-6b8a-4f32-9438-2d3b39b35dab
2019-02-20 18:28:32,872 INFO BlockStateChange: BLOCK* processReport 0x5a55ea3f5c705f11: from storage DS-39048a22-e14f-4fa4-91cf-2b951903fd70 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=0d0a0955-6b8a-4f32-9438-2d3b39b35dab, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 8, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-20 18:30:32,198 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:30:32,450 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1b7e3d4 expecting start txid #717
2019-02-20 18:30:32,450 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:30:32,451 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 717
2019-02-20 18:30:32,451 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 717
2019-02-20 18:30:32,491 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 20802 edits # 374 loaded in 0 seconds
2019-02-20 18:32:32,498 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:32:32,678 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@42d3b2a6 expecting start txid #1091
2019-02-20 18:32:32,678 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:32:32,678 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1091
2019-02-20 18:32:32,678 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1091
2019-02-20 18:32:32,694 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 11112 edits # 198 loaded in 0 seconds
2019-02-20 18:34:32,701 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:34:32,887 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@11ce5f3d expecting start txid #1289
2019-02-20 18:34:32,887 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:34:32,887 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1289
2019-02-20 18:34:32,888 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1289
2019-02-20 18:34:32,903 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 9985 edits # 180 loaded in 0 seconds
2019-02-20 18:36:32,910 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:36:33,116 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3caa208e expecting start txid #1469
2019-02-20 18:36:33,116 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:36:33,116 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1469
2019-02-20 18:36:33,116 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1469
2019-02-20 18:36:33,142 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 19304 edits # 344 loaded in 0 seconds
2019-02-20 18:38:33,150 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:38:33,326 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@27f7e445 expecting start txid #1813
2019-02-20 18:38:33,326 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:38:33,326 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1813
2019-02-20 18:38:33,326 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1813
2019-02-20 18:38:33,340 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 10448 edits # 187 loaded in 0 seconds
2019-02-20 18:38:39,863 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-02-20 18:38:39,864 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-02-20 18:38:39,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-20 18:38:39,876 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-02-20 18:38:39,913 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 6
2019-02-20 18:38:39,914 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 2000
2019-02-20 18:38:39,936 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.5:8485: segmentState { startTxId: 2000 endTxId: 2005 isInProgress: true } lastWriterEpoch: 5 lastCommittedTxId: 2004
10.10.1.2:8485: segmentState { startTxId: 2000 endTxId: 2005 isInProgress: true } lastWriterEpoch: 5 lastCommittedTxId: 2004
2019-02-20 18:38:39,938 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.5:8485=segmentState {
  startTxId: 2000
  endTxId: 2005
  isInProgress: true
}
lastWriterEpoch: 5
lastCommittedTxId: 2004

2019-02-20 18:38:39,982 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-02-20 18:38:40,007 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000696 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000696-0000000000000000716
2019-02-20 18:38:40,026 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-02-20 18:38:40,030 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1048b384 expecting start txid #2000
2019-02-20 18:38:40,030 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:38:40,030 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2000
2019-02-20 18:38:40,030 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2000
2019-02-20 18:38:40,037 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 6 loaded in 0 seconds
2019-02-20 18:38:40,037 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-02-20 18:38:40,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-02-20 18:38:40,038 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-20 18:38:40,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 2006
2019-02-20 18:38:40,041 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2006
2019-02-20 18:38:40,288 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 53 
2019-02-20 18:38:40,309 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-20 18:38:40,313 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 3 milliseconds
name space=19
storage space=55566139392
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-02-20 18:38:40,319 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-20 18:38:40,385 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 138
2019-02-20 18:38:40,385 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-20 18:38:40,385 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-20 18:38:40,385 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-20 18:38:40,385 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 1
2019-02-20 18:38:40,385 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 346 msec
2019-02-20 18:38:42,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742355_1531, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-20 18:38:47,437 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742356_1532, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-02-20 18:38:47,742 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742357_1533, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-20 18:38:53,785 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742358_1534, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-20 18:38:56,802 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742359_1535, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-20 18:38:56,802 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742360_1536, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-20 18:38:56,803 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742361_1537, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-20 18:38:57,528 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742362_1538, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-20 18:38:57,768 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742363_1539, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile19._COPYING_
2019-02-20 18:38:57,785 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742364_1540, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-20 18:38:57,894 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742365_1541, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-20 18:38:58,135 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742366_1542, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-20 18:38:58,367 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742367_1543, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile19._COPYING_
2019-02-20 18:38:58,370 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742368_1544, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-20 18:38:58,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742369_1545, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-20 18:38:58,622 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742370_1546, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-20 18:38:58,838 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742371_1547, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-20 18:38:58,841 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742372_1548, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-20 18:38:58,971 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742373_1549, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-20 18:39:00,516 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742374_1550, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-20 18:39:00,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742375_1551, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-20 18:39:00,958 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742376_1552, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-20 18:39:00,959 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742377_1553, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-20 18:39:01,494 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742378_1554, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-20 18:39:01,513 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile12._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1177796158_1
2019-02-20 18:39:01,526 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742379_1555, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-20 18:39:01,609 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742380_1556, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-20 18:39:01,750 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742381_1557, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-20 18:39:01,945 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742382_1558, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile17._COPYING_
2019-02-20 18:39:02,196 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742383_1559, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-20 18:39:02,248 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742384_1560, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-20 18:39:02,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742385_1561, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile17._COPYING_
2019-02-20 18:39:02,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742386_1562, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-20 18:39:02,992 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile19._COPYING_ is closed by DFSClient_NONMAPREDUCE_-457056955_1
2019-02-20 18:39:03,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742387_1563, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-20 18:39:03,330 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile15._COPYING_ is closed by DFSClient_NONMAPREDUCE_167755678_1
2019-02-20 18:39:03,822 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742388_1564, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-20 18:39:03,927 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742389_1565, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-20 18:39:04,387 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile16._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1282641021_1
2019-02-20 18:39:04,432 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742390_1566, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile17._COPYING_
2019-02-20 18:39:07,083 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742391_1567, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile17._COPYING_
2019-02-20 18:39:07,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742392_1568, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile17._COPYING_
2019-02-20 18:39:07,891 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile17._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1857191512_1
2019-02-20 18:39:10,764 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742393_1569, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-20 18:39:11,217 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742394_1570, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-20 18:39:11,778 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742395_1571, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-20 18:39:12,084 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742396_1572, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-20 18:39:12,672 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742397_1573, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-20 18:39:13,125 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742398_1574, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-20 18:39:13,190 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742399_1575, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-20 18:39:13,661 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742400_1576, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-20 18:39:13,789 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742401_1577, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-20 18:39:14,213 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742402_1578, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-20 18:39:14,385 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742403_1579, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-20 18:39:14,713 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742404_1580, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile18._COPYING_
2019-02-20 18:39:14,883 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742405_1581, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-20 18:39:14,982 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-20 18:39:14,985 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode050.clemson.cloudlab.us/130.127.133.59
************************************************************/
2019-02-20 18:39:32,023 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode050.clemson.cloudlab.us/130.127.133.59
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-17T02:52Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-20 18:39:32,033 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 18:39:32,038 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-20 18:39:32,325 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 18:39:32,430 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 18:39:32,430 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-20 18:39:32,482 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-20 18:39:32,482 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-20 18:39:32,649 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 18:39:32,676 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-20 18:39:32,694 INFO org.eclipse.jetty.util.log: Logging initialized @1190ms
2019-02-20 18:39:32,801 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 18:39:32,816 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-20 18:39:32,826 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 18:39:32,829 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-20 18:39:32,830 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 18:39:32,830 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 18:39:32,856 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-20 18:39:32,856 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-20 18:39:32,865 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-20 18:39:32,867 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-20 18:39:32,902 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-20 18:39:32,903 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-20 18:39:32,978 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-20 18:39:33,000 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-20 18:39:33,000 INFO org.eclipse.jetty.server.Server: Started @1498ms
2019-02-20 18:39:33,357 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-20 18:39:33,409 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-20 18:39:33,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-20 18:39:33,425 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-20 18:39:33,427 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-20 18:39:33,434 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-20 18:39:33,434 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-20 18:39:33,434 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-20 18:39:33,435 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-20 18:39:33,435 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-20 18:39:33,478 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-20 18:39:33,490 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-20 18:39:33,490 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-20 18:39:33,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-20 18:39:33,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 20 18:39:33
2019-02-20 18:39:33,497 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-20 18:39:33,497 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:39:33,499 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-20 18:39:33,499 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-20 18:39:33,634 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-20 18:39:33,644 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-20 18:39:33,644 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-20 18:39:33,644 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-20 18:39:33,644 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-20 18:39:33,644 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-20 18:39:33,644 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-20 18:39:33,644 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-20 18:39:33,644 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-20 18:39:33,645 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-20 18:39:33,645 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-20 18:39:33,645 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-20 18:39:33,729 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-20 18:39:33,729 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:39:33,730 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-20 18:39:33,730 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-20 18:39:33,803 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-20 18:39:33,803 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-20 18:39:33,803 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-20 18:39:33,803 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-20 18:39:33,810 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-20 18:39:33,813 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-20 18:39:33,818 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-20 18:39:33,818 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:39:33,819 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-20 18:39:33,819 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-20 18:39:33,846 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-20 18:39:33,846 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-20 18:39:33,847 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-20 18:39:33,851 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-20 18:39:33,851 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-20 18:39:33,853 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-20 18:39:33,853 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:39:33,854 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-20 18:39:33,854 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-20 18:39:33,907 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 69144@clnode050.clemson.cloudlab.us
2019-02-20 18:39:35,269 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1117ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=331ms
GC pool 'PS Scavenge' had collection(s): count=1 time=905ms
2019-02-20 18:39:35,440 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-20 18:39:35,502 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-20 18:39:35,504 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-20 18:39:35,535 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-20 18:39:35,535 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-20 18:39:35,540 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-02-20 18:39:35,541 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,544 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,545 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,661 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 490 loaded in 0 seconds
2019-02-20 18:39:35,661 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #491
2019-02-20 18:39:35,661 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,662 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,662 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,672 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 52 loaded in 0 seconds
2019-02-20 18:39:35,672 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a7288a3 expecting start txid #543
2019-02-20 18:39:35,673 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,673 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,673 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,675 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 42 edits # 2 loaded in 0 seconds
2019-02-20 18:39:35,676 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2974f221 expecting start txid #545
2019-02-20 18:39:35,676 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,676 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,676 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,695 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 3598 edits # 38 loaded in 0 seconds
2019-02-20 18:39:35,695 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@58fe0499 expecting start txid #583
2019-02-20 18:39:35,695 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,696 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,696 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,709 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 5046 edits # 48 loaded in 0 seconds
2019-02-20 18:39:35,709 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@686449f9 expecting start txid #631
2019-02-20 18:39:35,709 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,709 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,709 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 4106 edits # 36 loaded in 0 seconds
2019-02-20 18:39:35,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@665df3c6 expecting start txid #667
2019-02-20 18:39:35,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,718 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,718 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,724 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 3148 edits # 28 loaded in 0 seconds
2019-02-20 18:39:35,724 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68b6f0d6 expecting start txid #695
2019-02-20 18:39:35,724 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,724 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,724 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,728 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-20 18:39:35,728 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4044fb95 expecting start txid #696
2019-02-20 18:39:35,728 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,728 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,728 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,737 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 21 loaded in 0 seconds
2019-02-20 18:39:35,737 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@aa549e5 expecting start txid #717
2019-02-20 18:39:35,737 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,737 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,737 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,756 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 20802 edits # 374 loaded in 0 seconds
2019-02-20 18:39:35,756 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@36f48b4 expecting start txid #1091
2019-02-20 18:39:35,756 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,756 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,756 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,767 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 11112 edits # 198 loaded in 0 seconds
2019-02-20 18:39:35,767 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5c00384f expecting start txid #1289
2019-02-20 18:39:35,767 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,767 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,767 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,777 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 9985 edits # 180 loaded in 0 seconds
2019-02-20 18:39:35,777 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3b7ff809 expecting start txid #1469
2019-02-20 18:39:35,778 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,778 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,778 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 19304 edits # 344 loaded in 0 seconds
2019-02-20 18:39:35,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1bb564e2 expecting start txid #1813
2019-02-20 18:39:35,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,798 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,799 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,807 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 10448 edits # 187 loaded in 0 seconds
2019-02-20 18:39:35,807 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@62e6b5c8 expecting start txid #2000
2019-02-20 18:39:35,807 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,808 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,808 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,812 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 6 loaded in 0 seconds
2019-02-20 18:39:35,812 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3f792b9b expecting start txid #2006
2019-02-20 18:39:35,812 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:39:35,812 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,812 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:39:35,822 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 176 loaded in 0 seconds
2019-02-20 18:39:35,822 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-20 18:39:35,822 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-20 18:39:35,823 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1961 msecs
2019-02-20 18:39:36,003 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-20 18:39:36,008 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 18:39:36,020 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-20 18:39:36,217 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-20 18:39:36,228 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 2
2019-02-20 18:39:36,240 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 138 blocks to reach the threshold 0.9990 of total blocks 139.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-02-20 18:39:36,272 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-20 18:39:36,272 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-20 18:39:36,276 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-20 18:39:36,279 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-20 18:39:36,285 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-20 18:39:36,291 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-20 18:39:36,511 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=ba18f7c4-135d-4cb1-9251-cc80bd21778d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage ba18f7c4-135d-4cb1-9251-cc80bd21778d
2019-02-20 18:39:36,513 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-20 18:39:36,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN ba18f7c4-135d-4cb1-9251-cc80bd21778d (10.10.1.5:9866).
2019-02-20 18:39:36,515 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=0d0a0955-6b8a-4f32-9438-2d3b39b35dab, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage 0d0a0955-6b8a-4f32-9438-2d3b39b35dab
2019-02-20 18:39:36,515 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-20 18:39:36,515 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 0d0a0955-6b8a-4f32-9438-2d3b39b35dab (10.10.1.2:9866).
2019-02-20 18:39:36,515 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=51d461cb-7c6e-476d-ab0f-839504cf72ad, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage 51d461cb-7c6e-476d-ab0f-839504cf72ad
2019-02-20 18:39:36,515 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-20 18:39:36,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 51d461cb-7c6e-476d-ab0f-839504cf72ad (10.10.1.3:9866).
2019-02-20 18:39:36,526 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 for DN 10.10.1.3:9866
2019-02-20 18:39:36,530 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 for DN 10.10.1.5:9866
2019-02-20 18:39:36,530 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-39048a22-e14f-4fa4-91cf-2b951903fd70 for DN 10.10.1.2:9866
2019-02-20 18:39:36,543 INFO BlockStateChange: BLOCK* processReport 0x164dadc5045cc478: Processing first storage report for DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 from datanode ba18f7c4-135d-4cb1-9251-cc80bd21778d
2019-02-20 18:39:36,554 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 138 has reached the threshold 0.9990 of total blocks 139. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 30 seconds.
2019-02-20 18:39:36,555 INFO BlockStateChange: BLOCK* processReport 0x164dadc5045cc478: from storage DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=ba18f7c4-135d-4cb1-9251-cc80bd21778d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 173, hasStaleStorage: false, processing time: 11 msecs, invalidatedBlocks: 0
2019-02-20 18:39:36,555 INFO BlockStateChange: BLOCK* processReport 0x5a55ea3f5c705f12: Processing first storage report for DS-39048a22-e14f-4fa4-91cf-2b951903fd70 from datanode 0d0a0955-6b8a-4f32-9438-2d3b39b35dab
2019-02-20 18:39:36,558 INFO BlockStateChange: BLOCK* processReport 0x5a55ea3f5c705f12: from storage DS-39048a22-e14f-4fa4-91cf-2b951903fd70 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=0d0a0955-6b8a-4f32-9438-2d3b39b35dab, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 165, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2019-02-20 18:39:36,558 INFO BlockStateChange: BLOCK* processReport 0xdf1a5e81ee885baf: Processing first storage report for DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 from datanode 51d461cb-7c6e-476d-ab0f-839504cf72ad
2019-02-20 18:39:36,561 INFO BlockStateChange: BLOCK* processReport 0xdf1a5e81ee885baf: from storage DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=51d461cb-7c6e-476d-ab0f-839504cf72ad, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 157, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-02-20 18:39:56,557 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 139 has reached the threshold 0.9990 of total blocks 139. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-02-20 18:40:06,558 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2019-02-20 18:40:06,559 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 30 secs
2019-02-20 18:40:06,559 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2019-02-20 18:40:06,559 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-20 18:41:36,305 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:41:36,544 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@138fa090 expecting start txid #2182
2019-02-20 18:41:36,544 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:41:36,545 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2182
2019-02-20 18:41:36,545 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2182
2019-02-20 18:41:36,557 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 3910 edits # 41 loaded in 0 seconds
2019-02-20 18:43:36,564 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:43:36,755 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@601a4ca2 expecting start txid #2223
2019-02-20 18:43:36,755 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:43:36,755 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2223
2019-02-20 18:43:36,755 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2223
2019-02-20 18:43:36,764 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 4165 edits # 39 loaded in 0 seconds
2019-02-20 18:45:36,771 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:45:36,948 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4d56e05f expecting start txid #2262
2019-02-20 18:45:36,948 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:45:36,948 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2262
2019-02-20 18:45:36,948 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2262
2019-02-20 18:45:36,957 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 4825 edits # 42 loaded in 0 seconds
2019-02-20 18:47:36,963 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:47:37,140 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@71a47d expecting start txid #2304
2019-02-20 18:47:37,140 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:47:37,140 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2304
2019-02-20 18:47:37,140 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2304
2019-02-20 18:47:37,147 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 4104 edits # 36 loaded in 0 seconds
2019-02-20 18:49:37,154 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:49:37,317 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@8146c7c expecting start txid #2340
2019-02-20 18:49:37,317 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:49:37,318 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2340
2019-02-20 18:49:37,318 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2340
2019-02-20 18:49:37,327 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 4581 edits # 40 loaded in 0 seconds
2019-02-20 18:49:44,360 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-02-20 18:49:44,361 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-02-20 18:49:44,364 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-20 18:49:44,372 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-02-20 18:49:44,411 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 8
2019-02-20 18:49:44,411 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 2380
2019-02-20 18:49:44,432 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.5:8485: segmentState { startTxId: 2380 endTxId: 2382 isInProgress: true } lastWriterEpoch: 7 lastCommittedTxId: 2381
10.10.1.3:8485: segmentState { startTxId: 2380 endTxId: 2382 isInProgress: true } lastWriterEpoch: 7 lastCommittedTxId: 2381
10.10.1.2:8485: segmentState { startTxId: 2380 endTxId: 2382 isInProgress: true } lastWriterEpoch: 7 lastCommittedTxId: 2381
2019-02-20 18:49:44,434 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.5:8485=segmentState {
  startTxId: 2380
  endTxId: 2382
  isInProgress: true
}
lastWriterEpoch: 7
lastCommittedTxId: 2381

2019-02-20 18:49:44,473 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-02-20 18:49:44,498 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000002006 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000002006-0000000000000002181
2019-02-20 18:49:44,516 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-02-20 18:49:44,520 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@ddd847a expecting start txid #2380
2019-02-20 18:49:44,520 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:49:44,520 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2380
2019-02-20 18:49:44,520 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2380
2019-02-20 18:49:44,527 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 3 loaded in 0 seconds
2019-02-20 18:49:44,527 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-02-20 18:49:44,528 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-02-20 18:49:44,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-20 18:49:44,528 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 2383
2019-02-20 18:49:44,531 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2383
2019-02-20 18:49:44,816 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 101 
2019-02-20 18:49:44,837 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-20 18:49:44,841 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 3 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-02-20 18:49:44,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2019-02-20 18:49:44,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-20 18:49:44,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-20 18:49:44,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-20 18:49:44,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-20 18:49:44,847 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-02-20 18:49:44,847 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 319 msec
2019-02-20 18:50:09,897 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=3}
2019-02-20 18:50:09,897 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-20 18:50:09,898 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-20 18:50:09,898 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-20 18:50:09,898 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call Call#5 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 10.10.1.6:58202
java.io.IOException: File /myfile13._COPYING_ could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2117)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2691)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-02-20 18:50:10,498 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=3}
2019-02-20 18:50:10,498 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-20 18:50:10,498 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-20 18:50:10,499 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-20 18:50:10,499 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020, call Call#5 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 10.10.1.6:58206
java.io.IOException: File /myfile1._COPYING_ could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2117)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2691)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-02-20 18:50:12,972 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=3}
2019-02-20 18:50:12,972 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-20 18:50:12,972 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 3 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK, DISK, DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-20 18:50:12,972 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 3 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-20 18:50:12,973 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call Call#5 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 10.10.1.6:58216
java.io.IOException: File /myfile3._COPYING_ could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and no node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2117)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:287)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2691)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-02-20 18:50:19,022 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-20 18:50:19,024 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode050.clemson.cloudlab.us/130.127.133.59
************************************************************/
2019-02-20 18:50:36,063 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode050.clemson.cloudlab.us/130.127.133.59
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-17T02:52Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-20 18:50:36,073 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 18:50:36,078 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-20 18:50:36,364 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 18:50:36,467 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 18:50:36,468 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-20 18:50:36,519 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-20 18:50:36,519 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-20 18:50:36,685 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 18:50:36,713 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-20 18:50:36,731 INFO org.eclipse.jetty.util.log: Logging initialized @1178ms
2019-02-20 18:50:36,838 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 18:50:36,852 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-20 18:50:36,863 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 18:50:36,866 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-20 18:50:36,866 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 18:50:36,867 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 18:50:36,893 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-20 18:50:36,893 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-20 18:50:36,903 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-20 18:50:36,904 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-20 18:50:36,939 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-20 18:50:36,940 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-20 18:50:37,015 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-20 18:50:37,040 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-20 18:50:37,040 INFO org.eclipse.jetty.server.Server: Started @1489ms
2019-02-20 18:50:37,386 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-20 18:50:37,444 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-20 18:50:37,458 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-20 18:50:37,460 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-20 18:50:37,462 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-20 18:50:37,469 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-20 18:50:37,469 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-20 18:50:37,469 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-20 18:50:37,470 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-20 18:50:37,470 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-20 18:50:37,513 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-20 18:50:37,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-20 18:50:37,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-20 18:50:37,530 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-20 18:50:37,530 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 20 18:50:37
2019-02-20 18:50:37,532 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-20 18:50:37,532 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:50:37,534 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-20 18:50:37,534 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-20 18:50:37,667 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-20 18:50:37,677 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-20 18:50:37,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-20 18:50:37,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-20 18:50:37,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-20 18:50:37,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-20 18:50:37,678 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-20 18:50:37,678 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-20 18:50:37,678 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-20 18:50:37,678 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-20 18:50:37,678 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-20 18:50:37,678 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-20 18:50:37,762 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-20 18:50:37,763 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:50:37,763 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-20 18:50:37,763 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-20 18:50:37,836 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-20 18:50:37,837 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-20 18:50:37,837 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-20 18:50:37,837 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-20 18:50:37,844 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-20 18:50:37,847 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-20 18:50:37,852 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-20 18:50:37,852 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:50:37,853 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-20 18:50:37,853 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-20 18:50:37,881 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-20 18:50:37,881 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-20 18:50:37,881 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-20 18:50:37,885 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-20 18:50:37,885 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-20 18:50:37,887 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-20 18:50:37,887 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-20 18:50:37,888 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-20 18:50:37,888 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-20 18:50:37,959 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 70143@clnode050.clemson.cloudlab.us
2019-02-20 18:50:39,337 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-20 18:50:39,400 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-20 18:50:39,402 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-20 18:50:39,432 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-20 18:50:39,432 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-20 18:50:39,437 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-02-20 18:50:39,438 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,441 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,441 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,552 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 490 loaded in 0 seconds
2019-02-20 18:50:39,552 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #491
2019-02-20 18:50:39,552 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,553 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,553 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,563 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=491&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 52 loaded in 0 seconds
2019-02-20 18:50:39,563 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a7288a3 expecting start txid #543
2019-02-20 18:50:39,563 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,564 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,564 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,565 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 42 edits # 2 loaded in 0 seconds
2019-02-20 18:50:39,565 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2974f221 expecting start txid #545
2019-02-20 18:50:39,566 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,566 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,566 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,585 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=545&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 3598 edits # 38 loaded in 0 seconds
2019-02-20 18:50:39,585 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@58fe0499 expecting start txid #583
2019-02-20 18:50:39,586 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,586 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,586 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,600 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=583&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 5046 edits # 48 loaded in 0 seconds
2019-02-20 18:50:39,600 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@686449f9 expecting start txid #631
2019-02-20 18:50:39,600 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,600 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,600 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,608 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=631&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 4106 edits # 36 loaded in 0 seconds
2019-02-20 18:50:39,608 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@665df3c6 expecting start txid #667
2019-02-20 18:50:39,608 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,608 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,608 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,616 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=667&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 3148 edits # 28 loaded in 0 seconds
2019-02-20 18:50:39,616 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68b6f0d6 expecting start txid #695
2019-02-20 18:50:39,616 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,616 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,616 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,619 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=695&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-20 18:50:39,619 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4044fb95 expecting start txid #696
2019-02-20 18:50:39,620 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,620 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,620 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,628 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=696&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 21 loaded in 0 seconds
2019-02-20 18:50:39,628 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@aa549e5 expecting start txid #717
2019-02-20 18:50:39,628 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,628 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,628 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,647 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=717&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 20802 edits # 374 loaded in 0 seconds
2019-02-20 18:50:39,648 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@36f48b4 expecting start txid #1091
2019-02-20 18:50:39,648 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,648 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,648 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,657 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1091&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 11112 edits # 198 loaded in 0 seconds
2019-02-20 18:50:39,657 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5c00384f expecting start txid #1289
2019-02-20 18:50:39,658 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,658 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,658 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,669 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1289&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 9985 edits # 180 loaded in 0 seconds
2019-02-20 18:50:39,669 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3b7ff809 expecting start txid #1469
2019-02-20 18:50:39,669 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,669 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,669 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,684 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1469&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 19304 edits # 344 loaded in 0 seconds
2019-02-20 18:50:39,685 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1bb564e2 expecting start txid #1813
2019-02-20 18:50:39,685 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,685 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,685 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,693 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1813&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 10448 edits # 187 loaded in 0 seconds
2019-02-20 18:50:39,693 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@62e6b5c8 expecting start txid #2000
2019-02-20 18:50:39,693 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,693 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,693 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2000&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 6 loaded in 0 seconds
2019-02-20 18:50:39,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3f792b9b expecting start txid #2006
2019-02-20 18:50:39,697 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,697 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,697 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,705 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2006&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 176 loaded in 0 seconds
2019-02-20 18:50:39,705 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7b8233cd expecting start txid #2182
2019-02-20 18:50:39,705 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,705 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,705 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,712 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2182&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 3910 edits # 41 loaded in 0 seconds
2019-02-20 18:50:39,712 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4b20ca2b expecting start txid #2223
2019-02-20 18:50:39,712 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,712 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,712 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,719 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2223&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 4165 edits # 39 loaded in 0 seconds
2019-02-20 18:50:39,719 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1cbf6e72 expecting start txid #2262
2019-02-20 18:50:39,719 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,719 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,719 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,726 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2262&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 4825 edits # 42 loaded in 0 seconds
2019-02-20 18:50:39,726 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6aecbb8d expecting start txid #2304
2019-02-20 18:50:39,726 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,726 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,726 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,733 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2304&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 4104 edits # 36 loaded in 0 seconds
2019-02-20 18:50:39,733 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1af146 expecting start txid #2340
2019-02-20 18:50:39,733 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,733 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,733 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,740 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2340&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 4581 edits # 40 loaded in 0 seconds
2019-02-20 18:50:39,740 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4da602fc expecting start txid #2380
2019-02-20 18:50:39,740 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,740 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,740 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,743 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2380&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 3 loaded in 0 seconds
2019-02-20 18:50:39,743 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2a8d39c4 expecting start txid #2383
2019-02-20 18:50:39,743 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2383&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2383&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2383&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:50:39,743 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2383&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2383&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2383&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,743 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2383&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 1
2019-02-20 18:50:39,748 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2383&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2383&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2383&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 1048576 edits # 7 loaded in 0 seconds
2019-02-20 18:50:39,748 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-20 18:50:39,748 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 20 entries 233 lookups
2019-02-20 18:50:39,748 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1852 msecs
2019-02-20 18:50:39,931 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-20 18:50:39,935 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 18:50:39,948 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-20 18:50:40,146 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-20 18:50:40,157 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-20 18:50:40,169 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2019-02-20 18:50:40,169 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2019-02-20 18:50:40,169 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-20 18:50:40,200 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-20 18:50:40,201 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-20 18:50:40,203 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-20 18:50:40,206 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-20 18:50:40,211 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-20 18:50:40,217 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-20 18:50:41,295 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=51d461cb-7c6e-476d-ab0f-839504cf72ad, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage 51d461cb-7c6e-476d-ab0f-839504cf72ad
2019-02-20 18:50:41,297 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-20 18:50:41,297 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 51d461cb-7c6e-476d-ab0f-839504cf72ad (10.10.1.3:9866).
2019-02-20 18:50:41,299 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=0d0a0955-6b8a-4f32-9438-2d3b39b35dab, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage 0d0a0955-6b8a-4f32-9438-2d3b39b35dab
2019-02-20 18:50:41,299 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-20 18:50:41,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 0d0a0955-6b8a-4f32-9438-2d3b39b35dab (10.10.1.2:9866).
2019-02-20 18:50:41,299 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=ba18f7c4-135d-4cb1-9251-cc80bd21778d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991) storage ba18f7c4-135d-4cb1-9251-cc80bd21778d
2019-02-20 18:50:41,299 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-20 18:50:41,300 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN ba18f7c4-135d-4cb1-9251-cc80bd21778d (10.10.1.5:9866).
2019-02-20 18:50:41,310 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 for DN 10.10.1.5:9866
2019-02-20 18:50:41,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 for DN 10.10.1.3:9866
2019-02-20 18:50:41,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-39048a22-e14f-4fa4-91cf-2b951903fd70 for DN 10.10.1.2:9866
2019-02-20 18:50:41,325 INFO BlockStateChange: BLOCK* processReport 0x5a55ea3f5c705f13: Processing first storage report for DS-39048a22-e14f-4fa4-91cf-2b951903fd70 from datanode 0d0a0955-6b8a-4f32-9438-2d3b39b35dab
2019-02-20 18:50:41,326 INFO BlockStateChange: BLOCK* processReport 0x5a55ea3f5c705f13: from storage DS-39048a22-e14f-4fa4-91cf-2b951903fd70 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=0d0a0955-6b8a-4f32-9438-2d3b39b35dab, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 24, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-02-20 18:50:41,327 INFO BlockStateChange: BLOCK* processReport 0x164dadc5045cc479: Processing first storage report for DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 from datanode ba18f7c4-135d-4cb1-9251-cc80bd21778d
2019-02-20 18:50:41,327 INFO BlockStateChange: BLOCK* processReport 0x164dadc5045cc479: from storage DS-1f2526a2-cf1d-4efe-8c5d-64e5daddae03 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=ba18f7c4-135d-4cb1-9251-cc80bd21778d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 32, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-20 18:50:41,327 INFO BlockStateChange: BLOCK* processReport 0xdf1a5e81ee885bb0: Processing first storage report for DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 from datanode 51d461cb-7c6e-476d-ab0f-839504cf72ad
2019-02-20 18:50:41,327 INFO BlockStateChange: BLOCK* processReport 0xdf1a5e81ee885bb0: from storage DS-50c62fdf-267c-4f13-a0ed-a057c3b547c6 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=51d461cb-7c6e-476d-ab0f-839504cf72ad, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-4c203421-1546-4a02-998b-ed86277c5fa7;nsid=314068740;c=1550711692991), blocks: 16, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-20 18:52:40,229 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:52:40,486 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@21c96380 expecting start txid #2390
2019-02-20 18:52:40,486 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2390&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2390&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2390&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:52:40,487 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2390&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2390&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2390&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2390
2019-02-20 18:52:40,487 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2390&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2390
2019-02-20 18:52:40,525 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2390&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2390&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2390&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 26613 edits # 473 loaded in 0 seconds
2019-02-20 18:54:40,532 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:54:40,729 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@74b39d3b expecting start txid #2863
2019-02-20 18:54:40,729 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2863&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2863&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:54:40,729 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2863&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2863&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2863
2019-02-20 18:54:40,729 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2863&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2863
2019-02-20 18:54:40,739 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2863&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2863&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 6998 edits # 129 loaded in 0 seconds
2019-02-20 18:56:40,746 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:56:40,939 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6aabc0b2 expecting start txid #2992
2019-02-20 18:56:40,939 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2992&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2992&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:56:40,939 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2992&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2992&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2992
2019-02-20 18:56:40,939 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2992&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 2992
2019-02-20 18:56:40,963 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2992&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2992&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 23500 edits # 420 loaded in 0 seconds
2019-02-20 18:58:40,970 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 18:58:41,140 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2c3354d9 expecting start txid #3412
2019-02-20 18:58:41,140 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3412&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3412&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 18:58:41,141 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3412&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3412&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 3412
2019-02-20 18:58:41,141 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3412&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 3412
2019-02-20 18:58:41,148 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3412&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3412&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 5666 edits # 102 loaded in 0 seconds
2019-02-20 19:00:41,156 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-20 19:00:41,347 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6f82264d expecting start txid #3514
2019-02-20 19:00:41,347 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3514&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3514&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-20 19:00:41,347 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3514&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3514&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 3514
2019-02-20 19:00:41,347 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3514&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true' to transaction ID 3514
2019-02-20 19:00:41,372 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3514&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3514&storageInfo=-64%3A314068740%3A1550711692991%3ACID-4c203421-1546-4a02-998b-ed86277c5fa7&inProgressOk=true of size 21611 edits # 390 loaded in 0 seconds
