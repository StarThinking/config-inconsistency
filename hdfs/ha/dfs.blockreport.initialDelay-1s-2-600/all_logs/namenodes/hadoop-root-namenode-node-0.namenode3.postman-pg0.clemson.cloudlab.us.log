2019-02-22 17:53:15,516 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode058.clemson.cloudlab.us/130.127.133.67
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-18T22:18Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-22 17:53:15,526 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-22 17:53:15,531 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-22 17:53:15,817 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-22 17:53:15,924 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-22 17:53:15,924 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-22 17:53:15,976 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-22 17:53:15,976 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-22 17:53:16,137 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-22 17:53:16,165 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-22 17:53:16,182 INFO org.eclipse.jetty.util.log: Logging initialized @1177ms
2019-02-22 17:53:16,289 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-22 17:53:16,303 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-22 17:53:16,314 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-22 17:53:16,317 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-22 17:53:16,317 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-22 17:53:16,317 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-22 17:53:16,344 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-22 17:53:16,344 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-22 17:53:16,353 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-22 17:53:16,354 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-22 17:53:16,389 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-22 17:53:16,390 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-22 17:53:16,465 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-22 17:53:16,485 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@7848fd1f{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-22 17:53:16,486 INFO org.eclipse.jetty.server.Server: Started @1482ms
2019-02-22 17:53:16,819 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-22 17:53:16,869 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-22 17:53:16,884 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-22 17:53:16,885 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-22 17:53:16,888 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-22 17:53:16,894 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-22 17:53:16,894 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-22 17:53:16,894 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-22 17:53:16,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-22 17:53:16,895 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-22 17:53:16,937 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-22 17:53:16,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-22 17:53:16,950 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-22 17:53:16,954 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-22 17:53:16,955 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 22 17:53:16
2019-02-22 17:53:16,957 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-22 17:53:16,957 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 17:53:16,958 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-22 17:53:16,958 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-22 17:53:17,093 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-22 17:53:17,102 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-22 17:53:17,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-22 17:53:17,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-22 17:53:17,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-22 17:53:17,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-22 17:53:17,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-22 17:53:17,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-22 17:53:17,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-22 17:53:17,103 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-22 17:53:17,103 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-22 17:53:17,103 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-22 17:53:17,186 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-22 17:53:17,186 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 17:53:17,186 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-22 17:53:17,186 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-22 17:53:17,259 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-22 17:53:17,259 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-22 17:53:17,259 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-22 17:53:17,260 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-22 17:53:17,266 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-22 17:53:17,269 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-22 17:53:17,274 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-22 17:53:17,274 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 17:53:17,275 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-22 17:53:17,275 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-22 17:53:17,302 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-22 17:53:17,302 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-22 17:53:17,302 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-22 17:53:17,306 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-22 17:53:17,307 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-22 17:53:17,309 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-22 17:53:17,309 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 17:53:17,309 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-22 17:53:17,309 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-22 17:53:17,361 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 120492@clnode058.clemson.cloudlab.us
2019-02-22 17:53:18,806 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1165ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=340ms
GC pool 'PS Scavenge' had collection(s): count=1 time=979ms
2019-02-22 17:53:18,962 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2019-02-22 17:53:18,962 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-22 17:53:19,025 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-22 17:53:19,028 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-22 17:53:19,059 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-22 17:53:19,059 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-22 17:53:19,064 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-22 17:53:19,064 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-22 17:53:19,064 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1747 msecs
2019-02-22 17:53:19,244 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-22 17:53:19,249 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-22 17:53:19,261 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-22 17:53:19,447 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-22 17:53:19,456 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-22 17:53:19,466 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2019-02-22 17:53:19,466 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2019-02-22 17:53:19,466 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-22 17:53:19,500 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-22 17:53:19,500 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-22 17:53:19,503 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-22 17:53:19,506 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-22 17:53:19,511 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-22 17:53:19,517 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-22 17:53:24,470 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, fileSize: 389. Sent total: 389 bytes. Size of last segment intended to send: -1 bytes.
2019-02-22 17:53:24,636 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-22 17:53:24,638 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode058.clemson.cloudlab.us/130.127.133.67
************************************************************/
2019-02-22 17:53:35,267 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode058.clemson.cloudlab.us/130.127.133.67
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-18T22:18Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-22 17:53:35,277 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-22 17:53:35,282 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-22 17:53:35,570 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-22 17:53:35,676 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-22 17:53:35,676 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-22 17:53:35,729 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-22 17:53:35,730 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-22 17:53:35,884 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-22 17:53:35,911 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-22 17:53:35,929 INFO org.eclipse.jetty.util.log: Logging initialized @1180ms
2019-02-22 17:53:36,033 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-22 17:53:36,047 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-22 17:53:36,058 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-22 17:53:36,061 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-22 17:53:36,061 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-22 17:53:36,062 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-22 17:53:36,088 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-22 17:53:36,088 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-22 17:53:36,098 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-22 17:53:36,099 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-22 17:53:36,134 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-22 17:53:36,135 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-22 17:53:36,209 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-22 17:53:36,229 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-22 17:53:36,230 INFO org.eclipse.jetty.server.Server: Started @1482ms
2019-02-22 17:53:36,576 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-22 17:53:36,626 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-22 17:53:36,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-22 17:53:36,642 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-22 17:53:36,645 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-22 17:53:36,652 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-22 17:53:36,652 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-22 17:53:36,652 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-22 17:53:36,652 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-22 17:53:36,652 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-22 17:53:36,695 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-22 17:53:36,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-22 17:53:36,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-22 17:53:36,713 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-22 17:53:36,713 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 22 17:53:36
2019-02-22 17:53:36,715 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-22 17:53:36,715 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 17:53:36,717 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-22 17:53:36,717 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-22 17:53:36,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-22 17:53:36,845 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-22 17:53:36,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-22 17:53:36,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-22 17:53:36,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-22 17:53:36,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-22 17:53:36,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-22 17:53:36,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-22 17:53:36,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-22 17:53:36,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-22 17:53:36,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-22 17:53:36,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-22 17:53:36,936 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-22 17:53:36,936 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 17:53:36,937 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-22 17:53:36,937 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-22 17:53:37,010 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-22 17:53:37,010 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-22 17:53:37,010 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-22 17:53:37,011 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-22 17:53:37,018 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-22 17:53:37,021 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-22 17:53:37,027 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-22 17:53:37,027 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 17:53:37,027 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-22 17:53:37,027 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-22 17:53:37,055 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-22 17:53:37,055 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-22 17:53:37,055 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-22 17:53:37,060 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-22 17:53:37,060 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-22 17:53:37,062 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-22 17:53:37,062 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 17:53:37,063 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-22 17:53:37,063 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-22 17:53:37,133 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 121172@clnode058.clemson.cloudlab.us
2019-02-22 17:53:38,551 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1163ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=333ms
GC pool 'PS Scavenge' had collection(s): count=1 time=950ms
2019-02-22 17:53:39,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:39,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:39,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:40,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:40,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:40,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:41,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:41,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:41,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:42,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:42,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:42,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:43,241 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-02-22 17:53:43,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:43,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:43,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 17:53:44,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2019-02-22 17:53:44,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-22 17:53:44,069 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-22 17:53:44,071 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-22 17:53:44,101 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-22 17:53:44,102 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-22 17:53:44,107 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-22 17:53:44,107 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-22 17:53:44,107 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 7036 msecs
2019-02-22 17:53:44,287 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-22 17:53:44,292 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-22 17:53:44,304 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-22 17:53:44,492 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-22 17:53:44,500 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-22 17:53:44,511 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2019-02-22 17:53:44,511 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2019-02-22 17:53:44,511 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-22 17:53:44,544 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-22 17:53:44,545 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-22 17:53:44,548 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-22 17:53:44,551 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-22 17:53:44,556 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-22 17:53:44,563 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-22 17:53:45,084 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=69e9a3f9-0141-485b-8de9-94314ed4f10e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage 69e9a3f9-0141-485b-8de9-94314ed4f10e
2019-02-22 17:53:45,087 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-22 17:53:45,088 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 69e9a3f9-0141-485b-8de9-94314ed4f10e (10.10.1.2:9866).
2019-02-22 17:53:45,152 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e62e641d-cd9d-41d8-9287-df1c100157c2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage e62e641d-cd9d-41d8-9287-df1c100157c2
2019-02-22 17:53:45,153 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-22 17:53:45,153 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e62e641d-cd9d-41d8-9287-df1c100157c2 (10.10.1.3:9866).
2019-02-22 17:53:45,178 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 for DN 10.10.1.2:9866
2019-02-22 17:53:45,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=686ff710-55de-4f47-bdc7-8b03cef69352, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage 686ff710-55de-4f47-bdc7-8b03cef69352
2019-02-22 17:53:45,183 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-22 17:53:45,183 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 686ff710-55de-4f47-bdc7-8b03cef69352 (10.10.1.5:9866).
2019-02-22 17:53:45,203 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf for DN 10.10.1.3:9866
2019-02-22 17:53:45,227 INFO BlockStateChange: BLOCK* processReport 0xa6776519114ad2ef: Processing first storage report for DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 from datanode 69e9a3f9-0141-485b-8de9-94314ed4f10e
2019-02-22 17:53:45,229 INFO BlockStateChange: BLOCK* processReport 0xa6776519114ad2ef: from storage DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=69e9a3f9-0141-485b-8de9-94314ed4f10e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 0, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2019-02-22 17:53:45,230 INFO BlockStateChange: BLOCK* processReport 0xf30fb5c818c55ccc: Processing first storage report for DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf from datanode e62e641d-cd9d-41d8-9287-df1c100157c2
2019-02-22 17:53:45,230 INFO BlockStateChange: BLOCK* processReport 0xf30fb5c818c55ccc: from storage DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e62e641d-cd9d-41d8-9287-df1c100157c2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-22 17:53:45,230 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 for DN 10.10.1.5:9866
2019-02-22 17:53:45,253 INFO BlockStateChange: BLOCK* processReport 0x3867e07a00bf05a2: Processing first storage report for DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 from datanode 686ff710-55de-4f47-bdc7-8b03cef69352
2019-02-22 17:53:45,253 INFO BlockStateChange: BLOCK* processReport 0x3867e07a00bf05a2: from storage DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=686ff710-55de-4f47-bdc7-8b03cef69352, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-22 17:54:53,098 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-02-22 17:54:53,099 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-02-22 17:54:53,203 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-22 17:54:53,215 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-02-22 17:54:53,303 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 2
2019-02-22 17:54:53,303 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 1
2019-02-22 17:54:53,341 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.2:8485: segmentState { startTxId: 1 endTxId: 541 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 540
10.10.1.3:8485: segmentState { startTxId: 1 endTxId: 541 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 540
2019-02-22 17:54:53,344 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.2:8485=segmentState {
  startTxId: 1
  endTxId: 541
  isInProgress: true
}
lastWriterEpoch: 1
lastCommittedTxId: 540

2019-02-22 17:54:53,423 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-02-22 17:54:53,423 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-02-22 17:54:53,444 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2930cde4 expecting start txid #1
2019-02-22 17:54:53,444 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 17:54:53,449 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 17:54:53,449 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 17:54:53,679 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-02-22 17:54:53,679 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-02-22 17:54:53,680 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-02-22 17:54:53,680 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-22 17:54:53,681 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 542
2019-02-22 17:54:53,684 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 542
2019-02-22 17:54:53,977 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 97 
2019-02-22 17:54:53,999 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-22 17:54:54,003 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=21
storage space=64424509440
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-02-22 17:54:54,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-22 17:54:54,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 160
2019-02-22 17:54:54,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-22 17:54:54,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-22 17:54:54,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-22 17:54:54,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-02-22 17:54:54,075 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 394 msec
2019-02-22 17:55:27,286 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-22 17:55:27,289 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode058.clemson.cloudlab.us/130.127.133.67
************************************************************/
2019-02-22 17:55:44,325 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode058.clemson.cloudlab.us/130.127.133.67
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-18T22:18Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-22 17:55:44,335 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-22 17:55:44,340 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-22 17:55:44,628 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-22 17:55:44,734 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-22 17:55:44,734 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-22 17:55:44,786 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-22 17:55:44,786 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-22 17:55:44,952 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-22 17:55:44,980 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-22 17:55:44,998 INFO org.eclipse.jetty.util.log: Logging initialized @1185ms
2019-02-22 17:55:45,106 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-22 17:55:45,120 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-22 17:55:45,131 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-22 17:55:45,134 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-22 17:55:45,134 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-22 17:55:45,134 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-22 17:55:45,161 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-22 17:55:45,161 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-22 17:55:45,170 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-22 17:55:45,172 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-22 17:55:45,207 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-22 17:55:45,208 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-22 17:55:45,283 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-22 17:55:45,305 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-22 17:55:45,305 INFO org.eclipse.jetty.server.Server: Started @1494ms
2019-02-22 17:55:45,639 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-22 17:55:45,690 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-22 17:55:45,704 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-22 17:55:45,706 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-22 17:55:45,708 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-22 17:55:45,715 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-22 17:55:45,715 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-22 17:55:45,715 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-22 17:55:45,716 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-22 17:55:45,716 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-22 17:55:45,759 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-22 17:55:45,771 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-22 17:55:45,771 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-22 17:55:45,776 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-22 17:55:45,776 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 22 17:55:45
2019-02-22 17:55:45,778 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-22 17:55:45,778 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 17:55:45,780 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-22 17:55:45,780 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-22 17:55:45,916 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-22 17:55:45,925 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-22 17:55:45,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-22 17:55:45,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-22 17:55:45,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-22 17:55:45,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-22 17:55:45,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-22 17:55:45,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-22 17:55:45,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-22 17:55:45,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-22 17:55:45,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-22 17:55:45,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-22 17:55:46,011 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-22 17:55:46,011 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 17:55:46,011 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-22 17:55:46,011 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-22 17:55:46,084 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-22 17:55:46,084 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-22 17:55:46,084 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-22 17:55:46,085 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-22 17:55:46,092 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-22 17:55:46,094 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-22 17:55:46,100 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-22 17:55:46,100 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 17:55:46,100 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-22 17:55:46,100 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-22 17:55:46,128 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-22 17:55:46,128 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-22 17:55:46,128 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-22 17:55:46,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-22 17:55:46,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-22 17:55:46,135 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-22 17:55:46,135 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 17:55:46,135 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-22 17:55:46,135 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-22 17:55:46,199 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 122564@clnode058.clemson.cloudlab.us
2019-02-22 17:55:47,770 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1313ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=353ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1089ms
2019-02-22 17:55:47,941 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-22 17:55:48,005 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-22 17:55:48,007 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-22 17:55:48,038 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-22 17:55:48,038 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-22 17:55:48,043 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-02-22 17:55:48,044 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 17:55:48,047 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 17:55:48,048 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 17:55:48,168 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-02-22 17:55:48,168 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #542
2019-02-22 17:55:48,168 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 17:55:48,168 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 17:55:48,168 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 17:55:48,267 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-22 17:55:48,267 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-22 17:55:48,267 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-22 17:55:48,267 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 2125 msecs
2019-02-22 17:55:48,457 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-22 17:55:48,462 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-22 17:55:48,475 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-22 17:55:48,664 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-22 17:55:48,673 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-22 17:55:48,685 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 159 blocks to reach the threshold 0.9990 of total blocks 160.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-02-22 17:55:48,716 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-22 17:55:48,716 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-22 17:55:48,719 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-22 17:55:48,722 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-22 17:55:48,726 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-22 17:55:48,733 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-22 17:55:49,304 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=69e9a3f9-0141-485b-8de9-94314ed4f10e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage 69e9a3f9-0141-485b-8de9-94314ed4f10e
2019-02-22 17:55:49,306 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-22 17:55:49,307 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 69e9a3f9-0141-485b-8de9-94314ed4f10e (10.10.1.2:9866).
2019-02-22 17:55:49,308 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=686ff710-55de-4f47-bdc7-8b03cef69352, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage 686ff710-55de-4f47-bdc7-8b03cef69352
2019-02-22 17:55:49,308 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-22 17:55:49,308 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 686ff710-55de-4f47-bdc7-8b03cef69352 (10.10.1.5:9866).
2019-02-22 17:55:49,308 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e62e641d-cd9d-41d8-9287-df1c100157c2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage e62e641d-cd9d-41d8-9287-df1c100157c2
2019-02-22 17:55:49,308 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-22 17:55:49,309 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e62e641d-cd9d-41d8-9287-df1c100157c2 (10.10.1.3:9866).
2019-02-22 17:55:49,319 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 for DN 10.10.1.2:9866
2019-02-22 17:55:49,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf for DN 10.10.1.3:9866
2019-02-22 17:55:49,323 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 for DN 10.10.1.5:9866
2019-02-22 17:55:49,337 INFO BlockStateChange: BLOCK* processReport 0xf30fb5c818c55ccd: Processing first storage report for DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf from datanode e62e641d-cd9d-41d8-9287-df1c100157c2
2019-02-22 17:55:49,348 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 159 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2019-02-22 17:55:49,348 INFO BlockStateChange: BLOCK* processReport 0xf30fb5c818c55ccd: from storage DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e62e641d-cd9d-41d8-9287-df1c100157c2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 160, hasStaleStorage: false, processing time: 11 msecs, invalidatedBlocks: 0
2019-02-22 17:55:49,348 INFO BlockStateChange: BLOCK* processReport 0x3867e07a00bf05a3: Processing first storage report for DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 from datanode 686ff710-55de-4f47-bdc7-8b03cef69352
2019-02-22 17:55:49,352 INFO BlockStateChange: BLOCK* processReport 0x3867e07a00bf05a3: from storage DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=686ff710-55de-4f47-bdc7-8b03cef69352, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 160, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2019-02-22 17:55:49,352 INFO BlockStateChange: BLOCK* processReport 0xa6776519114ad2f0: Processing first storage report for DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 from datanode 69e9a3f9-0141-485b-8de9-94314ed4f10e
2019-02-22 17:55:49,354 INFO BlockStateChange: BLOCK* processReport 0xa6776519114ad2f0: from storage DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=69e9a3f9-0141-485b-8de9-94314ed4f10e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 160, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-02-22 17:56:09,350 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 160 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-02-22 17:56:19,351 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2019-02-22 17:56:19,351 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 30 secs
2019-02-22 17:56:19,352 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2019-02-22 17:56:19,352 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-22 17:57:48,745 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 17:57:49,008 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3359d27e expecting start txid #543
2019-02-22 17:57:49,009 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 17:57:49,010 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 543
2019-02-22 17:57:49,010 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 543
2019-02-22 17:57:49,021 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 100 edits # 3 loaded in 0 seconds
2019-02-22 17:59:49,029 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 17:59:49,227 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@20133ad4 expecting start txid #546
2019-02-22 17:59:49,227 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 17:59:49,227 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 546
2019-02-22 17:59:49,227 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 546
2019-02-22 17:59:49,281 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 31402 edits # 561 loaded in 0 seconds
2019-02-22 18:01:49,288 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:01:49,502 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4eaeed4e expecting start txid #1107
2019-02-22 18:01:49,502 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:01:49,502 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1107
2019-02-22 18:01:49,502 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1107
2019-02-22 18:01:49,505 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 42 edits # 2 loaded in 0 seconds
2019-02-22 18:03:49,512 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:03:49,711 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6e4332d6 expecting start txid #1109
2019-02-22 18:03:49,712 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:03:49,712 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1109
2019-02-22 18:03:49,712 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1109
2019-02-22 18:03:49,745 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 27687 edits # 501 loaded in 0 seconds
2019-02-22 18:05:49,753 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:05:49,946 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@74cfe4ea expecting start txid #1610
2019-02-22 18:05:49,946 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:05:49,946 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1610
2019-02-22 18:05:49,946 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1610
2019-02-22 18:05:49,953 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 3818 edits # 63 loaded in 0 seconds
2019-02-22 18:05:56,550 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-02-22 18:05:56,551 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-02-22 18:05:56,554 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-22 18:05:56,563 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-02-22 18:05:56,608 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 4
2019-02-22 18:05:56,608 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 1673
2019-02-22 18:05:56,631 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.3:8485: segmentState { startTxId: 1673 endTxId: 1673 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 1672
10.10.1.5:8485: segmentState { startTxId: 1673 endTxId: 1673 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 1672
2019-02-22 18:05:56,633 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.3:8485=segmentState {
  startTxId: 1673
  endTxId: 1673
  isInProgress: true
}
lastWriterEpoch: 3
lastCommittedTxId: 1672

2019-02-22 18:05:56,670 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-02-22 18:05:56,700 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000542 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000542-0000000000000000542
2019-02-22 18:05:56,718 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-02-22 18:05:56,722 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2ba2fcd5 expecting start txid #1673
2019-02-22 18:05:56,722 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:05:56,722 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1673
2019-02-22 18:05:56,722 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1673
2019-02-22 18:05:56,729 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-22 18:05:56,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-02-22 18:05:56,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-02-22 18:05:56,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-22 18:05:56,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 1674
2019-02-22 18:05:56,733 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1674
2019-02-22 18:05:57,009 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 79 
2019-02-22 18:05:57,030 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-22 18:05:57,034 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=21
storage space=64424509440
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-02-22 18:05:57,039 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-22 18:05:57,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 160
2019-02-22 18:05:57,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-22 18:05:57,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-22 18:05:57,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-22 18:05:57,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-02-22 18:05:57,102 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 372 msec
2019-02-22 18:06:31,370 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-22 18:06:31,372 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode058.clemson.cloudlab.us/130.127.133.67
************************************************************/
2019-02-22 18:06:48,394 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode058.clemson.cloudlab.us/130.127.133.67
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-18T22:18Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-22 18:06:48,404 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-22 18:06:48,409 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-22 18:06:48,696 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-22 18:06:48,799 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-22 18:06:48,799 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-22 18:06:48,852 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-22 18:06:48,852 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-22 18:06:49,018 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-22 18:06:49,046 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-22 18:06:49,063 INFO org.eclipse.jetty.util.log: Logging initialized @1173ms
2019-02-22 18:06:49,172 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-22 18:06:49,186 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-22 18:06:49,197 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-22 18:06:49,200 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-22 18:06:49,200 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-22 18:06:49,200 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-22 18:06:49,226 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-22 18:06:49,226 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-22 18:06:49,235 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-22 18:06:49,236 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-22 18:06:49,272 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-22 18:06:49,272 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-22 18:06:49,346 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-22 18:06:49,369 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-22 18:06:49,370 INFO org.eclipse.jetty.server.Server: Started @1481ms
2019-02-22 18:06:49,738 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-22 18:06:49,789 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-22 18:06:49,803 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-22 18:06:49,805 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-22 18:06:49,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-22 18:06:49,814 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-22 18:06:49,814 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-22 18:06:49,814 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-22 18:06:49,815 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-22 18:06:49,815 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-22 18:06:49,857 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-22 18:06:49,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-22 18:06:49,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-22 18:06:49,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-22 18:06:49,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 22 18:06:49
2019-02-22 18:06:49,877 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-22 18:06:49,877 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 18:06:49,878 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-22 18:06:49,878 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-22 18:06:50,014 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-22 18:06:50,023 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-22 18:06:50,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-22 18:06:50,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-22 18:06:50,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-22 18:06:50,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-22 18:06:50,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-22 18:06:50,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-22 18:06:50,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-22 18:06:50,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-22 18:06:50,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-22 18:06:50,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-22 18:06:50,108 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-22 18:06:50,108 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 18:06:50,108 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-22 18:06:50,108 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-22 18:06:50,181 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-22 18:06:50,181 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-22 18:06:50,182 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-22 18:06:50,182 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-22 18:06:50,189 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-22 18:06:50,191 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-22 18:06:50,196 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-22 18:06:50,196 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 18:06:50,197 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-22 18:06:50,197 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-22 18:06:50,224 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-22 18:06:50,224 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-22 18:06:50,224 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-22 18:06:50,228 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-22 18:06:50,229 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-22 18:06:50,231 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-22 18:06:50,231 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 18:06:50,231 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-22 18:06:50,231 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-22 18:06:50,287 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 1029@clnode058.clemson.cloudlab.us
2019-02-22 18:06:51,538 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-22 18:06:51,602 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-22 18:06:51,604 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-22 18:06:51,634 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-22 18:06:51,635 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-22 18:06:51,640 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-02-22 18:06:51,640 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:06:51,644 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,644 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,764 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-02-22 18:06:51,764 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #542
2019-02-22 18:06:51,764 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:06:51,765 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,765 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,769 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-22 18:06:51,769 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a7288a3 expecting start txid #543
2019-02-22 18:06:51,769 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:06:51,770 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,770 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,782 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 100 edits # 3 loaded in 0 seconds
2019-02-22 18:06:51,782 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2974f221 expecting start txid #546
2019-02-22 18:06:51,782 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:06:51,782 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,782 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,819 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 31402 edits # 561 loaded in 0 seconds
2019-02-22 18:06:51,819 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@58fe0499 expecting start txid #1107
2019-02-22 18:06:51,819 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:06:51,819 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,819 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,821 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 42 edits # 2 loaded in 0 seconds
2019-02-22 18:06:51,821 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@686449f9 expecting start txid #1109
2019-02-22 18:06:51,821 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:06:51,821 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,821 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,845 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 27687 edits # 501 loaded in 0 seconds
2019-02-22 18:06:51,845 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@665df3c6 expecting start txid #1610
2019-02-22 18:06:51,846 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:06:51,846 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,846 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,850 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 3818 edits # 63 loaded in 0 seconds
2019-02-22 18:06:51,850 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68b6f0d6 expecting start txid #1673
2019-02-22 18:06:51,850 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:06:51,850 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,850 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,856 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-22 18:06:51,856 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4044fb95 expecting start txid #1674
2019-02-22 18:06:51,856 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:06:51,857 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,857 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:06:51,862 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-22 18:06:51,862 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-22 18:06:51,862 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-22 18:06:51,862 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1623 msecs
2019-02-22 18:06:52,044 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-22 18:06:52,049 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-22 18:06:52,061 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-22 18:06:52,253 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-22 18:06:52,264 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-22 18:06:52,277 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 159 blocks to reach the threshold 0.9990 of total blocks 160.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-02-22 18:06:52,309 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-22 18:06:52,309 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-22 18:06:52,313 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-22 18:06:52,316 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-22 18:06:52,322 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-22 18:06:52,328 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-22 18:06:52,982 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e62e641d-cd9d-41d8-9287-df1c100157c2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage e62e641d-cd9d-41d8-9287-df1c100157c2
2019-02-22 18:06:52,983 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-22 18:06:52,984 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e62e641d-cd9d-41d8-9287-df1c100157c2 (10.10.1.3:9866).
2019-02-22 18:06:52,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=69e9a3f9-0141-485b-8de9-94314ed4f10e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage 69e9a3f9-0141-485b-8de9-94314ed4f10e
2019-02-22 18:06:52,986 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-22 18:06:52,986 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 69e9a3f9-0141-485b-8de9-94314ed4f10e (10.10.1.2:9866).
2019-02-22 18:06:52,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=686ff710-55de-4f47-bdc7-8b03cef69352, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage 686ff710-55de-4f47-bdc7-8b03cef69352
2019-02-22 18:06:52,986 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-22 18:06:52,986 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 686ff710-55de-4f47-bdc7-8b03cef69352 (10.10.1.5:9866).
2019-02-22 18:06:52,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf for DN 10.10.1.3:9866
2019-02-22 18:06:53,000 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 for DN 10.10.1.5:9866
2019-02-22 18:06:53,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 for DN 10.10.1.2:9866
2019-02-22 18:06:53,014 INFO BlockStateChange: BLOCK* processReport 0xa6776519114ad2f1: Processing first storage report for DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 from datanode 69e9a3f9-0141-485b-8de9-94314ed4f10e
2019-02-22 18:06:53,023 INFO BlockStateChange: BLOCK* processReport 0xa6776519114ad2f1: from storage DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=69e9a3f9-0141-485b-8de9-94314ed4f10e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 120, hasStaleStorage: false, processing time: 9 msecs, invalidatedBlocks: 0
2019-02-22 18:06:53,023 INFO BlockStateChange: BLOCK* processReport 0xf30fb5c818c55cce: Processing first storage report for DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf from datanode e62e641d-cd9d-41d8-9287-df1c100157c2
2019-02-22 18:06:53,026 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 159 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 30 seconds.
2019-02-22 18:06:53,027 INFO BlockStateChange: BLOCK* processReport 0xf30fb5c818c55cce: from storage DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e62e641d-cd9d-41d8-9287-df1c100157c2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 160, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2019-02-22 18:06:53,027 INFO BlockStateChange: BLOCK* processReport 0x3867e07a00bf05a4: Processing first storage report for DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 from datanode 686ff710-55de-4f47-bdc7-8b03cef69352
2019-02-22 18:06:53,030 INFO BlockStateChange: BLOCK* processReport 0x3867e07a00bf05a4: from storage DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=686ff710-55de-4f47-bdc7-8b03cef69352, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 144, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2019-02-22 18:07:13,032 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 160 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-02-22 18:07:23,033 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2019-02-22 18:07:23,033 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 30 secs
2019-02-22 18:07:23,033 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2019-02-22 18:07:23,033 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-22 18:08:52,342 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:08:52,598 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@22866368 expecting start txid #1675
2019-02-22 18:08:52,598 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:08:52,599 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1675
2019-02-22 18:08:52,599 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1675
2019-02-22 18:08:52,640 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 31096 edits # 560 loaded in 0 seconds
2019-02-22 18:10:52,648 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:10:52,848 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@c247204 expecting start txid #2235
2019-02-22 18:10:52,848 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:10:52,848 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 2235
2019-02-22 18:10:52,848 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 2235
2019-02-22 18:10:52,851 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 404 edits # 4 loaded in 0 seconds
2019-02-22 18:12:52,859 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:12:53,084 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@511ead38 expecting start txid #2239
2019-02-22 18:12:53,084 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:12:53,084 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 2239
2019-02-22 18:12:53,084 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 2239
2019-02-22 18:12:53,111 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 27838 edits # 501 loaded in 0 seconds
2019-02-22 18:14:53,118 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:14:53,317 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4d97fd36 expecting start txid #2740
2019-02-22 18:14:53,317 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:14:53,317 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 2740
2019-02-22 18:14:53,317 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 2740
2019-02-22 18:14:53,323 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 3669 edits # 63 loaded in 0 seconds
2019-02-22 18:16:53,330 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:16:53,527 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@23cabe0c expecting start txid #2803
2019-02-22 18:16:53,527 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:16:53,528 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 2803
2019-02-22 18:16:53,528 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 2803
2019-02-22 18:16:53,541 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 11320 edits # 224 loaded in 0 seconds
2019-02-22 18:17:00,263 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-02-22 18:17:00,264 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-02-22 18:17:00,266 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-22 18:17:00,274 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-02-22 18:17:00,327 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 6
2019-02-22 18:17:00,328 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 3027
2019-02-22 18:17:00,347 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.2:8485: segmentState { startTxId: 3027 endTxId: 3041 isInProgress: true } lastWriterEpoch: 5 lastCommittedTxId: 3040
10.10.1.5:8485: segmentState { startTxId: 3027 endTxId: 3041 isInProgress: true } lastWriterEpoch: 5 lastCommittedTxId: 3040
2019-02-22 18:17:00,349 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.2:8485=segmentState {
  startTxId: 3027
  endTxId: 3041
  isInProgress: true
}
lastWriterEpoch: 5
lastCommittedTxId: 3040

2019-02-22 18:17:00,390 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-02-22 18:17:00,408 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000001674 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000001674-0000000000000001674
2019-02-22 18:17:00,425 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-02-22 18:17:00,428 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4a763fe expecting start txid #3027
2019-02-22 18:17:00,429 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:00,429 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 3027
2019-02-22 18:17:00,429 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 3027
2019-02-22 18:17:00,435 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 15 loaded in 0 seconds
2019-02-22 18:17:00,435 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-02-22 18:17:00,436 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-02-22 18:17:00,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-22 18:17:00,436 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 3042
2019-02-22 18:17:00,438 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3042
2019-02-22 18:17:00,745 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 100 
2019-02-22 18:17:00,768 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-22 18:17:00,772 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 4 milliseconds
name space=18
storage space=30198988800
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-02-22 18:17:00,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-22 18:17:00,839 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 75
2019-02-22 18:17:00,840 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-22 18:17:00,840 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-22 18:17:00,840 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-22 18:17:00,840 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 16
2019-02-22 18:17:00,840 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 404 msec
2019-02-22 18:17:00,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-22 18:17:00,857 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-22 18:17:00,857 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-22 18:17:00,857 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-22 18:17:00,859 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742692_1868, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-22 18:17:00,893 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-22 18:17:00,893 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-22 18:17:00,893 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-22 18:17:00,893 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-22 18:17:00,893 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-22 18:17:00,893 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-22 18:17:00,893 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742693_1869, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile13._COPYING_
2019-02-22 18:17:00,894 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-22 18:17:00,894 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-22 18:17:00,894 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-22 18:17:00,894 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-22 18:17:00,894 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742694_1870, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-02-22 18:17:00,894 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-22 18:17:00,894 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-22 18:17:00,894 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-22 18:17:00,894 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-22 18:17:00,894 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-22 18:17:00,894 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-22 18:17:00,894 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-22 18:17:00,894 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742695_1871, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-22 18:17:00,895 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742696_1872, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-22 18:17:00,895 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742697_1873, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-22 18:17:00,896 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-22 18:17:00,896 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-22 18:17:00,896 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-22 18:17:00,896 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-22 18:17:00,896 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-22 18:17:00,896 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-22 18:17:00,896 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-22 18:17:00,896 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-22 18:17:00,896 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742698_1874, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-22 18:17:00,896 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-22 18:17:00,896 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-22 18:17:00,896 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-22 18:17:00,896 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-22 18:17:00,896 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742699_1875, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-22 18:17:00,896 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-22 18:17:00,897 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742700_1876, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-22 18:17:00,897 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742701_1877, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-22 18:17:01,087 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-22 18:17:01,087 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-22 18:17:01,087 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-22 18:17:01,088 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-22 18:17:01,088 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742702_1878, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-22 18:17:01,780 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-22 18:17:01,780 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-22 18:17:01,780 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-22 18:17:01,780 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-22 18:17:01,780 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742703_1879, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-22 18:17:02,057 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742704_1880, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile17._COPYING_
2019-02-22 18:17:04,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742705_1881, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-22 18:17:04,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742706_1882, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-22 18:17:04,865 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742707_1883, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-22 18:17:04,865 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742708_1884, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-02-22 18:17:04,865 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742709_1885, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-22 18:17:04,866 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742710_1886, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-22 18:17:04,869 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742711_1887, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-22 18:17:04,874 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742712_1888, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-22 18:17:06,391 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742713_1889, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-22 18:17:06,392 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742714_1890, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile17._COPYING_
2019-02-22 18:17:06,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742715_1891, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-22 18:17:06,397 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742716_1892, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-22 18:17:06,397 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742717_1893, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-22 18:17:06,399 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742718_1894, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-22 18:17:06,445 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742719_1895, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-22 18:17:06,445 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742720_1896, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-22 18:17:06,445 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742721_1897, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-22 18:17:08,595 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742722_1898, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-22 18:17:08,643 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742723_1899, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-22 18:17:08,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742724_1900, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-22 18:17:08,645 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742725_1901, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-02-22 18:17:08,645 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742726_1902, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-22 18:17:08,646 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742727_1903, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-22 18:17:08,646 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742728_1904, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile10._COPYING_
2019-02-22 18:17:08,646 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742729_1905, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-22 18:17:08,646 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742730_1906, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-22 18:17:08,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742731_1907, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-22 18:17:08,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742732_1908, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-22 18:17:08,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742733_1909, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-22 18:17:08,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742734_1910, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-22 18:17:08,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742735_1911, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-22 18:17:08,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742736_1912, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-22 18:17:08,649 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile15._COPYING_ is closed by DFSClient_NONMAPREDUCE_650745678_1
2019-02-22 18:17:08,649 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile9._COPYING_ is closed by DFSClient_NONMAPREDUCE_1824282712_1
2019-02-22 18:17:08,649 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2123494212_1
2019-02-22 18:17:09,761 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742737_1913, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-22 18:17:09,788 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742738_1914, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile19._COPYING_
2019-02-22 18:17:10,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742739_1915, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-22 18:17:10,386 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile7._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1689108132_1
2019-02-22 18:17:10,386 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742740_1916, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile10._COPYING_
2019-02-22 18:17:10,418 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742741_1917, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-22 18:17:10,459 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742742_1918, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-22 18:17:10,510 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile6._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1881604499_1
2019-02-22 18:17:10,518 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742743_1919, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-22 18:17:10,535 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742744_1920, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-22 18:17:10,539 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742745_1921, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-22 18:17:10,554 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742746_1922, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-22 18:17:10,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742747_1923, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile11._COPYING_
2019-02-22 18:17:10,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742748_1924, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-02-22 18:17:11,401 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile10._COPYING_ is closed by DFSClient_NONMAPREDUCE_63947294_1
2019-02-22 18:17:11,402 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742749_1925, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile13._COPYING_
2019-02-22 18:17:11,403 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile12._COPYING_ is closed by DFSClient_NONMAPREDUCE_-481209853_1
2019-02-22 18:17:11,404 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742750_1926, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-22 18:17:11,424 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile14._COPYING_ is closed by DFSClient_NONMAPREDUCE_-800199999_1
2019-02-22 18:17:11,427 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742751_1927, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-22 18:17:11,501 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742752_1928, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-22 18:17:12,086 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile16._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1141133872_1
2019-02-22 18:17:12,296 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742753_1929, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-22 18:17:12,332 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742754_1930, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-22 18:17:12,551 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile3._COPYING_ is closed by DFSClient_NONMAPREDUCE_1440701933_1
2019-02-22 18:17:12,565 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742755_1931, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-22 18:17:17,637 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742756_1932, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-22 18:17:17,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742757_1933, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-22 18:17:17,639 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742758_1934, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-22 18:17:17,639 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742759_1935, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-22 18:17:17,640 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742760_1936, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-22 18:17:17,641 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_350136258_1
2019-02-22 18:17:17,642 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile18._COPYING_ is closed by DFSClient_NONMAPREDUCE_522472201_1
2019-02-22 18:17:17,642 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742761_1937, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-22 18:17:17,643 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742762_1938, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile11._COPYING_
2019-02-22 18:17:20,755 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742763_1939, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-22 18:17:21,431 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742764_1940, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-22 18:17:21,431 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742765_1941, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-22 18:17:21,432 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742766_1942, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-22 18:17:21,437 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile17._COPYING_ is closed by DFSClient_NONMAPREDUCE_-368811481_1
2019-02-22 18:17:22,892 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742767_1943, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-22 18:17:23,968 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742768_1944, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-22 18:17:23,970 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile13._COPYING_ is closed by DFSClient_NONMAPREDUCE_1039419077_1
2019-02-22 18:17:24,488 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile8._COPYING_ is closed by DFSClient_NONMAPREDUCE_1611111473_1
2019-02-22 18:17:24,554 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742769_1945, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-22 18:17:24,751 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile19._COPYING_ is closed by DFSClient_NONMAPREDUCE_328537351_1
2019-02-22 18:17:24,814 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742770_1946, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-22 18:17:24,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742771_1947, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-22 18:17:25,329 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742772_1948, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-22 18:17:25,517 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742773_1949, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-22 18:17:25,563 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742774_1950, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-22 18:17:25,684 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742775_1951, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-22 18:17:28,471 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742776_1952, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-22 18:17:28,472 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742777_1953, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-22 18:17:28,914 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-591239242_1
2019-02-22 18:17:28,916 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742778_1954, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-22 18:17:29,317 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742779_1955, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile20._COPYING_
2019-02-22 18:17:29,345 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_1044318748_1
2019-02-22 18:17:29,386 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742780_1956, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-22 18:17:29,759 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742781_1957, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-22 18:17:29,798 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742782_1958, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-22 18:17:31,070 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742783_1959, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile20._COPYING_
2019-02-22 18:17:31,072 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile11._COPYING_ is closed by DFSClient_NONMAPREDUCE_-131439388_1
2019-02-22 18:17:33,022 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742784_1960, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-22 18:17:35,410 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-22 18:17:35,412 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode058.clemson.cloudlab.us/130.127.133.67
************************************************************/
2019-02-22 18:17:52,440 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode058.clemson.cloudlab.us/130.127.133.67
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-18T22:18Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-22 18:17:52,450 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-22 18:17:52,455 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-22 18:17:52,741 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-22 18:17:52,846 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-22 18:17:52,846 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-22 18:17:52,897 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-22 18:17:52,898 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-22 18:17:53,062 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-22 18:17:53,089 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-22 18:17:53,107 INFO org.eclipse.jetty.util.log: Logging initialized @1175ms
2019-02-22 18:17:53,215 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-22 18:17:53,229 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-22 18:17:53,240 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-22 18:17:53,243 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-22 18:17:53,243 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-22 18:17:53,243 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-22 18:17:53,270 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-22 18:17:53,270 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-22 18:17:53,280 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-22 18:17:53,281 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-22 18:17:53,316 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-22 18:17:53,317 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-22 18:17:53,392 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-22 18:17:53,413 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-22 18:17:53,414 INFO org.eclipse.jetty.server.Server: Started @1483ms
2019-02-22 18:17:53,777 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-22 18:17:53,835 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-22 18:17:53,850 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-22 18:17:53,851 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-22 18:17:53,854 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-22 18:17:53,860 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-22 18:17:53,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-22 18:17:53,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-22 18:17:53,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-22 18:17:53,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-22 18:17:53,904 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-22 18:17:53,916 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-22 18:17:53,916 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-22 18:17:53,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-22 18:17:53,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 22 18:17:53
2019-02-22 18:17:53,923 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-22 18:17:53,924 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 18:17:53,925 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-22 18:17:53,925 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-22 18:17:54,062 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-22 18:17:54,072 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-22 18:17:54,072 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-22 18:17:54,072 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-22 18:17:54,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-22 18:17:54,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-22 18:17:54,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-22 18:17:54,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-22 18:17:54,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-22 18:17:54,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-22 18:17:54,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-22 18:17:54,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-22 18:17:54,157 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-22 18:17:54,157 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 18:17:54,157 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-22 18:17:54,157 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-22 18:17:54,230 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-22 18:17:54,231 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-22 18:17:54,231 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-22 18:17:54,231 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-22 18:17:54,238 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-22 18:17:54,241 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-22 18:17:54,246 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-22 18:17:54,246 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 18:17:54,246 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-22 18:17:54,247 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-22 18:17:54,274 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-22 18:17:54,275 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-22 18:17:54,275 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-22 18:17:54,279 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-22 18:17:54,279 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-22 18:17:54,281 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-22 18:17:54,281 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 18:17:54,282 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-22 18:17:54,282 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-22 18:17:54,364 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 2059@clnode058.clemson.cloudlab.us
2019-02-22 18:17:55,581 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1015ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1085ms
2019-02-22 18:17:55,754 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-22 18:17:55,816 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-22 18:17:55,818 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-22 18:17:55,848 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-22 18:17:55,848 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-22 18:17:55,853 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-02-22 18:17:55,853 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:55,857 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:55,857 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:55,985 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-02-22 18:17:55,985 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #542
2019-02-22 18:17:55,985 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:55,985 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:55,985 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:55,989 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-22 18:17:55,989 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a7288a3 expecting start txid #543
2019-02-22 18:17:55,989 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:55,989 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:55,989 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,001 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 100 edits # 3 loaded in 0 seconds
2019-02-22 18:17:56,001 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2974f221 expecting start txid #546
2019-02-22 18:17:56,001 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:56,002 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,002 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,040 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 31402 edits # 561 loaded in 0 seconds
2019-02-22 18:17:56,040 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@58fe0499 expecting start txid #1107
2019-02-22 18:17:56,040 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:56,040 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,040 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,042 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 42 edits # 2 loaded in 0 seconds
2019-02-22 18:17:56,042 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@686449f9 expecting start txid #1109
2019-02-22 18:17:56,042 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:56,042 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,042 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,066 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 27687 edits # 501 loaded in 0 seconds
2019-02-22 18:17:56,066 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@665df3c6 expecting start txid #1610
2019-02-22 18:17:56,066 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:56,066 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,066 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,071 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 3818 edits # 63 loaded in 0 seconds
2019-02-22 18:17:56,071 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68b6f0d6 expecting start txid #1673
2019-02-22 18:17:56,071 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:56,071 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,071 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,074 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-22 18:17:56,074 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4044fb95 expecting start txid #1674
2019-02-22 18:17:56,074 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:56,074 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,074 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,077 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-22 18:17:56,077 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@aa549e5 expecting start txid #1675
2019-02-22 18:17:56,078 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:56,078 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,078 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,098 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 31096 edits # 560 loaded in 0 seconds
2019-02-22 18:17:56,098 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@36f48b4 expecting start txid #2235
2019-02-22 18:17:56,098 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:56,099 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,099 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,102 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 404 edits # 4 loaded in 0 seconds
2019-02-22 18:17:56,102 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5c00384f expecting start txid #2239
2019-02-22 18:17:56,102 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:56,102 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,102 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,121 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 27838 edits # 501 loaded in 0 seconds
2019-02-22 18:17:56,121 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3b7ff809 expecting start txid #2740
2019-02-22 18:17:56,121 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:56,121 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,121 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,124 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 3669 edits # 63 loaded in 0 seconds
2019-02-22 18:17:56,124 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1bb564e2 expecting start txid #2803
2019-02-22 18:17:56,124 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:56,125 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,125 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,133 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 11320 edits # 224 loaded in 0 seconds
2019-02-22 18:17:56,133 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@62e6b5c8 expecting start txid #3027
2019-02-22 18:17:56,133 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:56,133 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,134 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,139 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 15 loaded in 0 seconds
2019-02-22 18:17:56,139 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3f792b9b expecting start txid #3042
2019-02-22 18:17:56,139 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:17:56,139 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,139 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:17:56,152 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 323 loaded in 0 seconds
2019-02-22 18:17:56,152 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-22 18:17:56,152 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-22 18:17:56,152 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1862 msecs
2019-02-22 18:17:56,335 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-22 18:17:56,340 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-22 18:17:56,352 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-22 18:17:56,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-22 18:17:56,560 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 1
2019-02-22 18:17:56,571 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 158 blocks to reach the threshold 0.9990 of total blocks 159.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-02-22 18:17:56,601 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-22 18:17:56,601 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-22 18:17:56,604 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-22 18:17:56,606 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-22 18:17:56,611 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-22 18:17:56,617 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-22 18:17:57,628 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=69e9a3f9-0141-485b-8de9-94314ed4f10e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage 69e9a3f9-0141-485b-8de9-94314ed4f10e
2019-02-22 18:17:57,629 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-22 18:17:57,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 69e9a3f9-0141-485b-8de9-94314ed4f10e (10.10.1.2:9866).
2019-02-22 18:17:57,631 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e62e641d-cd9d-41d8-9287-df1c100157c2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage e62e641d-cd9d-41d8-9287-df1c100157c2
2019-02-22 18:17:57,631 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-22 18:17:57,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e62e641d-cd9d-41d8-9287-df1c100157c2 (10.10.1.3:9866).
2019-02-22 18:17:57,632 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=686ff710-55de-4f47-bdc7-8b03cef69352, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage 686ff710-55de-4f47-bdc7-8b03cef69352
2019-02-22 18:17:57,632 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-22 18:17:57,632 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 686ff710-55de-4f47-bdc7-8b03cef69352 (10.10.1.5:9866).
2019-02-22 18:17:57,642 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 for DN 10.10.1.2:9866
2019-02-22 18:17:57,645 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf for DN 10.10.1.3:9866
2019-02-22 18:17:57,646 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 for DN 10.10.1.5:9866
2019-02-22 18:17:57,658 INFO BlockStateChange: BLOCK* processReport 0xf30fb5c818c55ccf: Processing first storage report for DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf from datanode e62e641d-cd9d-41d8-9287-df1c100157c2
2019-02-22 18:17:57,669 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 158 has reached the threshold 0.9990 of total blocks 159. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2019-02-22 18:17:57,669 INFO BlockStateChange: BLOCK* processReport 0xf30fb5c818c55ccf: from storage DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e62e641d-cd9d-41d8-9287-df1c100157c2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 176, hasStaleStorage: false, processing time: 11 msecs, invalidatedBlocks: 0
2019-02-22 18:17:57,670 INFO BlockStateChange: BLOCK* processReport 0xa6776519114ad2f2: Processing first storage report for DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 from datanode 69e9a3f9-0141-485b-8de9-94314ed4f10e
2019-02-22 18:17:57,673 INFO BlockStateChange: BLOCK* processReport 0xa6776519114ad2f2: from storage DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=69e9a3f9-0141-485b-8de9-94314ed4f10e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 176, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2019-02-22 18:17:57,673 INFO BlockStateChange: BLOCK* processReport 0x3867e07a00bf05a5: Processing first storage report for DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 from datanode 686ff710-55de-4f47-bdc7-8b03cef69352
2019-02-22 18:17:57,675 INFO BlockStateChange: BLOCK* processReport 0x3867e07a00bf05a5: from storage DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=686ff710-55de-4f47-bdc7-8b03cef69352, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 176, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-02-22 18:18:17,671 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 159 has reached the threshold 0.9990 of total blocks 159. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-02-22 18:18:27,672 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2019-02-22 18:18:27,672 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 31 secs
2019-02-22 18:18:27,673 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2019-02-22 18:18:27,673 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-22 18:19:56,629 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:19:56,892 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@d0aa37b expecting start txid #3365
2019-02-22 18:19:56,892 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:19:56,893 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 3365
2019-02-22 18:19:56,893 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 3365
2019-02-22 18:19:56,898 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 407 edits # 4 loaded in 0 seconds
2019-02-22 18:21:56,905 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:21:57,135 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6be5b224 expecting start txid #3369
2019-02-22 18:21:57,135 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:21:57,136 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 3369
2019-02-22 18:21:57,136 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 3369
2019-02-22 18:21:57,159 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 14013 edits # 280 loaded in 0 seconds
2019-02-22 18:23:57,167 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:23:57,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@16824f69 expecting start txid #3649
2019-02-22 18:23:57,362 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:23:57,362 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 3649
2019-02-22 18:23:57,362 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 3649
2019-02-22 18:23:57,380 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 17496 edits # 284 loaded in 0 seconds
2019-02-22 18:25:57,386 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:25:57,586 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@637231f4 expecting start txid #3933
2019-02-22 18:25:57,586 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:25:57,586 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 3933
2019-02-22 18:25:57,586 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 3933
2019-02-22 18:25:57,592 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 2108 edits # 38 loaded in 0 seconds
2019-02-22 18:27:57,600 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:27:57,788 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@15caec5d expecting start txid #3971
2019-02-22 18:27:57,788 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:27:57,788 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 3971
2019-02-22 18:27:57,788 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 3971
2019-02-22 18:27:57,813 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 29403 edits # 526 loaded in 0 seconds
2019-02-22 18:28:04,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-02-22 18:28:04,756 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-02-22 18:28:04,759 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-22 18:28:04,766 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-02-22 18:28:04,802 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 8
2019-02-22 18:28:04,802 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 4497
2019-02-22 18:28:04,822 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
10.10.1.5:8485: segmentState { startTxId: 4497 endTxId: 4497 isInProgress: true } lastWriterEpoch: 7 lastCommittedTxId: 4496
10.10.1.2:8485: segmentState { startTxId: 4497 endTxId: 4497 isInProgress: true } lastWriterEpoch: 7 lastCommittedTxId: 4496
2019-02-22 18:28:04,824 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 10.10.1.5:8485=segmentState {
  startTxId: 4497
  endTxId: 4497
  isInProgress: true
}
lastWriterEpoch: 7
lastCommittedTxId: 4496

2019-02-22 18:28:04,864 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-02-22 18:28:04,883 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000003042 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000003042-0000000000000003364
2019-02-22 18:28:04,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-02-22 18:28:04,905 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5c62b523 expecting start txid #4497
2019-02-22 18:28:04,905 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:28:04,905 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 4497
2019-02-22 18:28:04,905 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 4497
2019-02-22 18:28:04,911 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-22 18:28:04,911 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-02-22 18:28:04,912 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-02-22 18:28:04,912 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-22 18:28:04,912 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 4498
2019-02-22 18:28:04,915 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4498
2019-02-22 18:28:05,199 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 93 
2019-02-22 18:28:05,229 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-22 18:28:05,233 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 3 milliseconds
name space=21
storage space=64424509440
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-02-22 18:28:05,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-22 18:28:05,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 160
2019-02-22 18:28:05,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-22 18:28:05,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-22 18:28:05,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-22 18:28:05,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-02-22 18:28:05,299 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 387 msec
2019-02-22 18:28:39,434 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-22 18:28:39,436 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode058.clemson.cloudlab.us/130.127.133.67
************************************************************/
2019-02-22 18:28:56,466 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode058.clemson.cloudlab.us/130.127.133.67
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-18T22:18Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-22 18:28:56,476 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-22 18:28:56,481 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-22 18:28:56,775 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-22 18:28:56,880 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-22 18:28:56,881 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-22 18:28:56,932 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-22 18:28:56,932 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-22 18:28:57,095 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-22 18:28:57,123 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-22 18:28:57,140 INFO org.eclipse.jetty.util.log: Logging initialized @1182ms
2019-02-22 18:28:57,247 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-22 18:28:57,261 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-22 18:28:57,271 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-22 18:28:57,274 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-22 18:28:57,275 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-22 18:28:57,275 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-22 18:28:57,301 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-22 18:28:57,301 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-22 18:28:57,310 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-22 18:28:57,311 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-22 18:28:57,347 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-22 18:28:57,348 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-22 18:28:57,423 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-22 18:28:57,445 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-22 18:28:57,445 INFO org.eclipse.jetty.server.Server: Started @1489ms
2019-02-22 18:28:57,781 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-22 18:28:57,832 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-22 18:28:57,846 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-22 18:28:57,847 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-22 18:28:57,850 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-22 18:28:57,857 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-22 18:28:57,857 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-22 18:28:57,857 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-22 18:28:57,857 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-22 18:28:57,857 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-22 18:28:57,900 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-22 18:28:57,912 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-22 18:28:57,912 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-22 18:28:57,917 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-22 18:28:57,917 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 22 18:28:57
2019-02-22 18:28:57,919 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-22 18:28:57,919 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 18:28:57,921 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-22 18:28:57,921 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-22 18:28:58,063 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-22 18:28:58,073 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-22 18:28:58,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-22 18:28:58,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-22 18:28:58,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-22 18:28:58,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-22 18:28:58,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-22 18:28:58,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-22 18:28:58,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-22 18:28:58,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-22 18:28:58,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-22 18:28:58,074 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-22 18:28:58,158 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-22 18:28:58,158 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 18:28:58,158 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-22 18:28:58,158 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-22 18:28:58,231 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-22 18:28:58,231 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-22 18:28:58,231 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-22 18:28:58,231 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-22 18:28:58,238 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-22 18:28:58,241 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-22 18:28:58,247 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-22 18:28:58,247 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 18:28:58,247 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-22 18:28:58,247 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-22 18:28:58,274 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-22 18:28:58,275 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-22 18:28:58,275 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-22 18:28:58,279 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-22 18:28:58,279 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-22 18:28:58,281 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-22 18:28:58,281 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-22 18:28:58,281 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-22 18:28:58,281 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-22 18:28:58,351 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 3075@clnode058.clemson.cloudlab.us
2019-02-22 18:28:59,741 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-22 18:28:59,803 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-22 18:28:59,805 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-22 18:28:59,836 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-22 18:28:59,836 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-22 18:28:59,841 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@abf688e expecting start txid #1
2019-02-22 18:28:59,841 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:28:59,845 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:28:59,845 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:28:59,963 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 541 loaded in 0 seconds
2019-02-22 18:28:59,963 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@478ee483 expecting start txid #542
2019-02-22 18:28:59,963 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:28:59,964 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:28:59,964 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:28:59,967 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=542&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-22 18:28:59,967 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a7288a3 expecting start txid #543
2019-02-22 18:28:59,967 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:28:59,968 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:28:59,968 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:28:59,978 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=543&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 100 edits # 3 loaded in 0 seconds
2019-02-22 18:28:59,978 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2974f221 expecting start txid #546
2019-02-22 18:28:59,978 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:28:59,978 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:28:59,978 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,022 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=546&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 31402 edits # 561 loaded in 0 seconds
2019-02-22 18:29:00,022 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@58fe0499 expecting start txid #1107
2019-02-22 18:29:00,022 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,022 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,022 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,023 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1107&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 42 edits # 2 loaded in 0 seconds
2019-02-22 18:29:00,023 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@686449f9 expecting start txid #1109
2019-02-22 18:29:00,024 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,024 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,024 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,049 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1109&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 27687 edits # 501 loaded in 0 seconds
2019-02-22 18:29:00,049 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@665df3c6 expecting start txid #1610
2019-02-22 18:29:00,049 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,049 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,050 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,055 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1610&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 3818 edits # 63 loaded in 0 seconds
2019-02-22 18:29:00,055 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68b6f0d6 expecting start txid #1673
2019-02-22 18:29:00,055 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,055 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,055 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,058 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1673&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-22 18:29:00,058 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4044fb95 expecting start txid #1674
2019-02-22 18:29:00,058 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,059 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,059 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,063 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1674&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-22 18:29:00,064 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@aa549e5 expecting start txid #1675
2019-02-22 18:29:00,064 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,064 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,064 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,088 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1675&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 31096 edits # 560 loaded in 0 seconds
2019-02-22 18:29:00,088 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@36f48b4 expecting start txid #2235
2019-02-22 18:29:00,088 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,088 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,088 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2235&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 404 edits # 4 loaded in 0 seconds
2019-02-22 18:29:00,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5c00384f expecting start txid #2239
2019-02-22 18:29:00,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,090 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,091 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,110 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2239&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 27838 edits # 501 loaded in 0 seconds
2019-02-22 18:29:00,110 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3b7ff809 expecting start txid #2740
2019-02-22 18:29:00,110 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,110 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,110 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,113 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2740&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 3669 edits # 63 loaded in 0 seconds
2019-02-22 18:29:00,113 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1bb564e2 expecting start txid #2803
2019-02-22 18:29:00,113 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,114 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,114 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,122 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=2803&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 11320 edits # 224 loaded in 0 seconds
2019-02-22 18:29:00,123 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@62e6b5c8 expecting start txid #3027
2019-02-22 18:29:00,123 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,123 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,123 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,126 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3027&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 15 loaded in 0 seconds
2019-02-22 18:29:00,127 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3f792b9b expecting start txid #3042
2019-02-22 18:29:00,127 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,127 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,127 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,138 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3042&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 323 loaded in 0 seconds
2019-02-22 18:29:00,138 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7b8233cd expecting start txid #3365
2019-02-22 18:29:00,138 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,138 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,138 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,140 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3365&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 407 edits # 4 loaded in 0 seconds
2019-02-22 18:29:00,140 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4b20ca2b expecting start txid #3369
2019-02-22 18:29:00,140 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,140 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,140 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,150 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3369&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 14013 edits # 280 loaded in 0 seconds
2019-02-22 18:29:00,150 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1cbf6e72 expecting start txid #3649
2019-02-22 18:29:00,150 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,150 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,150 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,160 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3649&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 17496 edits # 284 loaded in 0 seconds
2019-02-22 18:29:00,160 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6aecbb8d expecting start txid #3933
2019-02-22 18:29:00,160 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,160 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,160 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,164 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3933&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 2108 edits # 38 loaded in 0 seconds
2019-02-22 18:29:00,164 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1af146 expecting start txid #3971
2019-02-22 18:29:00,164 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,164 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,164 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,178 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=3971&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 29403 edits # 526 loaded in 0 seconds
2019-02-22 18:29:00,178 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4da602fc expecting start txid #4497
2019-02-22 18:29:00,178 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,178 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,178 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,181 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4497&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-22 18:29:00,181 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2a8d39c4 expecting start txid #4498
2019-02-22 18:29:00,181 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4498&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4498&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4498&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:29:00,181 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4498&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4498&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4498&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,181 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4498&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 1
2019-02-22 18:29:00,184 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4498&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4498&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4498&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-02-22 18:29:00,185 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-22 18:29:00,185 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-22 18:29:00,185 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1896 msecs
2019-02-22 18:29:00,379 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-22 18:29:00,384 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-22 18:29:00,397 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-22 18:29:00,592 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-22 18:29:00,602 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-22 18:29:00,614 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 159 blocks to reach the threshold 0.9990 of total blocks 160.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-02-22 18:29:00,645 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-22 18:29:00,645 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-22 18:29:00,648 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-22 18:29:00,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-22 18:29:00,655 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-22 18:29:00,661 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-22 18:29:01,402 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e62e641d-cd9d-41d8-9287-df1c100157c2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage e62e641d-cd9d-41d8-9287-df1c100157c2
2019-02-22 18:29:01,403 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-22 18:29:01,404 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN e62e641d-cd9d-41d8-9287-df1c100157c2 (10.10.1.3:9866).
2019-02-22 18:29:01,405 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=686ff710-55de-4f47-bdc7-8b03cef69352, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage 686ff710-55de-4f47-bdc7-8b03cef69352
2019-02-22 18:29:01,405 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-22 18:29:01,406 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 686ff710-55de-4f47-bdc7-8b03cef69352 (10.10.1.5:9866).
2019-02-22 18:29:01,406 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=69e9a3f9-0141-485b-8de9-94314ed4f10e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697) storage 69e9a3f9-0141-485b-8de9-94314ed4f10e
2019-02-22 18:29:01,406 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-22 18:29:01,406 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 69e9a3f9-0141-485b-8de9-94314ed4f10e (10.10.1.2:9866).
2019-02-22 18:29:01,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 for DN 10.10.1.2:9866
2019-02-22 18:29:01,420 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 for DN 10.10.1.5:9866
2019-02-22 18:29:01,420 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf for DN 10.10.1.3:9866
2019-02-22 18:29:01,432 INFO BlockStateChange: BLOCK* processReport 0x3867e07a00bf05a6: Processing first storage report for DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 from datanode 686ff710-55de-4f47-bdc7-8b03cef69352
2019-02-22 18:29:01,443 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 159 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 30 seconds.
2019-02-22 18:29:01,443 INFO BlockStateChange: BLOCK* processReport 0x3867e07a00bf05a6: from storage DS-6b9bd9d2-8d87-4b64-b81d-4923b4b4a3f4 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=686ff710-55de-4f47-bdc7-8b03cef69352, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 176, hasStaleStorage: false, processing time: 11 msecs, invalidatedBlocks: 0
2019-02-22 18:29:01,444 INFO BlockStateChange: BLOCK* processReport 0xf30fb5c818c55cd0: Processing first storage report for DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf from datanode e62e641d-cd9d-41d8-9287-df1c100157c2
2019-02-22 18:29:01,447 INFO BlockStateChange: BLOCK* processReport 0xf30fb5c818c55cd0: from storage DS-c2e68d75-086e-4a42-b7d9-4dc26be5bdaf node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=e62e641d-cd9d-41d8-9287-df1c100157c2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 160, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2019-02-22 18:29:01,448 INFO BlockStateChange: BLOCK* processReport 0xa6776519114ad2f3: Processing first storage report for DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 from datanode 69e9a3f9-0141-485b-8de9-94314ed4f10e
2019-02-22 18:29:01,450 INFO BlockStateChange: BLOCK* processReport 0xa6776519114ad2f3: from storage DS-4be9ac31-fc9b-48c1-9246-0fcfb61b9993 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=69e9a3f9-0141-485b-8de9-94314ed4f10e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2e7df0e5-dd54-4249-9709-166365a5ecef;nsid=683626786;c=1550883193697), blocks: 176, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-02-22 18:29:21,446 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 160 has reached the threshold 0.9990 of total blocks 160. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-02-22 18:29:31,447 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2019-02-22 18:29:31,447 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 30 secs
2019-02-22 18:29:31,447 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2019-02-22 18:29:31,447 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-22 18:31:00,673 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:31:00,921 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6199c59 expecting start txid #4499
2019-02-22 18:31:00,921 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4499&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4499&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:31:00,922 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4499&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4499&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 4499
2019-02-22 18:31:00,922 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4499&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 4499
2019-02-22 18:31:00,928 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4499&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4499&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 494 edits # 9 loaded in 0 seconds
2019-02-22 18:33:00,937 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:33:01,131 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a842cef expecting start txid #4508
2019-02-22 18:33:01,131 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4508&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4508&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4508&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:33:01,131 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4508&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4508&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4508&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 4508
2019-02-22 18:33:01,131 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4508&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 4508
2019-02-22 18:33:01,162 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=4508&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=4508&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=4508&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 31011 edits # 555 loaded in 0 seconds
2019-02-22 18:35:01,169 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:35:01,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@16a29130 expecting start txid #5063
2019-02-22 18:35:01,364 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=5063&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=5063&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:35:01,365 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=5063&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=5063&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 5063
2019-02-22 18:35:01,365 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=5063&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 5063
2019-02-22 18:35:01,368 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=5063&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=5063&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 42 edits # 2 loaded in 0 seconds
2019-02-22 18:37:01,375 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:37:01,574 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5c4b13c2 expecting start txid #5065
2019-02-22 18:37:01,574 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=5065&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=5065&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:37:01,574 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=5065&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=5065&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 5065
2019-02-22 18:37:01,574 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=5065&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 5065
2019-02-22 18:37:01,599 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=5065&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=5065&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 31466 edits # 562 loaded in 0 seconds
2019-02-22 18:39:01,606 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode
2019-02-22 18:39:01,800 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@10fc03c6 expecting start txid #5627
2019-02-22 18:39:01,800 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=5627&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=5627&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=5627&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-02-22 18:39:01,800 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=5627&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=5627&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=5627&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 5627
2019-02-22 18:39:01,801 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=5627&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true' to transaction ID 5627
2019-02-22 18:39:01,804 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=5627&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=5627&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=5627&storageInfo=-64%3A683626786%3A1550883193697%3ACID-2e7df0e5-dd54-4249-9709-166365a5ecef&inProgressOk=true of size 42 edits # 2 loaded in 0 seconds
