2019-02-28 19:31:38,647 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode044.clemson.cloudlab.us/130.127.133.53
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-19T02:28Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-28 19:31:38,657 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-28 19:31:38,662 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-28 19:31:38,946 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-28 19:31:39,051 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-28 19:31:39,051 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-28 19:31:39,102 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-28 19:31:39,103 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-28 19:31:39,267 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-28 19:31:39,295 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-28 19:31:39,312 INFO org.eclipse.jetty.util.log: Logging initialized @1179ms
2019-02-28 19:31:39,420 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-28 19:31:39,433 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-28 19:31:39,444 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-28 19:31:39,447 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-28 19:31:39,447 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-28 19:31:39,447 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-28 19:31:39,474 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-28 19:31:39,474 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-28 19:31:39,484 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-28 19:31:39,485 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-28 19:31:39,520 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-28 19:31:39,521 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-28 19:31:39,595 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-28 19:31:39,615 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-28 19:31:39,616 INFO org.eclipse.jetty.server.Server: Started @1484ms
2019-02-28 19:31:39,947 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-28 19:31:40,005 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-28 19:31:40,019 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-28 19:31:40,021 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-28 19:31:40,023 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-28 19:31:40,030 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-28 19:31:40,030 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-28 19:31:40,030 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-28 19:31:40,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-28 19:31:40,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-28 19:31:40,074 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-28 19:31:40,086 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-28 19:31:40,086 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-28 19:31:40,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-28 19:31:40,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 28 19:31:40
2019-02-28 19:31:40,093 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-28 19:31:40,093 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-28 19:31:40,095 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-28 19:31:40,095 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-28 19:31:40,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-28 19:31:40,235 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-28 19:31:40,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-28 19:31:40,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-28 19:31:40,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-28 19:31:40,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-28 19:31:40,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-28 19:31:40,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-28 19:31:40,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-28 19:31:40,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-28 19:31:40,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-28 19:31:40,236 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-28 19:31:40,319 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-28 19:31:40,319 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-28 19:31:40,320 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-28 19:31:40,320 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-28 19:31:40,392 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-28 19:31:40,392 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-28 19:31:40,392 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-28 19:31:40,392 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-28 19:31:40,399 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-28 19:31:40,402 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-28 19:31:40,407 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-28 19:31:40,407 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-28 19:31:40,408 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-28 19:31:40,408 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-28 19:31:40,435 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-28 19:31:40,435 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-28 19:31:40,435 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-28 19:31:40,439 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-28 19:31:40,439 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-28 19:31:40,442 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-28 19:31:40,442 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-28 19:31:40,442 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-28 19:31:40,442 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-28 19:31:40,500 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 113678@clnode044.clemson.cloudlab.us
2019-02-28 19:31:41,871 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1100ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=310ms
GC pool 'PS Scavenge' had collection(s): count=1 time=925ms
2019-02-28 19:31:42,022 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2019-02-28 19:31:42,022 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-28 19:31:42,085 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-28 19:31:42,087 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-28 19:31:42,117 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-28 19:31:42,118 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-28 19:31:42,123 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-28 19:31:42,123 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-28 19:31:42,123 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1673 msecs
2019-02-28 19:31:42,304 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-28 19:31:42,309 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-28 19:31:42,321 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-28 19:31:42,508 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-28 19:31:42,517 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-28 19:31:42,527 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2019-02-28 19:31:42,527 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2019-02-28 19:31:42,527 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-28 19:31:42,560 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-28 19:31:42,560 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-28 19:31:42,563 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-28 19:31:42,566 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-28 19:31:42,571 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-28 19:31:42,577 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-28 19:31:47,545 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, fileSize: 389. Sent total: 389 bytes. Size of last segment intended to send: -1 bytes.
2019-02-28 19:31:47,725 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-28 19:31:47,727 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode044.clemson.cloudlab.us/130.127.133.53
************************************************************/
2019-02-28 19:31:58,663 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode044.clemson.cloudlab.us/130.127.133.53
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-02-19T02:28Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-28 19:31:58,673 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-28 19:31:58,677 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-02-28 19:31:58,967 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-28 19:31:59,071 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-28 19:31:59,071 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-02-28 19:31:59,122 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils: fs.defaultFS is hdfs://mycluster
2019-02-28 19:31:59,122 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients should use mycluster to access this namenode/service.
2019-02-28 19:31:59,282 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-28 19:31:59,309 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-02-28 19:31:59,327 INFO org.eclipse.jetty.util.log: Logging initialized @1180ms
2019-02-28 19:31:59,436 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-28 19:31:59,449 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-02-28 19:31:59,460 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-28 19:31:59,463 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-02-28 19:31:59,463 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-28 19:31:59,464 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-28 19:31:59,490 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-02-28 19:31:59,490 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-02-28 19:31:59,500 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
2019-02-28 19:31:59,501 INFO org.eclipse.jetty.server.Server: jetty-9.3.19.v20170502
2019-02-28 19:31:59,536 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c137fd5{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-02-28 19:31:59,537 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d9d0818{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-02-28 19:31:59,613 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@376a0d86{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-02-28 19:31:59,640 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@536dbea0{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-02-28 19:31:59,640 INFO org.eclipse.jetty.server.Server: Started @1494ms
2019-02-28 19:31:59,962 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-02-28 19:32:00,020 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-02-28 19:32:00,035 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-02-28 19:32:00,036 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-02-28 19:32:00,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-02-28 19:32:00,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2019-02-28 19:32:00,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-02-28 19:32:00,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-02-28 19:32:00,046 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: mycluster
2019-02-28 19:32:00,046 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2019-02-28 19:32:00,089 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-02-28 19:32:00,101 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-02-28 19:32:00,101 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-02-28 19:32:00,106 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-02-28 19:32:00,107 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Feb 28 19:32:00
2019-02-28 19:32:00,109 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-02-28 19:32:00,109 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-28 19:32:00,110 INFO org.apache.hadoop.util.GSet: 2.0% max memory 26.7 GB = 546.1 MB
2019-02-28 19:32:00,110 INFO org.apache.hadoop.util.GSet: capacity      = 2^26 = 67108864 entries
2019-02-28 19:32:00,249 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable = false
2019-02-28 19:32:00,258 INFO org.apache.hadoop.conf.Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-02-28 19:32:00,258 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-02-28 19:32:00,258 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-02-28 19:32:00,258 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-02-28 19:32:00,258 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-02-28 19:32:00,258 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-02-28 19:32:00,259 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-02-28 19:32:00,259 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-02-28 19:32:00,259 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
2019-02-28 19:32:00,259 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-02-28 19:32:00,259 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-02-28 19:32:00,344 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-02-28 19:32:00,344 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-28 19:32:00,344 INFO org.apache.hadoop.util.GSet: 1.0% max memory 26.7 GB = 273.0 MB
2019-02-28 19:32:00,344 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2019-02-28 19:32:00,417 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-02-28 19:32:00,417 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: POSIX ACL inheritance enabled? true
2019-02-28 19:32:00,417 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-02-28 19:32:00,417 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-02-28 19:32:00,424 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-02-28 19:32:00,427 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: SkipList is disabled
2019-02-28 19:32:00,433 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-02-28 19:32:00,433 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-28 19:32:00,433 INFO org.apache.hadoop.util.GSet: 0.25% max memory 26.7 GB = 68.3 MB
2019-02-28 19:32:00,433 INFO org.apache.hadoop.util.GSet: capacity      = 2^23 = 8388608 entries
2019-02-28 19:32:00,461 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-02-28 19:32:00,461 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-02-28 19:32:00,461 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-02-28 19:32:00,465 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-02-28 19:32:00,465 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-02-28 19:32:00,467 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-02-28 19:32:00,467 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-02-28 19:32:00,468 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-02-28 19:32:00,468 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-02-28 19:32:00,530 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 114364@clnode044.clemson.cloudlab.us
2019-02-28 19:32:02,085 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1299ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=332ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1094ms
2019-02-28 19:32:03,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:03,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:03,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-1-link-0/10.10.1.4:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:04,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:04,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-1-link-0/10.10.1.4:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:04,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:05,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:05,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-1-link-0/10.10.1.4:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:05,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:06,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-1-link-0/10.10.1.4:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:06,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:06,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:06,638 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-02-28 19:32:07,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-1-link-0/10.10.1.4:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:07,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:07,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-28 19:32:07,552 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2019-02-28 19:32:07,552 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-02-28 19:32:07,616 INFO org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager: Enable the erasure coding policy RS-6-3-1024k
2019-02-28 19:32:07,618 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-02-28 19:32:07,649 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-02-28 19:32:07,649 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-02-28 19:32:07,655 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-02-28 19:32:07,655 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-02-28 19:32:07,655 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 7180 msecs
2019-02-28 19:32:07,835 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to node-0-link-0:8020
2019-02-28 19:32:07,840 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-28 19:32:07,852 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2019-02-28 19:32:08,042 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-02-28 19:32:08,051 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-02-28 19:32:08,063 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2019-02-28 19:32:08,063 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2019-02-28 19:32:08,063 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-02-28 19:32:08,097 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-28 19:32:08,098 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2019-02-28 19:32:08,101 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-02-28 19:32:08,104 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2019-02-28 19:32:08,109 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2019-02-28 19:32:08,115 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-02-28 19:32:08,706 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=8d3d4cbe-4911-4156-8dc4-126b9d979b60, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811) storage 8d3d4cbe-4911-4156-8dc4-126b9d979b60
2019-02-28 19:32:08,709 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-28 19:32:08,710 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 8d3d4cbe-4911-4156-8dc4-126b9d979b60 (10.10.1.2:9866).
2019-02-28 19:32:08,783 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=d00d3c14-afd6-4072-8144-e3127d837346, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811) storage d00d3c14-afd6-4072-8144-e3127d837346
2019-02-28 19:32:08,784 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.3:9866
2019-02-28 19:32:08,784 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN d00d3c14-afd6-4072-8144-e3127d837346 (10.10.1.3:9866).
2019-02-28 19:32:08,788 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=522ba3e7-81cd-4aeb-941e-c6a603bcff1e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811) storage 522ba3e7-81cd-4aeb-941e-c6a603bcff1e
2019-02-28 19:32:08,788 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.5:9866
2019-02-28 19:32:08,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 522ba3e7-81cd-4aeb-941e-c6a603bcff1e (10.10.1.5:9866).
2019-02-28 19:32:08,794 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.4:9866, datanodeUuid=4d706107-dfc6-4029-bbaa-ba4c6e7f4457, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811) storage 4d706107-dfc6-4029-bbaa-ba4c6e7f4457
2019-02-28 19:32:08,794 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.4:9866
2019-02-28 19:32:08,795 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 4d706107-dfc6-4029-bbaa-ba4c6e7f4457 (10.10.1.4:9866).
2019-02-28 19:32:08,801 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-a1432ba0-d337-4416-8318-8bd44c394298 for DN 10.10.1.2:9866
2019-02-28 19:32:08,832 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-2e4519ce-2171-4f32-8cc6-64f29b9fbb4f for DN 10.10.1.3:9866
2019-02-28 19:32:08,836 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-736337a5-4a5f-4bf6-af19-492213eb726d for DN 10.10.1.5:9866
2019-02-28 19:32:08,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-c429abab-911e-4507-ad51-f419141d5ada for DN 10.10.1.4:9866
2019-02-28 19:32:08,849 INFO BlockStateChange: BLOCK* processReport 0x1ce9f853f5e648d0: Processing first storage report for DS-a1432ba0-d337-4416-8318-8bd44c394298 from datanode 8d3d4cbe-4911-4156-8dc4-126b9d979b60
2019-02-28 19:32:08,851 INFO BlockStateChange: BLOCK* processReport 0x1ce9f853f5e648d0: from storage DS-a1432ba0-d337-4416-8318-8bd44c394298 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=8d3d4cbe-4911-4156-8dc4-126b9d979b60, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811), blocks: 0, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2019-02-28 19:32:08,857 INFO BlockStateChange: BLOCK* processReport 0x5d9779039005a3ec: Processing first storage report for DS-2e4519ce-2171-4f32-8cc6-64f29b9fbb4f from datanode d00d3c14-afd6-4072-8144-e3127d837346
2019-02-28 19:32:08,857 INFO BlockStateChange: BLOCK* processReport 0x5d9779039005a3ec: from storage DS-2e4519ce-2171-4f32-8cc6-64f29b9fbb4f node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=d00d3c14-afd6-4072-8144-e3127d837346, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-28 19:32:08,860 INFO BlockStateChange: BLOCK* processReport 0xb5e28b1023d22ecd: Processing first storage report for DS-736337a5-4a5f-4bf6-af19-492213eb726d from datanode 522ba3e7-81cd-4aeb-941e-c6a603bcff1e
2019-02-28 19:32:08,860 INFO BlockStateChange: BLOCK* processReport 0xb5e28b1023d22ecd: from storage DS-736337a5-4a5f-4bf6-af19-492213eb726d node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=522ba3e7-81cd-4aeb-941e-c6a603bcff1e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-28 19:32:08,879 INFO BlockStateChange: BLOCK* processReport 0xbabde52dfa7bc876: Processing first storage report for DS-c429abab-911e-4507-ad51-f419141d5ada from datanode 4d706107-dfc6-4029-bbaa-ba4c6e7f4457
2019-02-28 19:32:08,880 INFO BlockStateChange: BLOCK* processReport 0xbabde52dfa7bc876: from storage DS-c429abab-911e-4507-ad51-f419141d5ada node DatanodeRegistration(10.10.1.4:9866, datanodeUuid=4d706107-dfc6-4029-bbaa-ba4c6e7f4457, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-02-28 19:32:09,536 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2019-02-28 19:32:09,537 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-02-28 19:32:09,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-02-28 19:32:09,650 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2019-02-28 19:32:09,730 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 1
2019-02-28 19:32:09,730 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-02-28 19:32:09,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2019-02-28 19:32:09,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datanodes as stale
2019-02-28 19:32:09,736 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2019-02-28 19:32:09,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-02-28 19:32:09,737 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 1
2019-02-28 19:32:09,740 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2019-02-28 19:32:10,198 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-02-28 19:32:10,203 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 5 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-02-28 19:32:10,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-02-28 19:32:10,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2019-02-28 19:32:10,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-02-28 19:32:10,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-02-28 19:32:10,209 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-02-28 19:32:10,209 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-02-28 19:32:10,209 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 471 msec
2019-02-28 19:32:15,440 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:32:15,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:32:15,444 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile2._COPYING_
2019-02-28 19:32:15,445 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:32:15,469 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:32:15,536 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-02-28 19:32:15,552 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:32:15,554 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-28 19:32:15,571 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:32:15,574 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:32:15,578 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:32:15,594 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:32:15,600 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-28 19:32:15,607 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-28 19:32:15,609 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:32:15,627 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-28 19:32:15,631 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:32:15,661 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:32:15,667 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:32:15,675 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile13._COPYING_
2019-02-28 19:32:17,411 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:32:17,496 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:32:17,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:32:17,500 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Received an RBW replica for blk_1073741825_1001 on 10.10.1.3:9866: ignoring it, since it is complete with the same genstamp
2019-02-28 19:32:17,521 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:32:17,539 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-28 19:32:17,558 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:32:17,559 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:32:17,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile10._COPYING_
2019-02-28 19:32:17,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile2._COPYING_
2019-02-28 19:32:17,603 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:32:17,619 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:32:17,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:32:18,094 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-28 19:32:18,446 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:32:18,701 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:32:18,710 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:32:18,829 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:32:18,846 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-28 19:32:18,875 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:32:19,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-28 19:32:19,194 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:32:19,351 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:32:19,429 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-28 19:32:19,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-28 19:32:19,930 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:32:20,007 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-02-28 19:32:20,014 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:32:20,046 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:32:20,071 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile10._COPYING_
2019-02-28 19:32:20,197 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:32:20,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-28 19:32:20,293 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:32:20,514 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:32:20,711 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:32:21,011 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:32:21,241 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:32:22,180 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:32:22,184 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-28 19:32:22,185 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile5._COPYING_
2019-02-28 19:32:22,186 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:32:22,186 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-28 19:32:22,188 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:32:22,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-28 19:32:22,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:32:22,212 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-28 19:32:22,212 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-02-28 19:32:22,213 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:32:22,218 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-28 19:32:22,219 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:32:22,219 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile17._COPYING_
2019-02-28 19:32:22,220 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1071, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:32:22,221 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1072, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:32:22,224 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1073, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:32:23,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1074, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile18._COPYING_
2019-02-28 19:32:23,601 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1075, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile20._COPYING_
2019-02-28 19:32:23,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1076, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-28 19:32:23,633 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1077, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-02-28 19:32:23,636 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1078, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:32:23,637 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1079, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile17._COPYING_
2019-02-28 19:32:24,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1080, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:32:24,320 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1081, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:32:24,377 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1082, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:32:24,479 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1083, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:32:24,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1084, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:32:24,808 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1085, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-28 19:32:24,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1086, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:32:24,927 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1087, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-28 19:32:24,928 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1088, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile5._COPYING_
2019-02-28 19:32:24,940 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1089, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:32:25,377 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1090, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-28 19:32:25,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1091, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:32:25,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1092, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:32:25,477 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1093, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:32:25,488 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1094, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:32:25,499 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1095, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:32:25,963 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1096, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile13._COPYING_
2019-02-28 19:32:26,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1097, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:32:26,111 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1098, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-28 19:32:26,571 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1099, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:32:27,037 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1100, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-28 19:32:27,075 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1101, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:32:27,290 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1102, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-28 19:32:27,491 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1103, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-28 19:32:31,144 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1104, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile11._COPYING_
2019-02-28 19:32:31,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1105, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:32:31,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741930_1106, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile12._COPYING_
2019-02-28 19:32:31,149 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741931_1107, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:32:32,335 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741932_1108, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-02-28 19:32:32,335 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741933_1109, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:32:32,336 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741934_1110, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:32:34,884 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741935_1111, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile10._COPYING_
2019-02-28 19:32:34,896 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741936_1112, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:32:34,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741937_1113, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:32:37,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741938_1114, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:32:37,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741939_1115, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile17._COPYING_
2019-02-28 19:32:37,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741940_1116, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:32:37,499 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741941_1117, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:32:37,499 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741942_1118, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile14._COPYING_
2019-02-28 19:32:40,978 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741943_1119, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:32:42,488 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741944_1120, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:32:42,490 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741945_1121, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-28 19:32:44,174 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741946_1122, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:32:44,717 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741947_1123, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-28 19:32:44,722 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741948_1124, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:32:44,751 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741949_1125, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-02-28 19:32:44,963 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741950_1126, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:32:44,963 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741951_1127, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:32:45,633 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741952_1128, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:32:45,777 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741953_1129, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:32:45,867 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741954_1130, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:32:45,888 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741955_1131, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:32:45,953 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741956_1132, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:32:46,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741957_1133, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:32:49,849 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741958_1134, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:32:49,850 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741959_1135, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:32:49,851 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741960_1136, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:32:49,852 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741961_1137, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:32:49,853 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile15._COPYING_ is closed by DFSClient_NONMAPREDUCE_-654907001_1
2019-02-28 19:32:50,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741962_1138, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:32:51,391 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741963_1139, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:32:51,392 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741964_1140, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile12._COPYING_
2019-02-28 19:32:51,392 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741965_1141, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:32:51,393 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741966_1142, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:32:51,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741967_1143, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:32:51,994 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741968_1144, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:32:56,198 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741969_1145, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:32:57,573 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile13._COPYING_ is closed by DFSClient_NONMAPREDUCE_754853197_1
2019-02-28 19:32:58,221 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741970_1146, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile10._COPYING_
2019-02-28 19:32:58,224 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741971_1147, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:32:58,227 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile19._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1116364168_1
2019-02-28 19:32:59,302 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile14._COPYING_ is closed by DFSClient_NONMAPREDUCE_-189378233_1
2019-02-28 19:32:59,303 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741972_1148, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile17._COPYING_
2019-02-28 19:32:59,702 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile6._COPYING_ is closed by DFSClient_NONMAPREDUCE_-940321990_1
2019-02-28 19:33:04,486 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741973_1149, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:33:04,486 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 477 Total time for transactions(ms): 33 Number of transactions batched in Syncs: 306 Number of syncs: 169 SyncTimes(ms): 1320 1701 
2019-02-28 19:33:04,486 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741974_1150, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:33:04,486 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741975_1151, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:33:04,487 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741976_1152, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-28 19:33:04,488 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741977_1153, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-28 19:33:06,079 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_1276991388_1
2019-02-28 19:33:07,780 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile10._COPYING_ is closed by DFSClient_NONMAPREDUCE_42255994_1
2019-02-28 19:33:11,307 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741978_1154, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:33:12,108 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741979_1159, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:33:12,286 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2035882206_1
2019-02-28 19:33:12,602 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741975_1151, newGS=1155, newLength=120121856, newNodes=[10.10.1.5:9866, 10.10.1.4:9866], client=DFSClient_NONMAPREDUCE_1520551755_1)
2019-02-28 19:33:12,603 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741975_1151 => blk_1073741975_1155) success
2019-02-28 19:33:14,044 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741976_1152, newGS=1157, newLength=65024, newNodes=[10.10.1.4:9866, 10.10.1.3:9866], client=DFSClient_NONMAPREDUCE_-476207745_1)
2019-02-28 19:33:14,044 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741976_1152 => blk_1073741976_1157) success
2019-02-28 19:33:17,734 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741980_1161, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:33:17,812 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741981_1162, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:33:17,814 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile20._COPYING_ is closed by DFSClient_NONMAPREDUCE_-189319250_1
2019-02-28 19:33:17,814 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile3._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1624103198_1
2019-02-28 19:33:17,814 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile8._COPYING_ is closed by DFSClient_NONMAPREDUCE_-476207745_1
2019-02-28 19:33:17,815 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_97315082_1
2019-02-28 19:33:17,815 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile7._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2047143576_1
2019-02-28 19:33:17,816 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741973_1149, newGS=1156, newLength=512, newNodes=[10.10.1.3:9866, 10.10.1.4:9866], client=DFSClient_NONMAPREDUCE_2110188817_1)
2019-02-28 19:33:17,817 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741973_1149 => blk_1073741973_1156) success
2019-02-28 19:33:17,817 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741972_1148, newGS=1158, newLength=839168, newNodes=[10.10.1.3:9866, 10.10.1.4:9866], client=DFSClient_NONMAPREDUCE_1622927388_1)
2019-02-28 19:33:17,817 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741972_1148 => blk_1073741972_1158) success
2019-02-28 19:33:17,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741977_1153, newGS=1160, newLength=512, newNodes=[10.10.1.3:9866, 10.10.1.4:9866], client=DFSClient_NONMAPREDUCE_38999359_1)
2019-02-28 19:33:17,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073741977_1153 => blk_1073741977_1160) success
2019-02-28 19:33:21,773 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_414527913_1
2019-02-28 19:33:28,246 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741982_1163, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:33:28,246 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741983_1164, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile17._COPYING_
2019-02-28 19:33:28,248 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile16._COPYING_ is closed by DFSClient_NONMAPREDUCE_38999359_1
2019-02-28 19:33:28,251 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile18._COPYING_ is closed by DFSClient_NONMAPREDUCE_2110188817_1
2019-02-28 19:33:28,594 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741984_1165, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile12._COPYING_
2019-02-28 19:33:28,597 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile9._COPYING_ is closed by DFSClient_NONMAPREDUCE_1520551755_1
2019-02-28 19:33:39,473 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=8d3d4cbe-4911-4156-8dc4-126b9d979b60, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811) storage 8d3d4cbe-4911-4156-8dc4-126b9d979b60
2019-02-28 19:33:39,473 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.10.1.2:9866
2019-02-28 19:33:39,473 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-28 19:33:39,519 INFO BlockStateChange: BLOCK* processReport 0x4eaf6355dc6e5be2: Processing first storage report for DS-a1432ba0-d337-4416-8318-8bd44c394298 from datanode 8d3d4cbe-4911-4156-8dc4-126b9d979b60
2019-02-28 19:33:39,524 INFO BlockStateChange: BLOCK* processReport 0x4eaf6355dc6e5be2: from storage DS-a1432ba0-d337-4416-8318-8bd44c394298 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=8d3d4cbe-4911-4156-8dc4-126b9d979b60, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811), blocks: 113, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2019-02-28 19:33:41,069 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Rescan of postponedMisreplicatedBlocks completed in 0 msecs. 0 blocks are left. 5 blocks were removed.
2019-02-28 19:33:47,070 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Rescan of postponedMisreplicatedBlocks completed in 0 msecs. 0 blocks are left. 1 blocks were removed.
2019-02-28 19:33:51,311 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741985_1166, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:33:51,315 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile12._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1122469079_1
2019-02-28 19:33:51,315 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile17._COPYING_ is closed by DFSClient_NONMAPREDUCE_1622927388_1
2019-02-28 19:34:04,024 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile11._COPYING_ is closed by DFSClient_NONMAPREDUCE_-704961656_1
2019-02-28 19:34:08,175 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.10.1.4
2019-02-28 19:34:08,175 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-02-28 19:34:08,175 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1, 555
2019-02-28 19:34:08,175 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 556 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 348 Number of syncs: 207 SyncTimes(ms): 1649 2031 
2019-02-28 19:34:08,189 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 556 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 348 Number of syncs: 208 SyncTimes(ms): 1655 2038 
2019-02-28 19:34:08,219 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000001 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000001-0000000000000000556
2019-02-28 19:34:08,236 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 557
2019-02-28 19:36:08,683 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.10.1.4
2019-02-28 19:36:08,684 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-02-28 19:36:08,684 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 557, 557
2019-02-28 19:36:08,684 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 9 80 
2019-02-28 19:36:08,703 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 20 87 
2019-02-28 19:36:08,705 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000557 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000557-0000000000000000558
2019-02-28 19:36:08,706 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 559
2019-02-28 19:36:39,631 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741986_1167, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:36:40,066 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=8d3d4cbe-4911-4156-8dc4-126b9d979b60, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811) storage 8d3d4cbe-4911-4156-8dc4-126b9d979b60
2019-02-28 19:36:40,066 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.10.1.2:9866
2019-02-28 19:36:40,067 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-28 19:36:40,155 INFO BlockStateChange: BLOCK* processReport 0x24e7cd890e8ac694: Processing first storage report for DS-a1432ba0-d337-4416-8318-8bd44c394298 from datanode 8d3d4cbe-4911-4156-8dc4-126b9d979b60
2019-02-28 19:36:40,156 INFO BlockStateChange: BLOCK* processReport 0x24e7cd890e8ac694: from storage DS-a1432ba0-d337-4416-8318-8bd44c394298 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=8d3d4cbe-4911-4156-8dc4-126b9d979b60, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811), blocks: 85, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-02-28 19:36:40,205 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741987_1168, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:36:40,600 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741988_1169, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:36:41,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741989_1170, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:36:41,081 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Rescan of postponedMisreplicatedBlocks completed in 0 msecs. 0 blocks are left. 3 blocks were removed.
2019-02-28 19:36:41,524 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741990_1171, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:36:41,954 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741991_1172, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:36:42,054 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741992_1173, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-28 19:36:42,467 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741993_1174, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:36:42,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741994_1175, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-02-28 19:36:42,957 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741995_1176, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:36:43,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741996_1177, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:36:44,190 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741997_1178, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:36:44,195 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile6._COPYING_ is closed by DFSClient_NONMAPREDUCE_244301987_1
2019-02-28 19:36:44,775 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741998_1179, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:36:45,044 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741999_1180, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:36:45,198 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742000_1181, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-28 19:36:45,663 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742001_1182, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-28 19:36:45,703 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742002_1183, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:36:46,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742003_1184, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile10._COPYING_
2019-02-28 19:36:46,174 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742004_1185, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:36:46,561 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742005_1186, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile10._COPYING_
2019-02-28 19:36:46,669 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile15._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1803309944_1
2019-02-28 19:36:47,054 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742006_1187, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:36:47,299 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742007_1188, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:36:47,461 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742008_1189, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile10._COPYING_
2019-02-28 19:36:47,936 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742009_1190, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:36:47,997 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742010_1191, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:36:48,461 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742011_1192, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:36:48,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742012_1193, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:36:48,960 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742013_1194, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-28 19:36:49,030 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile10._COPYING_ is closed by DFSClient_NONMAPREDUCE_2074167489_1
2019-02-28 19:36:49,683 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742014_1195, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:36:50,596 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742015_1196, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile14._COPYING_
2019-02-28 19:36:52,187 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742016_1197, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:36:52,606 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742017_1198, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:36:53,171 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742018_1199, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-28 19:36:53,559 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742019_1200, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-28 19:36:53,968 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742020_1201, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:36:54,143 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742021_1202, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-28 19:36:54,591 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742022_1203, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile14._COPYING_
2019-02-28 19:36:54,591 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742023_1204, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:36:54,700 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742024_1205, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:36:55,135 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742025_1206, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:36:55,159 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742026_1207, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:36:55,243 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742027_1208, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-28 19:36:57,029 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742028_1209, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:36:58,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742029_1210, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:36:59,093 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742030_1211, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile18._COPYING_
2019-02-28 19:36:59,339 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742031_1212, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:36:59,559 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile16._COPYING_ is closed by DFSClient_NONMAPREDUCE_78059318_1
2019-02-28 19:36:59,784 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742032_1213, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:36:59,884 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742033_1214, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:37:00,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742034_1215, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:37:00,287 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742035_1216, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile14._COPYING_
2019-02-28 19:37:00,488 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742036_1217, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:37:00,550 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742037_1218, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:37:00,628 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile8._COPYING_ is closed by DFSClient_NONMAPREDUCE_1456794501_1
2019-02-28 19:37:00,692 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742038_1219, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:37:00,854 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742039_1220, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:37:04,503 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742040_1221, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:37:04,504 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742041_1222, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:37:04,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742042_1223, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:37:04,506 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742043_1224, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:37:05,023 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742044_1225, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:37:05,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742045_1226, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-28 19:37:05,045 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742046_1227, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-28 19:37:05,052 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742047_1228, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:37:05,537 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742048_1229, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-28 19:37:05,570 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742049_1230, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-28 19:37:05,570 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742050_1231, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:37:05,663 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile14._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2021149775_1
2019-02-28 19:37:05,816 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742051_1232, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:37:06,023 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742052_1233, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile18._COPYING_
2019-02-28 19:37:06,082 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742053_1234, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:37:06,128 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742054_1235, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:37:08,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742055_1236, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:37:08,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742056_1237, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:37:08,285 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742057_1238, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:37:08,285 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile18._COPYING_ is closed by DFSClient_NONMAPREDUCE_-285787059_1
2019-02-28 19:37:08,720 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1305851167_1
2019-02-28 19:37:08,720 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 254 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 97 Number of syncs: 156 SyncTimes(ms): 1183 1397 
2019-02-28 19:37:08,809 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742058_1239, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:37:09,237 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742059_1240, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:37:09,305 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742060_1241, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-28 19:37:09,723 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile9._COPYING_ is closed by DFSClient_NONMAPREDUCE_507907836_1
2019-02-28 19:37:09,754 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742061_1242, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-28 19:37:09,784 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742062_1243, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:37:10,218 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742063_1244, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:37:10,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742064_1245, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-28 19:37:10,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742065_1246, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:37:10,925 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742066_1247, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:37:11,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742067_1248, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:37:11,501 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742068_1249, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:37:11,632 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742069_1250, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile17._COPYING_
2019-02-28 19:37:11,657 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742070_1251, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile12._COPYING_
2019-02-28 19:37:11,922 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742071_1252, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:37:12,334 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742072_1253, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:37:13,874 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile12._COPYING_ is closed by DFSClient_NONMAPREDUCE_1517241237_1
2019-02-28 19:37:13,947 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742073_1254, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:37:14,034 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742074_1255, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:37:16,896 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742075_1256, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:37:16,949 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742076_1257, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:37:19,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742077_1258, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:37:19,916 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile7._COPYING_ is closed by DFSClient_NONMAPREDUCE_1750892368_1
2019-02-28 19:37:22,080 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742078_1259, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile17._COPYING_
2019-02-28 19:37:22,521 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742079_1260, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile17._COPYING_
2019-02-28 19:37:27,548 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742080_1261, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile17._COPYING_
2019-02-28 19:37:31,363 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742081_1262, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile17._COPYING_
2019-02-28 19:37:32,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742082_1263, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile11._COPYING_
2019-02-28 19:37:36,980 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile17._COPYING_ is closed by DFSClient_NONMAPREDUCE_759755153_1
2019-02-28 19:37:40,959 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742083_1264, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:37:46,105 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742084_1265, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-28 19:37:52,037 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742085_1266, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-28 19:37:55,483 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742086_1267, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:37:56,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742087_1268, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:37:56,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742088_1269, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile11._COPYING_
2019-02-28 19:38:03,997 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742089_1270, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile11._COPYING_
2019-02-28 19:38:08,976 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.10.1.4
2019-02-28 19:38:08,976 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-02-28 19:38:08,976 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 559, 921
2019-02-28 19:38:08,976 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 364 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 132 Number of syncs: 231 SyncTimes(ms): 1771 2026 
2019-02-28 19:38:08,992 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 364 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 132 Number of syncs: 232 SyncTimes(ms): 1779 2034 
2019-02-28 19:38:08,995 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000559 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000559-0000000000000000922
2019-02-28 19:38:08,995 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 923
2019-02-28 19:38:22,379 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile11._COPYING_ is closed by DFSClient_NONMAPREDUCE_867330945_1
2019-02-28 19:38:24,293 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742090_1271, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:38:27,293 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742091_1272, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-28 19:38:27,688 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742092_1273, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-28 19:38:28,086 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742093_1274, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:38:28,538 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742094_1275, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile13._COPYING_
2019-02-28 19:38:28,918 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742095_1276, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:38:36,856 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742096_1277, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile13._COPYING_
2019-02-28 19:38:37,307 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742097_1278, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:38:37,753 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile13._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1298419343_1
2019-02-28 19:38:45,853 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742098_1279, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:38:47,598 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742099_1280, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-02-28 19:38:47,719 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742100_1281, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-28 19:38:47,854 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742101_1282, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-28 19:38:48,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742102_1283, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:38:48,390 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742103_1284, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-28 19:38:48,450 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742104_1285, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-28 19:38:48,821 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742105_1286, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-02-28 19:38:49,164 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742106_1287, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:38:49,344 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742107_1288, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile2._COPYING_
2019-02-28 19:38:49,536 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742108_1289, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile20._COPYING_
2019-02-28 19:38:49,712 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742109_1290, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:38:50,789 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742110_1291, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:38:50,790 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742111_1292, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:38:51,320 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742112_1293, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-02-28 19:38:51,406 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742113_1294, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile20._COPYING_
2019-02-28 19:38:51,464 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742114_1295, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:38:51,824 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742115_1296, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:38:51,971 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742116_1297, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:38:52,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742117_1298, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:38:52,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742118_1299, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:38:53,219 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742119_1300, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-28 19:38:53,220 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742120_1301, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-28 19:38:53,751 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742121_1302, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:38:53,775 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_-362528394_1
2019-02-28 19:38:53,791 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742122_1303, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:38:53,797 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742123_1304, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile19._COPYING_
2019-02-28 19:38:53,832 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742124_1305, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-28 19:38:54,220 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742125_1306, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile2._COPYING_
2019-02-28 19:38:59,317 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742126_1307, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile5._COPYING_
2019-02-28 19:38:59,817 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742127_1308, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:39:00,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742128_1309, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:39:00,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742129_1310, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:39:01,723 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742130_1311, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:39:01,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742131_1312, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:39:02,134 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742132_1313, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile5._COPYING_
2019-02-28 19:39:02,195 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742133_1314, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-28 19:39:02,196 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742134_1315, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-28 19:39:02,328 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_-655413798_1
2019-02-28 19:39:02,788 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_-515754650_1
2019-02-28 19:39:02,846 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742135_1316, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile20._COPYING_
2019-02-28 19:39:02,972 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742136_1317, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:39:04,732 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742137_1318, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile19._COPYING_
2019-02-28 19:39:04,735 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile20._COPYING_ is closed by DFSClient_NONMAPREDUCE_-560051927_1
2019-02-28 19:39:06,644 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile19._COPYING_ is closed by DFSClient_NONMAPREDUCE_-295380483_1
2019-02-28 19:39:09,952 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 173 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 64 Number of syncs: 108 SyncTimes(ms): 736 564 
2019-02-28 19:39:10,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742138_1319, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-02-28 19:39:12,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742139_1320, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-02-28 19:39:12,824 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742140_1321, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-02-28 19:39:13,354 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742141_1322, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:39:13,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742142_1323, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-02-28 19:39:14,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742143_1324, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:39:15,070 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742144_1325, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-02-28 19:39:15,551 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742145_1326, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:39:27,126 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile3._COPYING_ is closed by DFSClient_NONMAPREDUCE_1548578341_1
2019-02-28 19:40:09,218 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.10.1.4
2019-02-28 19:40:09,218 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-02-28 19:40:09,218 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 923, 1121
2019-02-28 19:40:09,240 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 200 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 72 Number of syncs: 128 SyncTimes(ms): 880 701 
2019-02-28 19:40:09,243 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000923 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000923-0000000000000001122
2019-02-28 19:40:09,243 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1123
2019-02-28 19:40:12,323 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=8d3d4cbe-4911-4156-8dc4-126b9d979b60, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811) storage 8d3d4cbe-4911-4156-8dc4-126b9d979b60
2019-02-28 19:40:12,323 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.10.1.2:9866
2019-02-28 19:40:12,323 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-28 19:40:12,398 INFO BlockStateChange: BLOCK* processReport 0x805bbd4d3932b96b: Processing first storage report for DS-a1432ba0-d337-4416-8318-8bd44c394298 from datanode 8d3d4cbe-4911-4156-8dc4-126b9d979b60
2019-02-28 19:40:12,400 INFO BlockStateChange: BLOCK* processReport 0x805bbd4d3932b96b: from storage DS-a1432ba0-d337-4416-8318-8bd44c394298 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=8d3d4cbe-4911-4156-8dc4-126b9d979b60, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811), blocks: 129, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-02-28 19:40:54,539 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742146_1327, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:40:54,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742147_1328, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-28 19:40:56,590 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742148_1329, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-28 19:41:01,623 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742149_1330, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-28 19:41:01,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742150_1331, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:41:02,073 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742151_1332, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:41:03,234 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742152_1333, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:41:08,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742153_1334, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:41:10,167 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742154_1335, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:41:10,167 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 38 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 8 Number of syncs: 28 SyncTimes(ms): 235 214 
2019-02-28 19:41:10,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742155_1336, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:41:12,367 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742156_1337, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-28 19:41:14,282 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742157_1338, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:41:15,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742158_1339, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-28 19:41:15,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742159_1340, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:41:16,327 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742160_1341, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:41:16,777 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742161_1342, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:41:16,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742162_1343, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:41:17,024 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742163_1344, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-28 19:41:17,348 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742164_1345, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:41:17,365 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742165_1346, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:41:18,558 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742166_1347, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-28 19:41:19,047 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742167_1348, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-28 19:41:21,220 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742168_1349, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:41:21,224 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742169_1350, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-28 19:41:23,175 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742170_1351, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:41:23,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742171_1352, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:41:23,930 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742172_1353, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:41:28,477 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742173_1354, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:41:29,010 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742174_1355, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:41:30,388 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742175_1356, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-28 19:41:30,388 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742176_1357, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-28 19:41:30,389 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742177_1358, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:41:30,389 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742178_1359, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:41:30,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742179_1360, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:41:30,873 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742180_1361, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:41:31,215 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742181_1362, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-28 19:41:31,250 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742182_1363, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:41:31,262 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742183_1364, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:41:31,402 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742184_1365, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:41:31,494 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742185_1366, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:41:31,794 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742186_1367, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-28 19:41:31,897 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile6._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1842912619_1
2019-02-28 19:41:32,061 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742187_1368, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:41:32,484 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742188_1369, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:41:32,920 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742189_1370, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:41:33,692 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742190_1371, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:41:34,113 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742191_1372, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:41:36,616 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742192_1373, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:41:37,170 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742193_1374, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:41:37,994 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742194_1375, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:41:38,680 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742195_1376, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:41:38,828 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742196_1377, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:41:39,087 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742197_1378, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:41:39,574 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile16._COPYING_ is closed by DFSClient_NONMAPREDUCE_558895899_1
2019-02-28 19:41:39,899 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742198_1379, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile10._COPYING_
2019-02-28 19:41:40,032 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742199_1380, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile18._COPYING_
2019-02-28 19:41:41,282 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742200_1381, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-28 19:41:43,853 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742201_1382, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:41:43,967 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742202_1383, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:41:43,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742203_1384, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:41:43,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742204_1385, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:41:49,711 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742205_1386, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:41:49,711 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742206_1387, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:41:49,713 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742207_1388, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:41:50,108 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile14._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1043192584_1
2019-02-28 19:41:51,246 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742208_1389, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:41:51,248 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742209_1390, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:41:51,249 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742210_1391, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:41:51,251 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742211_1392, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-28 19:41:56,740 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742212_1393, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-28 19:41:58,099 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742213_1394, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile11._COPYING_
2019-02-28 19:41:58,819 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742214_1395, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:42:02,210 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742215_1396, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-28 19:42:02,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742216_1397, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:42:06,610 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742217_1398, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:42:06,612 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile7._COPYING_ is closed by DFSClient_NONMAPREDUCE_-81307442_1
2019-02-28 19:42:07,826 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742218_1399, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:42:07,829 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742219_1400, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:42:07,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742220_1401, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:42:07,893 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742221_1402, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:42:07,906 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742222_1403, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:42:08,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: StorageInfo TreeSet defragmented DS-c429abab-911e-4507-ad51-f419141d5ada : 1.0
2019-02-28 19:42:08,140 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742223_1404, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile10._COPYING_
2019-02-28 19:42:08,255 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742224_1405, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:42:08,689 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742225_1406, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:42:09,426 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.10.1.4
2019-02-28 19:42:09,426 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-02-28 19:42:09,426 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1123, 1397
2019-02-28 19:42:09,447 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 276 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 112 Number of syncs: 164 SyncTimes(ms): 1159 876 
2019-02-28 19:42:09,450 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000001123 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000001123-0000000000000001398
2019-02-28 19:42:09,450 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1399
2019-02-28 19:42:11,477 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742226_1407, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:42:11,481 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_366099186_1
2019-02-28 19:42:12,195 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742227_1408, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-28 19:42:14,874 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742228_1409, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile17._COPYING_
2019-02-28 19:42:16,114 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile18._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1759958591_1
2019-02-28 19:42:17,688 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742229_1410, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile11._COPYING_
2019-02-28 19:42:17,689 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742230_1411, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:42:17,691 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742231_1412, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:42:17,692 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile12._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1668732142_1
2019-02-28 19:42:26,084 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742232_1413, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:42:26,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742233_1414, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile11._COPYING_
2019-02-28 19:42:26,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742234_1415, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:42:27,885 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742235_1416, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-28 19:42:27,891 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile8._COPYING_ is closed by DFSClient_NONMAPREDUCE_746151865_1
2019-02-28 19:42:30,379 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742236_1417, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:42:30,403 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742237_1418, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile10._COPYING_
2019-02-28 19:42:32,432 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile9._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1842985946_1
2019-02-28 19:42:33,532 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742238_1419, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:42:33,537 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742239_1420, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile11._COPYING_
2019-02-28 19:42:34,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742240_1421, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:42:40,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742241_1422, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile10._COPYING_
2019-02-28 19:42:40,941 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742242_1423, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-28 19:42:40,941 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile15._COPYING_ is closed by DFSClient_NONMAPREDUCE_694997015_1
2019-02-28 19:42:42,088 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742243_1424, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile17._COPYING_
2019-02-28 19:42:45,013 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742244_1425, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile17._COPYING_
2019-02-28 19:42:45,530 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742245_1426, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile20._COPYING_
2019-02-28 19:42:47,605 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742246_1427, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-28 19:42:49,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742247_1428, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:42:49,731 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742248_1429, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:42:49,834 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742249_1430, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:42:50,199 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile10._COPYING_ is closed by DFSClient_NONMAPREDUCE_996109917_1
2019-02-28 19:42:50,229 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742250_1431, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile19._COPYING_
2019-02-28 19:42:50,519 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742251_1432, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:42:50,649 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742252_1433, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile19._COPYING_
2019-02-28 19:42:57,039 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742253_1434, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile11._COPYING_
2019-02-28 19:42:57,039 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742254_1435, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile17._COPYING_
2019-02-28 19:42:57,039 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742255_1436, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile20._COPYING_
2019-02-28 19:42:57,812 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742256_1437, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:43:00,081 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742257_1438, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile17._COPYING_
2019-02-28 19:43:05,005 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742258_1439, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile11._COPYING_
2019-02-28 19:43:05,829 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742259_1440, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:43:08,304 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742260_1441, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:43:08,309 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742261_1442, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile3._COPYING_
2019-02-28 19:43:11,992 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 132 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 60 Number of syncs: 71 SyncTimes(ms): 510 427 
2019-02-28 19:43:12,043 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742262_1443, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-28 19:43:12,504 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile17._COPYING_ is closed by DFSClient_NONMAPREDUCE_992136218_1
2019-02-28 19:43:13,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742263_1444, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-28 19:43:16,603 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742264_1445, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-02-28 19:43:18,001 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742265_1446, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-02-28 19:43:22,627 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742266_1447, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:43:23,177 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742267_1448, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile19._COPYING_
2019-02-28 19:43:23,180 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742268_1449, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile13._COPYING_
2019-02-28 19:43:23,183 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile11._COPYING_ is closed by DFSClient_NONMAPREDUCE_-570678907_1
2019-02-28 19:43:25,021 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073742267_1448, newGS=1454, newLength=14709248, newNodes=[10.10.1.5:9866, 10.10.1.4:9866], client=DFSClient_NONMAPREDUCE_632929065_1)
2019-02-28 19:43:25,021 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073742267_1448 => blk_1073742267_1454) success
2019-02-28 19:43:25,033 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073742265_1446, newGS=1453, newLength=119476736, newNodes=[10.10.1.5:9866, 10.10.1.4:9866], client=DFSClient_NONMAPREDUCE_-499583063_1)
2019-02-28 19:43:25,034 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073742265_1446 => blk_1073742265_1453) success
2019-02-28 19:43:25,099 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742269_1455, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-02-28 19:43:25,375 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742270_1456, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:43:25,416 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742271_1457, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:43:27,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073742266_1447, newGS=1450, newLength=25224704, newNodes=[10.10.1.5:9866, 10.10.1.3:9866], client=DFSClient_NONMAPREDUCE_175711930_1)
2019-02-28 19:43:27,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073742266_1447 => blk_1073742266_1450) success
2019-02-28 19:43:27,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073742264_1445, newGS=1452, newLength=114702336, newNodes=[10.10.1.4:9866, 10.10.1.3:9866], client=DFSClient_NONMAPREDUCE_1374752471_1)
2019-02-28 19:43:27,011 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073742264_1445 => blk_1073742264_1452) success
2019-02-28 19:43:27,110 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742272_1458, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-28 19:43:27,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742273_1459, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:43:28,566 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073742268_1449, newGS=1451, newLength=9225728, newNodes=[10.10.1.3:9866, 10.10.1.5:9866], client=DFSClient_NONMAPREDUCE_1850564596_1)
2019-02-28 19:43:28,567 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: updatePipeline(blk_1073742268_1449 => blk_1073742268_1451) success
2019-02-28 19:43:29,028 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742274_1460, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile13._COPYING_
2019-02-28 19:43:29,030 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742275_1461, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile19._COPYING_
2019-02-28 19:43:29,101 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742276_1462, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile4._COPYING_
2019-02-28 19:43:30,540 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742277_1463, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile20._COPYING_
2019-02-28 19:43:30,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742278_1464, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-28 19:43:31,212 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=8d3d4cbe-4911-4156-8dc4-126b9d979b60, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811) storage 8d3d4cbe-4911-4156-8dc4-126b9d979b60
2019-02-28 19:43:31,212 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.10.1.2:9866
2019-02-28 19:43:31,213 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.10.1.2:9866
2019-02-28 19:43:31,273 INFO BlockStateChange: BLOCK* processReport 0x9488c1d33b497eaf: Processing first storage report for DS-a1432ba0-d337-4416-8318-8bd44c394298 from datanode 8d3d4cbe-4911-4156-8dc4-126b9d979b60
2019-02-28 19:43:31,274 INFO BlockStateChange: BLOCK* processReport 0x9488c1d33b497eaf: from storage DS-a1432ba0-d337-4416-8318-8bd44c394298 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=8d3d4cbe-4911-4156-8dc4-126b9d979b60, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-e4cfd186-b9f1-482c-9cd3-c4fbfc7e07c8;nsid=535501746;c=1551407496811), blocks: 91, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-02-28 19:43:32,110 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Rescan of postponedMisreplicatedBlocks completed in 0 msecs. 0 blocks are left. 5 blocks were removed.
2019-02-28 19:43:35,401 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742279_1465, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-02-28 19:43:35,401 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile19._COPYING_ is closed by DFSClient_NONMAPREDUCE_632929065_1
2019-02-28 19:43:36,428 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742280_1466, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:43:38,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Rescan of postponedMisreplicatedBlocks completed in 0 msecs. 0 blocks are left. 1 blocks were removed.
2019-02-28 19:43:38,882 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742281_1467, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-28 19:43:39,331 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742282_1468, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:43:39,766 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742283_1469, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:43:40,024 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742284_1470, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:43:40,554 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742285_1471, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:43:40,993 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742286_1472, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:43:41,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Rescan of postponedMisreplicatedBlocks completed in 0 msecs. 0 blocks are left. 2 blocks were removed.
2019-02-28 19:43:42,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742287_1473, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-28 19:43:44,113 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Rescan of postponedMisreplicatedBlocks completed in 0 msecs. 0 blocks are left. 2 blocks were removed.
2019-02-28 19:43:48,265 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742288_1474, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile20._COPYING_
2019-02-28 19:43:48,266 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742289_1475, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-02-28 19:43:48,266 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:43:48,266 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:43:48,266 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742290_1476, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-02-28 19:43:48,266 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:43:48,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742291_1477, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:43:48,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742292_1478, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:43:48,687 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742293_1479, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-28 19:43:49,174 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742294_1480, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile13._COPYING_
2019-02-28 19:43:49,401 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742295_1481, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile20._COPYING_
2019-02-28 19:43:49,566 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not enough replicas was chosen. Reason:{NODE_TOO_BUSY=1}
2019-02-28 19:43:49,566 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:43:49,566 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:43:49,566 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:43:49,566 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742296_1482, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:43:49,866 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742297_1483, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile13._COPYING_
2019-02-28 19:43:49,869 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742298_1484, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:43:49,899 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742299_1485, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-02-28 19:43:50,024 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile3._COPYING_ is closed by DFSClient_NONMAPREDUCE_-499583063_1
2019-02-28 19:43:50,233 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile20._COPYING_ is closed by DFSClient_NONMAPREDUCE_175711930_1
2019-02-28 19:43:50,279 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:43:50,279 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:43:50,279 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:43:50,279 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742300_1486, replicas=10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-02-28 19:43:50,451 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742301_1487, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile13._COPYING_
2019-02-28 19:43:50,470 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742302_1488, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-02-28 19:43:50,556 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742303_1489, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-02-28 19:43:50,761 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2019-02-28 19:43:50,761 WARN org.apache.hadoop.hdfs.protocol.BlockStoragePolicy: Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=3, selected=[], unavailable=[DISK], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2019-02-28 19:43:50,761 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Failed to place enough replicas, still in need of 1 to reach 3 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=true) All required storage types are unavailable:  unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2019-02-28 19:43:50,761 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742304_1490, replicas=10.10.1.5:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-02-28 19:43:51,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742305_1491, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile2._COPYING_
2019-02-28 19:43:51,033 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile13._COPYING_ is closed by DFSClient_NONMAPREDUCE_1850564596_1
2019-02-28 19:43:51,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742306_1492, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-02-28 19:43:51,301 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_1374752471_1
2019-02-28 19:43:51,963 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1035213602_1
2019-02-28 19:43:52,045 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742307_1493, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile2._COPYING_
2019-02-28 19:43:52,700 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1193435393_1
2019-02-28 19:44:09,626 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.10.1.4
2019-02-28 19:44:09,626 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-02-28 19:44:09,626 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1399, 1703
2019-02-28 19:44:09,645 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 306 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 131 Number of syncs: 175 SyncTimes(ms): 1226 975 
2019-02-28 19:44:09,648 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000001399 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000001399-0000000000000001704
2019-02-28 19:44:09,648 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1705
2019-02-28 19:45:11,891 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 30 68 
2019-02-28 19:45:11,953 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742308_1494, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile16._COPYING_
2019-02-28 19:45:12,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742309_1495, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:45:15,509 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742310_1496, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:45:15,556 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742311_1497, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:45:16,141 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742312_1498, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:45:16,184 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742313_1499, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile6._COPYING_
2019-02-28 19:45:16,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742314_1500, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-28 19:45:16,721 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742315_1501, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile6._COPYING_
2019-02-28 19:45:17,111 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742316_1502, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile16._COPYING_
2019-02-28 19:45:17,697 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742317_1503, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:45:17,698 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742318_1504, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile16._COPYING_
2019-02-28 19:45:18,225 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742319_1505, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:45:18,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742320_1506, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile16._COPYING_
2019-02-28 19:45:18,807 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742321_1507, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:45:18,881 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile16._COPYING_ is closed by DFSClient_NONMAPREDUCE_1857150555_1
2019-02-28 19:45:19,335 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742322_1508, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile6._COPYING_
2019-02-28 19:45:19,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742323_1509, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile6._COPYING_
2019-02-28 19:45:20,313 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile6._COPYING_ is closed by DFSClient_NONMAPREDUCE_1447661924_1
2019-02-28 19:45:48,262 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742324_1510, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile14._COPYING_
2019-02-28 19:45:55,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742325_1511, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:45:57,620 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742326_1512, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-28 19:45:59,341 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742327_1513, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:45:59,682 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742328_1514, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:45:59,924 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742329_1515, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile12._COPYING_
2019-02-28 19:46:00,221 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742330_1516, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-28 19:46:01,082 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742331_1517, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile14._COPYING_
2019-02-28 19:46:01,257 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742332_1518, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:46:02,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742333_1519, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:46:02,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742334_1520, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile18._COPYING_
2019-02-28 19:46:02,224 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742335_1521, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:46:02,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742336_1522, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile14._COPYING_
2019-02-28 19:46:02,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742337_1523, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile18._COPYING_
2019-02-28 19:46:02,756 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742338_1524, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile7._COPYING_
2019-02-28 19:46:02,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742339_1525, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:46:02,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742340_1526, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:46:03,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742341_1527, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile14._COPYING_
2019-02-28 19:46:03,509 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742342_1528, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:46:03,513 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742343_1529, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile12._COPYING_
2019-02-28 19:46:03,524 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742344_1530, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:46:03,544 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742345_1531, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile7._COPYING_
2019-02-28 19:46:04,093 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742346_1532, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile12._COPYING_
2019-02-28 19:46:04,111 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742347_1533, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-28 19:46:04,141 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742348_1534, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile14._COPYING_
2019-02-28 19:46:04,142 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742349_1535, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile18._COPYING_
2019-02-28 19:46:04,308 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742350_1536, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-28 19:46:04,742 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742351_1537, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:46:04,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742352_1538, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:46:04,755 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742353_1539, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-02-28 19:46:04,822 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile14._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1994177878_1
2019-02-28 19:46:04,906 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742354_1540, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:46:05,293 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742355_1541, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile18._COPYING_
2019-02-28 19:46:05,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742356_1542, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:46:05,331 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742357_1543, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile1._COPYING_
2019-02-28 19:46:05,496 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742358_1544, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile7._COPYING_
2019-02-28 19:46:05,851 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742359_1545, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.2:9866 for /myfile18._COPYING_
2019-02-28 19:46:05,943 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742360_1546, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile12._COPYING_
2019-02-28 19:46:05,950 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742361_1547, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-02-28 19:46:06,038 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742362_1548, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile7._COPYING_
2019-02-28 19:46:06,345 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile18._COPYING_ is closed by DFSClient_NONMAPREDUCE_662602368_1
2019-02-28 19:46:06,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742363_1549, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-02-28 19:46:06,472 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile12._COPYING_ is closed by DFSClient_NONMAPREDUCE_-966914785_1
2019-02-28 19:46:06,772 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile7._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1741748074_1
2019-02-28 19:46:06,883 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_1697656512_1
2019-02-28 19:46:09,845 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.10.1.4
2019-02-28 19:46:09,845 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-02-28 19:46:09,845 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1705, 1901
2019-02-28 19:46:09,862 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 198 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 80 Number of syncs: 118 SyncTimes(ms): 774 630 
2019-02-28 19:46:09,864 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000001705 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000001705-0000000000000001902
2019-02-28 19:46:09,864 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1903
2019-02-28 19:46:25,895 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742364_1550, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile10._COPYING_
2019-02-28 19:46:26,218 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742365_1551, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-28 19:46:26,591 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742366_1552, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:46:26,838 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742367_1553, replicas=10.10.1.3:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile8._COPYING_
2019-02-28 19:46:27,079 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742368_1554, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile10._COPYING_
2019-02-28 19:46:27,292 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742369_1555, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:46:27,538 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742370_1556, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:46:27,757 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742371_1557, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-28 19:46:27,962 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742372_1558, replicas=10.10.1.4:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:46:28,208 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742373_1559, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:46:28,383 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742374_1560, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:46:28,633 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742375_1561, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile8._COPYING_
2019-02-28 19:46:28,834 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742376_1562, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.5:9866 for /myfile10._COPYING_
2019-02-28 19:46:29,054 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742377_1563, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile8._COPYING_
2019-02-28 19:46:29,293 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742378_1564, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile10._COPYING_
2019-02-28 19:46:29,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742379_1565, replicas=10.10.1.5:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile8._COPYING_
2019-02-28 19:46:29,749 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile10._COPYING_ is closed by DFSClient_NONMAPREDUCE_-737802238_1
2019-02-28 19:46:29,938 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile8._COPYING_ is closed by DFSClient_NONMAPREDUCE_-906641166_1
2019-02-28 19:46:30,208 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742380_1566, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile15._COPYING_
2019-02-28 19:46:30,895 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742381_1567, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:46:31,507 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742382_1568, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:46:31,944 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742383_1569, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:46:34,453 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742384_1570, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:46:35,609 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742385_1571, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile15._COPYING_
2019-02-28 19:46:38,612 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742386_1572, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:46:39,563 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742387_1573, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:46:40,089 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742388_1574, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.4:9866 for /myfile15._COPYING_
2019-02-28 19:46:40,522 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742389_1575, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile15._COPYING_
2019-02-28 19:46:40,958 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile15._COPYING_ is closed by DFSClient_NONMAPREDUCE_2019730929_1
2019-02-28 19:46:40,980 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742390_1576, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:46:41,404 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742391_1577, replicas=10.10.1.4:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile9._COPYING_
2019-02-28 19:46:41,915 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742392_1578, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.4:9866 for /myfile9._COPYING_
2019-02-28 19:46:42,511 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742393_1579, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-28 19:46:46,909 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742394_1580, replicas=10.10.1.4:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile9._COPYING_
2019-02-28 19:46:47,369 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073742395_1581, replicas=10.10.1.2:9866, 10.10.1.4:9866, 10.10.1.3:9866 for /myfile9._COPYING_
2019-02-28 19:46:47,783 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /myfile9._COPYING_ is closed by DFSClient_NONMAPREDUCE_1707994002_1
2019-02-28 19:47:11,244 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 132 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 34 Number of syncs: 97 SyncTimes(ms): 857 670 
