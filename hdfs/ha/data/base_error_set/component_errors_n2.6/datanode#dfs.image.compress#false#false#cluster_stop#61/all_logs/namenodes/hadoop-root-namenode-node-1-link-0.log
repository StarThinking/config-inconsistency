2019-09-15 03:06:40,888 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-1-link-0/192.168.122.148
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/etc/hadoop:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-kms-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-07-19T04:04Z
STARTUP_MSG:   java = 1.8.0_212
************************************************************/
2019-09-15 03:06:40,896 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-15 03:06:40,976 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-09-15 03:06:41,161 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-09-15 03:06:41,191 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-09-15 03:06:41,276 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-09-15 03:06:41,276 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-09-15 03:06:41,314 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-09-15 03:06:41,314 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-09-15 03:06:41,422 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-09-15 03:06:41,443 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-09-15 03:06:41,457 INFO  util.log Log.java:initialized:192 - Logging initialized @1043ms
2019-09-15 03:06:41,545 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-15 03:06:41,554 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-09-15 03:06:41,562 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:970 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-15 03:06:41,564 INFO  http.HttpServer2 HttpServer2.java:addFilter:943 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-09-15 03:06:41,565 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-15 03:06:41,565 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-15 03:06:41,584 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-09-15 03:06:41,584 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:789 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-09-15 03:06:41,590 INFO  http.HttpServer2 HttpServer2.java:bindListener:1186 - Jetty bound to port 9870
2019-09-15 03:06:41,591 INFO  server.Server Server.java:doStart:351 - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T13:11:56-04:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-15 03:06:41,624 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@66982506{/logs,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/logs/,AVAILABLE}
2019-09-15 03:06:41,631 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@5a59ca5e{/static,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-09-15 03:06:41,723 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@15f47664{/,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-09-15 03:06:41,731 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@1cc0e896{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-09-15 03:06:41,732 INFO  server.Server Server.java:doStart:419 - Started @1319ms
2019-09-15 03:06:41,873 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-09-15 03:06:41,980 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-09-15 03:06:41,990 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-09-15 03:06:41,991 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:121 - fsLock is fair: true
2019-09-15 03:06:41,992 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:139 - Detailed lock hold time metrics enabled: false
2019-09-15 03:06:41,998 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-09-15 03:06:41,998 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-09-15 03:06:41,998 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-09-15 03:06:41,999 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-09-15 03:06:41,999 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-09-15 03:06:42,032 INFO  common.Util Util.java:isDiskStatsEnabled:394 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-15 03:06:42,042 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-09-15 03:06:42,042 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-15 03:06:42,046 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-15 03:06:42,046 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Sep 15 03:06:42
2019-09-15 03:06:42,048 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-09-15 03:06:42,048 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:06:42,049 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 444.5 MB = 8.9 MB
2019-09-15 03:06:42,049 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-09-15 03:06:42,057 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-09-15 03:06:42,068 INFO  Configuration.deprecation Configuration.java:logDeprecation:1394 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-09-15 03:06:42,068 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-15 03:06:42,068 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-09-15 03:06:42,068 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-09-15 03:06:42,068 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-09-15 03:06:42,068 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-09-15 03:06:42,068 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-09-15 03:06:42,069 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-09-15 03:06:42,069 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-09-15 03:06:42,069 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-09-15 03:06:42,069 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-09-15 03:06:42,095 INFO  namenode.FSDirectory SerialNumberManager.java:initialize:77 - GLOBAL serial map: bits=24 maxEntries=16777215
2019-09-15 03:06:42,109 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-09-15 03:06:42,109 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:06:42,109 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 444.5 MB = 4.4 MB
2019-09-15 03:06:42,109 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^19 = 524288 entries
2019-09-15 03:06:42,110 INFO  namenode.FSDirectory FSDirectory.java:<init>:285 - ACLs enabled? false
2019-09-15 03:06:42,110 INFO  namenode.FSDirectory FSDirectory.java:<init>:289 - POSIX ACL inheritance enabled? true
2019-09-15 03:06:42,112 INFO  namenode.FSDirectory FSDirectory.java:<init>:293 - XAttrs enabled? true
2019-09-15 03:06:42,113 INFO  namenode.NameNode FSDirectory.java:<init>:357 - Caching file names occurring more than 10 times
2019-09-15 03:06:42,131 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-09-15 03:06:42,134 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-09-15 03:06:42,139 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-09-15 03:06:42,139 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:06:42,140 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 444.5 MB = 1.1 MB
2019-09-15 03:06:42,140 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^17 = 131072 entries
2019-09-15 03:06:42,149 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-15 03:06:42,149 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-09-15 03:06:42,149 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-15 03:06:42,153 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:990 - Retry cache on namenode is enabled
2019-09-15 03:06:42,153 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:998 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-09-15 03:06:42,155 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-09-15 03:06:42,155 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:06:42,155 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 444.5 MB = 136.5 KB
2019-09-15 03:06:42,155 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^14 = 16384 entries
2019-09-15 03:06:42,194 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 3181@node-1-link-0
2019-09-15 03:06:43,436 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:43,437 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:43,437 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:44,438 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:44,439 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:44,440 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:45,440 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:45,441 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:45,441 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:46,441 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:46,442 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:46,443 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:47,443 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:47,444 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:47,444 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:48,295 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 03:06:48,444 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:48,446 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:48,446 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:49,296 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 03:06:49,446 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:49,447 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:49,448 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:06:50,090 INFO  namenode.FSImage FSImage.java:loadFSImage:718 - No edit log streams selected.
2019-09-15 03:06:50,091 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-09-15 03:06:50,182 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:233 - Loading 1 INodes.
2019-09-15 03:06:50,215 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:183 - Loaded FSImage in 0 seconds.
2019-09-15 03:06:50,216 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-09-15 03:06:50,220 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1102 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-09-15 03:06:50,220 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-09-15 03:06:50,220 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 8063 msecs
2019-09-15 03:06:50,376 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-09-15 03:06:50,381 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-15 03:06:50,394 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-09-15 03:06:50,559 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:5000 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-09-15 03:06:50,566 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-09-15 03:06:50,575 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 0 secs
2019-09-15 03:06:50,575 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 0 racks and 0 datanodes
2019-09-15 03:06:50,576 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-09-15 03:06:50,606 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-09-15 03:06:50,616 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-09-15 03:06:50,645 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/192.168.122.148:8020
2019-09-15 03:06:50,660 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1376 - Starting services required for standby state
2019-09-15 03:06:50,664 INFO  ha.EditLogTailer EditLogTailer.java:<init>:186 - Will roll logs on active node every 120 seconds.
2019-09-15 03:06:50,677 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-09-15 03:06:51,632 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.50:9866, datanodeUuid=85236b5e-74cc-44f1-b732-9d8965e2a42d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage 85236b5e-74cc-44f1-b732-9d8965e2a42d
2019-09-15 03:06:51,634 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.50:9866
2019-09-15 03:06:51,635 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 85236b5e-74cc-44f1-b732-9d8965e2a42d (192.168.122.50:9866).
2019-09-15 03:06:51,638 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.31:9866, datanodeUuid=a3ddaf29-9834-4263-9360-432a183b4f7e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage a3ddaf29-9834-4263-9360-432a183b4f7e
2019-09-15 03:06:51,638 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.31:9866
2019-09-15 03:06:51,638 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN a3ddaf29-9834-4263-9360-432a183b4f7e (192.168.122.31:9866).
2019-09-15 03:06:51,716 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.153:9866, datanodeUuid=ae59bdb9-f4b3-4594-8b68-f5b4155c47f4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage ae59bdb9-f4b3-4594-8b68-f5b4155c47f4
2019-09-15 03:06:51,717 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.153:9866
2019-09-15 03:06:51,717 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN ae59bdb9-f4b3-4594-8b68-f5b4155c47f4 (192.168.122.153:9866).
2019-09-15 03:06:51,737 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 for DN 192.168.122.50:9866
2019-09-15 03:06:51,743 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-7030c263-fd6e-445c-add8-a45a5e96f152 for DN 192.168.122.31:9866
2019-09-15 03:06:51,766 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 for DN 192.168.122.153:9866
2019-09-15 03:06:51,784 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x3f08017c26d20213: Processing first storage report for DS-7030c263-fd6e-445c-add8-a45a5e96f152 from datanode a3ddaf29-9834-4263-9360-432a183b4f7e
2019-09-15 03:06:51,786 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x3f08017c26d20213: from storage DS-7030c263-fd6e-445c-add8-a45a5e96f152 node DatanodeRegistration(192.168.122.31:9866, datanodeUuid=a3ddaf29-9834-4263-9360-432a183b4f7e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-09-15 03:06:51,788 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x292ab5dad4d793e4: Processing first storage report for DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 from datanode 85236b5e-74cc-44f1-b732-9d8965e2a42d
2019-09-15 03:06:51,788 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x292ab5dad4d793e4: from storage DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 node DatanodeRegistration(192.168.122.50:9866, datanodeUuid=85236b5e-74cc-44f1-b732-9d8965e2a42d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 03:06:51,802 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xf094be92d9e7b775: Processing first storage report for DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 from datanode ae59bdb9-f4b3-4594-8b68-f5b4155c47f4
2019-09-15 03:06:51,802 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xf094be92d9e7b775: from storage DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 node DatanodeRegistration(192.168.122.153:9866, datanodeUuid=ae59bdb9-f4b3-4594-8b68-f5b4155c47f4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 03:06:52,018 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.235:9866, datanodeUuid=95f66c0e-6699-4f0f-b589-cdf63382f5b9, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage 95f66c0e-6699-4f0f-b589-cdf63382f5b9
2019-09-15 03:06:52,019 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.235:9866
2019-09-15 03:06:52,020 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 95f66c0e-6699-4f0f-b589-cdf63382f5b9 (192.168.122.235:9866).
2019-09-15 03:06:52,060 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 for DN 192.168.122.235:9866
2019-09-15 03:06:52,083 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x6fdeccbd349bddf1: Processing first storage report for DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 from datanode 95f66c0e-6699-4f0f-b589-cdf63382f5b9
2019-09-15 03:06:52,083 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x6fdeccbd349bddf1: from storage DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 node DatanodeRegistration(192.168.122.235:9866, datanodeUuid=95f66c0e-6699-4f0f-b589-cdf63382f5b9, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-09-15 03:07:42,946 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-09-15 03:07:42,950 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-1-link-0/192.168.122.148
************************************************************/
2019-09-15 03:07:56,986 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-1-link-0/192.168.122.148
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/etc/hadoop:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-kms-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-07-19T04:04Z
STARTUP_MSG:   java = 1.8.0_212
************************************************************/
2019-09-15 03:07:56,995 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-15 03:07:57,100 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-09-15 03:07:57,280 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-09-15 03:07:57,313 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-09-15 03:07:57,401 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-09-15 03:07:57,401 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-09-15 03:07:57,441 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-09-15 03:07:57,441 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-09-15 03:07:57,566 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-09-15 03:07:57,585 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-09-15 03:07:57,600 INFO  util.log Log.java:initialized:192 - Logging initialized @1068ms
2019-09-15 03:07:57,694 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-15 03:07:57,704 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-09-15 03:07:57,714 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:970 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-15 03:07:57,717 INFO  http.HttpServer2 HttpServer2.java:addFilter:943 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-09-15 03:07:57,720 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-15 03:07:57,721 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-15 03:07:57,745 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-09-15 03:07:57,745 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:789 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-09-15 03:07:57,753 INFO  http.HttpServer2 HttpServer2.java:bindListener:1186 - Jetty bound to port 9870
2019-09-15 03:07:57,754 INFO  server.Server Server.java:doStart:351 - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T13:11:56-04:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-15 03:07:57,791 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@66982506{/logs,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/logs/,AVAILABLE}
2019-09-15 03:07:57,792 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@5a59ca5e{/static,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-09-15 03:07:57,858 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@15f47664{/,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-09-15 03:07:57,863 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@56dc1551{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-09-15 03:07:57,863 INFO  server.Server Server.java:doStart:419 - Started @1332ms
2019-09-15 03:07:58,012 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-09-15 03:07:58,141 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-09-15 03:07:58,152 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-09-15 03:07:58,154 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:121 - fsLock is fair: true
2019-09-15 03:07:58,155 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:139 - Detailed lock hold time metrics enabled: false
2019-09-15 03:07:58,161 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-09-15 03:07:58,161 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-09-15 03:07:58,161 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-09-15 03:07:58,162 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-09-15 03:07:58,162 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-09-15 03:07:58,218 INFO  common.Util Util.java:isDiskStatsEnabled:394 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-15 03:07:58,232 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-09-15 03:07:58,233 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-15 03:07:58,242 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-15 03:07:58,242 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Sep 15 03:07:58
2019-09-15 03:07:58,246 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-09-15 03:07:58,246 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:07:58,248 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 444.5 MB = 8.9 MB
2019-09-15 03:07:58,249 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-09-15 03:07:58,261 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-09-15 03:07:58,273 INFO  Configuration.deprecation Configuration.java:logDeprecation:1394 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-09-15 03:07:58,273 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-15 03:07:58,274 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-09-15 03:07:58,274 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-09-15 03:07:58,274 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-09-15 03:07:58,274 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-09-15 03:07:58,274 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-09-15 03:07:58,274 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-09-15 03:07:58,275 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-09-15 03:07:58,275 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-09-15 03:07:58,275 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-09-15 03:07:58,310 INFO  namenode.FSDirectory SerialNumberManager.java:initialize:77 - GLOBAL serial map: bits=24 maxEntries=16777215
2019-09-15 03:07:58,329 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-09-15 03:07:58,330 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:07:58,330 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 444.5 MB = 4.4 MB
2019-09-15 03:07:58,330 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^19 = 524288 entries
2019-09-15 03:07:58,331 INFO  namenode.FSDirectory FSDirectory.java:<init>:285 - ACLs enabled? false
2019-09-15 03:07:58,331 INFO  namenode.FSDirectory FSDirectory.java:<init>:289 - POSIX ACL inheritance enabled? true
2019-09-15 03:07:58,331 INFO  namenode.FSDirectory FSDirectory.java:<init>:293 - XAttrs enabled? true
2019-09-15 03:07:58,331 INFO  namenode.NameNode FSDirectory.java:<init>:357 - Caching file names occurring more than 10 times
2019-09-15 03:07:58,337 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-09-15 03:07:58,340 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-09-15 03:07:58,344 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-09-15 03:07:58,344 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:07:58,344 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 444.5 MB = 1.1 MB
2019-09-15 03:07:58,344 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^17 = 131072 entries
2019-09-15 03:07:58,351 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-15 03:07:58,351 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-09-15 03:07:58,351 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-15 03:07:58,354 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:990 - Retry cache on namenode is enabled
2019-09-15 03:07:58,354 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:998 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-09-15 03:07:58,356 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-09-15 03:07:58,356 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:07:58,356 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 444.5 MB = 136.5 KB
2019-09-15 03:07:58,356 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^14 = 16384 entries
2019-09-15 03:07:58,386 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 3609@node-1-link-0
2019-09-15 03:07:59,692 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:07:59,692 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:07:59,693 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:00,693 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:00,694 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:00,696 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:01,695 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:01,697 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:01,697 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:02,697 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:02,698 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:02,699 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:03,699 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:03,700 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:03,700 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:04,531 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 03:08:04,701 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:04,701 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:04,702 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:05,533 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 03:08:05,702 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:05,703 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:05,704 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:08:06,443 INFO  namenode.FSImage FSImage.java:loadFSImage:718 - No edit log streams selected.
2019-09-15 03:08:06,444 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-09-15 03:08:06,533 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:233 - Loading 1 INodes.
2019-09-15 03:08:06,581 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:183 - Loaded FSImage in 0 seconds.
2019-09-15 03:08:06,581 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-09-15 03:08:06,588 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1102 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-09-15 03:08:06,589 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-09-15 03:08:06,589 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 8231 msecs
2019-09-15 03:08:06,785 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-09-15 03:08:06,789 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-15 03:08:06,799 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-09-15 03:08:06,958 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:5000 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-09-15 03:08:06,970 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-09-15 03:08:06,982 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 0 secs
2019-09-15 03:08:06,982 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 0 racks and 0 datanodes
2019-09-15 03:08:06,982 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-09-15 03:08:07,014 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-09-15 03:08:07,017 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/192.168.122.148:8020
2019-09-15 03:08:07,019 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1376 - Starting services required for standby state
2019-09-15 03:08:07,023 INFO  ha.EditLogTailer EditLogTailer.java:<init>:186 - Will roll logs on active node every 120 seconds.
2019-09-15 03:08:07,023 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-09-15 03:08:07,051 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-09-15 03:08:09,415 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1419 - Stopping services started for standby state
2019-09-15 03:08:09,420 WARN  ha.EditLogTailer EditLogTailer.java:doWork:471 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2019-09-15 03:08:09,527 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Starting services required for active state
2019-09-15 03:08:09,541 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:442 - Starting recovery process for unclosed journal segments...
2019-09-15 03:08:09,768 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:444 - Successfully started new epoch 2
2019-09-15 03:08:09,769 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:284 - Beginning recovery of unclosed segment starting at txid 1
2019-09-15 03:08:09,827 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:293 - Recovery prepare phase complete. Responses:
192.168.122.31:8485: segmentState { startTxId: 1 endTxId: 31 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 30
192.168.122.235:8485: segmentState { startTxId: 1 endTxId: 31 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 30
2019-09-15 03:08:09,832 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:317 - Using longest log: 192.168.122.31:8485=segmentState {
  startTxId: 1
  endTxId: 31
  isInProgress: true
}
lastWriterEpoch: 1
lastCommittedTxId: 30

2019-09-15 03:08:10,011 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-09-15 03:08:10,012 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1225 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-09-15 03:08:10,045 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@50bb6ea0 expecting start txid #1
2019-09-15 03:08:10,046 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:08:10,053 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:08:10,053 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:08:10,491 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 31 loaded in 0 seconds
2019-09-15 03:08:10,492 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1840 - Marking all datanodes as stale
2019-09-15 03:08:10,492 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1236 - Reprocessing replication and invalidation queues
2019-09-15 03:08:10,492 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4792 - initializing replication queues
2019-09-15 03:08:10,493 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1247 - Will take over writing edit logs at txnid 32
2019-09-15 03:08:10,508 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 32
2019-09-15 03:08:11,063 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:769 - Initializing quota with 4 thread(s)
2019-09-15 03:08:11,068 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:778 - Quota initialization completed in 5 milliseconds
name space=6
storage space=2013265920
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-09-15 03:08:11,078 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.31:9866, datanodeUuid=a3ddaf29-9834-4263-9360-432a183b4f7e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage a3ddaf29-9834-4263-9360-432a183b4f7e
2019-09-15 03:08:11,079 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.31:9866
2019-09-15 03:08:11,079 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN a3ddaf29-9834-4263-9360-432a183b4f7e (192.168.122.31:9866).
2019-09-15 03:08:11,084 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.235:9866, datanodeUuid=95f66c0e-6699-4f0f-b589-cdf63382f5b9, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage 95f66c0e-6699-4f0f-b589-cdf63382f5b9
2019-09-15 03:08:11,087 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.235:9866
2019-09-15 03:08:11,087 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 95f66c0e-6699-4f0f-b589-cdf63382f5b9 (192.168.122.235:9866).
2019-09-15 03:08:11,088 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.50:9866, datanodeUuid=85236b5e-74cc-44f1-b732-9d8965e2a42d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage 85236b5e-74cc-44f1-b732-9d8965e2a42d
2019-09-15 03:08:11,088 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.50:9866
2019-09-15 03:08:11,088 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 85236b5e-74cc-44f1-b732-9d8965e2a42d (192.168.122.50:9866).
2019-09-15 03:08:11,088 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.153:9866, datanodeUuid=ae59bdb9-f4b3-4594-8b68-f5b4155c47f4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage ae59bdb9-f4b3-4594-8b68-f5b4155c47f4
2019-09-15 03:08:11,089 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.153:9866
2019-09-15 03:08:11,089 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN ae59bdb9-f4b3-4594-8b68-f5b4155c47f4 (192.168.122.153:9866).
2019-09-15 03:08:11,110 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-09-15 03:08:11,123 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3475 - Total number of blocks            = 5
2019-09-15 03:08:11,124 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3476 - Number of invalid blocks          = 0
2019-09-15 03:08:11,124 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3477 - Number of under-replicated blocks = 5
2019-09-15 03:08:11,124 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3478 - Number of  over-replicated blocks = 0
2019-09-15 03:08:11,124 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3480 - Number of blocks being written    = 0
2019-09-15 03:08:11,124 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3483 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 631 msec
2019-09-15 03:08:11,152 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 for DN 192.168.122.235:9866
2019-09-15 03:08:11,162 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 for DN 192.168.122.50:9866
2019-09-15 03:08:11,167 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-7030c263-fd6e-445c-add8-a45a5e96f152 for DN 192.168.122.31:9866
2019-09-15 03:08:11,167 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 for DN 192.168.122.153:9866
2019-09-15 03:08:11,184 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xbe49c0b17e401fec: Processing first storage report for DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 from datanode 85236b5e-74cc-44f1-b732-9d8965e2a42d
2019-09-15 03:08:11,188 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xbe49c0b17e401fec: from storage DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 node DatanodeRegistration(192.168.122.50:9866, datanodeUuid=85236b5e-74cc-44f1-b732-9d8965e2a42d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 3, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2019-09-15 03:08:11,188 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xae39ad032c7656c4: Processing first storage report for DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 from datanode 95f66c0e-6699-4f0f-b589-cdf63382f5b9
2019-09-15 03:08:11,188 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xae39ad032c7656c4: from storage DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 node DatanodeRegistration(192.168.122.235:9866, datanodeUuid=95f66c0e-6699-4f0f-b589-cdf63382f5b9, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 3, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-09-15 03:08:11,195 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x51080075e94a8962: Processing first storage report for DS-7030c263-fd6e-445c-add8-a45a5e96f152 from datanode a3ddaf29-9834-4263-9360-432a183b4f7e
2019-09-15 03:08:11,196 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x51080075e94a8962: from storage DS-7030c263-fd6e-445c-add8-a45a5e96f152 node DatanodeRegistration(192.168.122.31:9866, datanodeUuid=a3ddaf29-9834-4263-9360-432a183b4f7e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 4, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 03:08:11,196 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x32f8efdf58e057ac: Processing first storage report for DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 from datanode ae59bdb9-f4b3-4594-8b68-f5b4155c47f4
2019-09-15 03:08:11,198 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x32f8efdf58e057ac: from storage DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 node DatanodeRegistration(192.168.122.153:9866, datanodeUuid=ae59bdb9-f4b3-4594-8b68-f5b4155c47f4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 5, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-09-15 03:08:38,408 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741830_1006, replicas=192.168.122.50:9866, 192.168.122.31:9866, 192.168.122.235:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 03:08:38,428 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741831_1007, replicas=192.168.122.235:9866, 192.168.122.153:9866, 192.168.122.31:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 03:08:38,532 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741832_1008, replicas=192.168.122.153:9866, 192.168.122.31:9866, 192.168.122.235:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 03:08:38,667 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741833_1009, replicas=192.168.122.50:9866, 192.168.122.235:9866, 192.168.122.31:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 03:08:38,944 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741834_1010, replicas=192.168.122.235:9866, 192.168.122.31:9866, 192.168.122.50:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 03:08:46,413 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-182587689_1
2019-09-15 03:08:46,507 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1483040068_1
2019-09-15 03:08:46,574 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1201241495_1
2019-09-15 03:08:46,716 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_597260862_1
2019-09-15 03:08:46,724 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1896699714_1
2019-09-15 03:08:52,413 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for sendEdits. No responses yet.
2019-09-15 03:08:53,413 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for sendEdits. No responses yet.
2019-09-15 03:08:54,414 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 8003 ms (timeout=20000 ms) for a response for sendEdits. No responses yet.
2019-09-15 03:08:55,266 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 8854ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.31:8485
2019-09-15 03:08:55,415 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 9004 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.31:8485]
2019-09-15 03:08:56,417 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 10005 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.31:8485]
2019-09-15 03:08:57,418 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 11006 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.31:8485]
2019-09-15 03:08:58,183 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 11772ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.50:8485
2019-09-15 03:08:59,391 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 26 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 40 Number of syncs: 13 SyncTimes(ms): 12476 1445 
2019-09-15 03:08:59,401 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 12989ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.235:8485
2019-09-15 03:09:54,533 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-09-15 03:09:54,535 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-1-link-0/192.168.122.148
************************************************************/
2019-09-15 03:10:08,274 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-1-link-0/192.168.122.148
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/etc/hadoop:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-kms-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-07-19T04:04Z
STARTUP_MSG:   java = 1.8.0_212
************************************************************/
2019-09-15 03:10:08,283 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-15 03:10:08,390 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-09-15 03:10:08,622 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-09-15 03:10:08,660 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-09-15 03:10:08,766 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-09-15 03:10:08,766 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-09-15 03:10:08,812 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-09-15 03:10:08,812 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-09-15 03:10:08,953 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-09-15 03:10:08,986 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-09-15 03:10:09,005 INFO  util.log Log.java:initialized:192 - Logging initialized @1224ms
2019-09-15 03:10:09,106 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-15 03:10:09,116 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-09-15 03:10:09,124 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:970 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-15 03:10:09,126 INFO  http.HttpServer2 HttpServer2.java:addFilter:943 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-09-15 03:10:09,128 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-15 03:10:09,128 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-15 03:10:09,149 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-09-15 03:10:09,149 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:789 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-09-15 03:10:09,157 INFO  http.HttpServer2 HttpServer2.java:bindListener:1186 - Jetty bound to port 9870
2019-09-15 03:10:09,158 INFO  server.Server Server.java:doStart:351 - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T13:11:56-04:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-15 03:10:09,186 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@66982506{/logs,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/logs/,AVAILABLE}
2019-09-15 03:10:09,187 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@5a59ca5e{/static,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-09-15 03:10:09,289 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@15f47664{/,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-09-15 03:10:09,298 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@56dc1551{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-09-15 03:10:09,298 INFO  server.Server Server.java:doStart:419 - Started @1517ms
2019-09-15 03:10:09,542 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-09-15 03:10:09,665 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-09-15 03:10:09,681 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-09-15 03:10:09,683 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:121 - fsLock is fair: true
2019-09-15 03:10:09,685 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:139 - Detailed lock hold time metrics enabled: false
2019-09-15 03:10:09,694 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-09-15 03:10:09,694 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-09-15 03:10:09,694 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-09-15 03:10:09,695 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-09-15 03:10:09,695 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-09-15 03:10:09,735 INFO  common.Util Util.java:isDiskStatsEnabled:394 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-15 03:10:09,746 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-09-15 03:10:09,746 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-15 03:10:09,749 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-15 03:10:09,750 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Sep 15 03:10:09
2019-09-15 03:10:09,752 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-09-15 03:10:09,752 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:10:09,753 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 444.5 MB = 8.9 MB
2019-09-15 03:10:09,753 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-09-15 03:10:09,761 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-09-15 03:10:09,772 INFO  Configuration.deprecation Configuration.java:logDeprecation:1394 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-09-15 03:10:09,773 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-15 03:10:09,773 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-09-15 03:10:09,773 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-09-15 03:10:09,773 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-09-15 03:10:09,773 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-09-15 03:10:09,773 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-09-15 03:10:09,773 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-09-15 03:10:09,773 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-09-15 03:10:09,774 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-09-15 03:10:09,774 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-09-15 03:10:09,804 INFO  namenode.FSDirectory SerialNumberManager.java:initialize:77 - GLOBAL serial map: bits=24 maxEntries=16777215
2019-09-15 03:10:09,818 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-09-15 03:10:09,818 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:10:09,818 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 444.5 MB = 4.4 MB
2019-09-15 03:10:09,818 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^19 = 524288 entries
2019-09-15 03:10:09,819 INFO  namenode.FSDirectory FSDirectory.java:<init>:285 - ACLs enabled? false
2019-09-15 03:10:09,819 INFO  namenode.FSDirectory FSDirectory.java:<init>:289 - POSIX ACL inheritance enabled? true
2019-09-15 03:10:09,822 INFO  namenode.FSDirectory FSDirectory.java:<init>:293 - XAttrs enabled? true
2019-09-15 03:10:09,822 INFO  namenode.NameNode FSDirectory.java:<init>:357 - Caching file names occurring more than 10 times
2019-09-15 03:10:09,826 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-09-15 03:10:09,831 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-09-15 03:10:09,835 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-09-15 03:10:09,835 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:10:09,835 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 444.5 MB = 1.1 MB
2019-09-15 03:10:09,836 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^17 = 131072 entries
2019-09-15 03:10:09,843 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-15 03:10:09,843 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-09-15 03:10:09,843 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-15 03:10:09,847 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:990 - Retry cache on namenode is enabled
2019-09-15 03:10:09,847 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:998 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-09-15 03:10:09,850 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-09-15 03:10:09,850 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:10:09,850 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 444.5 MB = 136.5 KB
2019-09-15 03:10:09,850 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^14 = 16384 entries
2019-09-15 03:10:09,893 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 4114@node-1-link-0
2019-09-15 03:10:11,263 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:11,263 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:11,263 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:12,265 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:12,265 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:12,266 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:13,266 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:13,267 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:13,269 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:14,268 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:14,269 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:14,271 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:15,269 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:15,270 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:15,272 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:16,113 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 03:10:16,271 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:16,271 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:16,273 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:17,114 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 03:10:17,272 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:17,273 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:17,275 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:10:17,650 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-09-15 03:10:17,734 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:233 - Loading 1 INodes.
2019-09-15 03:10:17,765 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:183 - Loaded FSImage in 0 seconds.
2019-09-15 03:10:17,765 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-09-15 03:10:17,769 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@41dd05a expecting start txid #1
2019-09-15 03:10:17,769 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:10:17,772 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:10:17,773 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:10:18,048 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 31 loaded in 0 seconds
2019-09-15 03:10:18,049 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1102 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-09-15 03:10:18,049 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-09-15 03:10:18,049 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 8194 msecs
2019-09-15 03:10:18,265 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-09-15 03:10:18,270 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-15 03:10:18,281 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-09-15 03:10:18,524 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:5000 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-09-15 03:10:18,538 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-09-15 03:10:18,547 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON. 
The reported blocks 0 needs additional 4 blocks to reach the threshold 0.9990 of total blocks 5.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-09-15 03:10:18,591 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-09-15 03:10:18,592 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-09-15 03:10:18,600 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/192.168.122.148:8020
2019-09-15 03:10:18,603 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1376 - Starting services required for standby state
2019-09-15 03:10:18,614 INFO  ha.EditLogTailer EditLogTailer.java:<init>:186 - Will roll logs on active node every 120 seconds.
2019-09-15 03:10:18,635 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-09-15 03:10:19,717 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.50:9866, datanodeUuid=85236b5e-74cc-44f1-b732-9d8965e2a42d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage 85236b5e-74cc-44f1-b732-9d8965e2a42d
2019-09-15 03:10:19,724 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.50:9866
2019-09-15 03:10:19,725 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 85236b5e-74cc-44f1-b732-9d8965e2a42d (192.168.122.50:9866).
2019-09-15 03:10:19,728 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.153:9866, datanodeUuid=ae59bdb9-f4b3-4594-8b68-f5b4155c47f4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage ae59bdb9-f4b3-4594-8b68-f5b4155c47f4
2019-09-15 03:10:19,728 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.153:9866
2019-09-15 03:10:19,728 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN ae59bdb9-f4b3-4594-8b68-f5b4155c47f4 (192.168.122.153:9866).
2019-09-15 03:10:19,744 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.31:9866, datanodeUuid=a3ddaf29-9834-4263-9360-432a183b4f7e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage a3ddaf29-9834-4263-9360-432a183b4f7e
2019-09-15 03:10:19,745 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.31:9866
2019-09-15 03:10:19,745 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN a3ddaf29-9834-4263-9360-432a183b4f7e (192.168.122.31:9866).
2019-09-15 03:10:19,953 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-7030c263-fd6e-445c-add8-a45a5e96f152 for DN 192.168.122.31:9866
2019-09-15 03:10:19,959 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 for DN 192.168.122.50:9866
2019-09-15 03:10:19,962 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 for DN 192.168.122.153:9866
2019-09-15 03:10:19,972 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.235:9866, datanodeUuid=95f66c0e-6699-4f0f-b589-cdf63382f5b9, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage 95f66c0e-6699-4f0f-b589-cdf63382f5b9
2019-09-15 03:10:19,972 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.235:9866
2019-09-15 03:10:19,972 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 95f66c0e-6699-4f0f-b589-cdf63382f5b9 (192.168.122.235:9866).
2019-09-15 03:10:20,011 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xc590562bafcab3c7: Processing first storage report for DS-7030c263-fd6e-445c-add8-a45a5e96f152 from datanode a3ddaf29-9834-4263-9360-432a183b4f7e
2019-09-15 03:10:20,019 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode extension entered. 
The reported blocks 4 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2019-09-15 03:10:20,019 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xc590562bafcab3c7: from storage DS-7030c263-fd6e-445c-add8-a45a5e96f152 node DatanodeRegistration(192.168.122.31:9866, datanodeUuid=a3ddaf29-9834-4263-9360-432a183b4f7e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 4, hasStaleStorage: false, processing time: 8 msecs, invalidatedBlocks: 0
2019-09-15 03:10:20,020 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x89efc4496d0cf41c: Processing first storage report for DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 from datanode 85236b5e-74cc-44f1-b732-9d8965e2a42d
2019-09-15 03:10:20,020 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x89efc4496d0cf41c: from storage DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 node DatanodeRegistration(192.168.122.50:9866, datanodeUuid=85236b5e-74cc-44f1-b732-9d8965e2a42d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 03:10:20,020 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xf3a79bbff2532b68: Processing first storage report for DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 from datanode ae59bdb9-f4b3-4594-8b68-f5b4155c47f4
2019-09-15 03:10:20,020 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xf3a79bbff2532b68: from storage DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 node DatanodeRegistration(192.168.122.153:9866, datanodeUuid=ae59bdb9-f4b3-4594-8b68-f5b4155c47f4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 5, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 03:10:20,032 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 for DN 192.168.122.235:9866
2019-09-15 03:10:20,079 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xa45b5f19f7df86fe: Processing first storage report for DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 from datanode 95f66c0e-6699-4f0f-b589-cdf63382f5b9
2019-09-15 03:10:20,081 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xa45b5f19f7df86fe: from storage DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 node DatanodeRegistration(192.168.122.235:9866, datanodeUuid=95f66c0e-6699-4f0f-b589-cdf63382f5b9, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 3, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-09-15 03:10:20,151 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1419 - Stopping services started for standby state
2019-09-15 03:10:20,152 WARN  ha.EditLogTailer EditLogTailer.java:doWork:471 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2019-09-15 03:10:20,259 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Starting services required for active state
2019-09-15 03:10:20,301 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:442 - Starting recovery process for unclosed journal segments...
2019-09-15 03:10:20,487 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:444 - Successfully started new epoch 3
2019-09-15 03:10:20,487 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:284 - Beginning recovery of unclosed segment starting at txid 32
2019-09-15 03:10:20,560 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:293 - Recovery prepare phase complete. Responses:
192.168.122.235:8485: segmentState { startTxId: 32 endTxId: 67 isInProgress: true } lastWriterEpoch: 2 lastCommittedTxId: 66
192.168.122.50:8485: segmentState { startTxId: 32 endTxId: 67 isInProgress: true } lastWriterEpoch: 2 lastCommittedTxId: 66
2019-09-15 03:10:20,563 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:317 - Using longest log: 192.168.122.235:8485=segmentState {
  startTxId: 32
  endTxId: 67
  isInProgress: true
}
lastWriterEpoch: 2
lastCommittedTxId: 66

2019-09-15 03:10:20,722 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-09-15 03:10:20,748 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000032 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000032-0000000000000000067
2019-09-15 03:10:20,773 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1225 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-09-15 03:10:20,784 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7e369796 expecting start txid #32
2019-09-15 03:10:20,784 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000032-0000000000000000067, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:10:20,785 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream '/tmp/hadoop-root/dfs/name/current/edits_0000000000000000032-0000000000000000067' to transaction ID 32
2019-09-15 03:10:20,804 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000032-0000000000000000067, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 36 loaded in 0 seconds
2019-09-15 03:10:20,804 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1840 - Marking all datanodes as stale
2019-09-15 03:10:20,805 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1247 - Will take over writing edit logs at txnid 68
2019-09-15 03:10:20,813 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 68
2019-09-15 03:10:21,401 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:769 - Initializing quota with 4 thread(s)
2019-09-15 03:10:21,409 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:778 - Quota initialization completed in 7 milliseconds
name space=6
storage space=2013265920
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-09-15 03:10:21,421 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-09-15 03:10:40,420 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON, in safe mode extension. 
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-09-15 03:10:50,423 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4792 - initializing replication queues
2019-09-15 03:10:50,424 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:391 - STATE* Safe mode is OFF
2019-09-15 03:10:50,424 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 31 secs
2019-09-15 03:10:50,424 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 1 racks and 4 datanodes
2019-09-15 03:10:50,424 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-09-15 03:10:50,432 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3475 - Total number of blocks            = 5
2019-09-15 03:10:50,432 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3476 - Number of invalid blocks          = 0
2019-09-15 03:10:50,434 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3477 - Number of under-replicated blocks = 0
2019-09-15 03:10:50,435 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3478 - Number of  over-replicated blocks = 0
2019-09-15 03:10:50,435 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3480 - Number of blocks being written    = 0
2019-09-15 03:10:50,435 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3483 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 12 msec
2019-09-15 03:10:55,258 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741835_1011, replicas=192.168.122.153:9866, 192.168.122.235:9866, 192.168.122.50:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 03:10:55,374 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741836_1012, replicas=192.168.122.153:9866, 192.168.122.235:9866, 192.168.122.50:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 03:10:55,395 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741837_1013, replicas=192.168.122.31:9866, 192.168.122.235:9866, 192.168.122.50:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 03:10:55,477 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741838_1014, replicas=192.168.122.31:9866, 192.168.122.235:9866, 192.168.122.153:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 03:10:55,645 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741839_1015, replicas=192.168.122.50:9866, 192.168.122.31:9866, 192.168.122.235:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 03:10:58,660 INFO  namenode.FSNamesystem FSNamesystem.java:checkBlocksComplete:2908 - BLOCK* blk_1073741835_1011 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /myfile5.remotecopy._COPYING_
2019-09-15 03:10:58,934 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2129640884_1
2019-09-15 03:10:58,980 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1771116447_1
2019-09-15 03:10:59,047 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1502302850_1
2019-09-15 03:10:59,072 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-712278146_1
2019-09-15 03:10:59,091 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_580727694_1
2019-09-15 03:11:04,936 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6002 ms (timeout=20000 ms) for a response for sendEdits. No responses yet.
2019-09-15 03:11:10,556 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 11621ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.31:8485
2019-09-15 03:11:10,557 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 11623 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.31:8485]
2019-09-15 03:11:11,559 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 12624 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.31:8485]
2019-09-15 03:11:12,559 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 13625 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.31:8485]
2019-09-15 03:11:13,561 WARN  client.QuorumJournalManager QuorumCall.java:waitFor:185 - Waited 14627 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.31:8485]
2019-09-15 03:11:14,563 WARN  client.QuorumJournalManager QuorumCall.java:waitFor:185 - Waited 15628 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.31:8485]
2019-09-15 03:11:15,334 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 16399ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.50:8485
2019-09-15 03:11:17,625 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 18689ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.235:8485
2019-09-15 03:11:17,875 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 26 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 78 Number of syncs: 11 SyncTimes(ms): 16704 2735 
2019-09-15 03:12:04,929 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-09-15 03:12:04,933 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-1-link-0/192.168.122.148
************************************************************/
2019-09-15 03:12:18,782 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-1-link-0/192.168.122.148
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/etc/hadoop:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-kms-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-07-19T04:04Z
STARTUP_MSG:   java = 1.8.0_212
************************************************************/
2019-09-15 03:12:18,793 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-15 03:12:18,886 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-09-15 03:12:19,086 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-09-15 03:12:19,120 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-09-15 03:12:19,211 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-09-15 03:12:19,211 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-09-15 03:12:19,252 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-09-15 03:12:19,252 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-09-15 03:12:19,380 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-09-15 03:12:19,391 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-09-15 03:12:19,405 INFO  util.log Log.java:initialized:192 - Logging initialized @1132ms
2019-09-15 03:12:19,513 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-15 03:12:19,523 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-09-15 03:12:19,532 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:970 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-15 03:12:19,534 INFO  http.HttpServer2 HttpServer2.java:addFilter:943 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-09-15 03:12:19,537 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-15 03:12:19,537 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-15 03:12:19,559 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-09-15 03:12:19,559 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:789 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-09-15 03:12:19,566 INFO  http.HttpServer2 HttpServer2.java:bindListener:1186 - Jetty bound to port 9870
2019-09-15 03:12:19,567 INFO  server.Server Server.java:doStart:351 - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T13:11:56-04:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-15 03:12:19,600 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@66982506{/logs,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/logs/,AVAILABLE}
2019-09-15 03:12:19,607 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@5a59ca5e{/static,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-09-15 03:12:19,663 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@15f47664{/,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-09-15 03:12:19,669 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@45902e7d{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-09-15 03:12:19,669 INFO  server.Server Server.java:doStart:419 - Started @1396ms
2019-09-15 03:12:19,841 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-09-15 03:12:19,944 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-09-15 03:12:19,954 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-09-15 03:12:19,955 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:121 - fsLock is fair: true
2019-09-15 03:12:19,957 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:139 - Detailed lock hold time metrics enabled: false
2019-09-15 03:12:19,962 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-09-15 03:12:19,962 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-09-15 03:12:19,962 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-09-15 03:12:19,964 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-09-15 03:12:19,964 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-09-15 03:12:20,017 INFO  common.Util Util.java:isDiskStatsEnabled:394 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-15 03:12:20,033 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-09-15 03:12:20,033 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-15 03:12:20,038 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-15 03:12:20,039 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Sep 15 03:12:20
2019-09-15 03:12:20,041 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-09-15 03:12:20,041 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:12:20,043 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 444.5 MB = 8.9 MB
2019-09-15 03:12:20,043 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-09-15 03:12:20,053 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-09-15 03:12:20,066 INFO  Configuration.deprecation Configuration.java:logDeprecation:1394 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-09-15 03:12:20,066 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-15 03:12:20,066 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-09-15 03:12:20,066 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-09-15 03:12:20,067 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-09-15 03:12:20,067 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-09-15 03:12:20,067 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-09-15 03:12:20,067 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-09-15 03:12:20,067 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-09-15 03:12:20,067 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-09-15 03:12:20,067 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-09-15 03:12:20,105 INFO  namenode.FSDirectory SerialNumberManager.java:initialize:77 - GLOBAL serial map: bits=24 maxEntries=16777215
2019-09-15 03:12:20,122 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-09-15 03:12:20,122 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:12:20,122 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 444.5 MB = 4.4 MB
2019-09-15 03:12:20,122 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^19 = 524288 entries
2019-09-15 03:12:20,123 INFO  namenode.FSDirectory FSDirectory.java:<init>:285 - ACLs enabled? false
2019-09-15 03:12:20,123 INFO  namenode.FSDirectory FSDirectory.java:<init>:289 - POSIX ACL inheritance enabled? true
2019-09-15 03:12:20,125 INFO  namenode.FSDirectory FSDirectory.java:<init>:293 - XAttrs enabled? true
2019-09-15 03:12:20,126 INFO  namenode.NameNode FSDirectory.java:<init>:357 - Caching file names occurring more than 10 times
2019-09-15 03:12:20,130 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-09-15 03:12:20,135 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-09-15 03:12:20,139 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-09-15 03:12:20,139 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:12:20,140 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 444.5 MB = 1.1 MB
2019-09-15 03:12:20,140 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^17 = 131072 entries
2019-09-15 03:12:20,147 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-15 03:12:20,148 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-09-15 03:12:20,148 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-15 03:12:20,152 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:990 - Retry cache on namenode is enabled
2019-09-15 03:12:20,152 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:998 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-09-15 03:12:20,154 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-09-15 03:12:20,154 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:12:20,155 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 444.5 MB = 136.5 KB
2019-09-15 03:12:20,155 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^14 = 16384 entries
2019-09-15 03:12:20,191 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 4576@node-1-link-0
2019-09-15 03:12:21,500 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:21,500 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:21,500 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:22,501 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:22,502 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:22,503 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:23,503 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:23,504 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:23,505 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:24,505 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:24,506 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:24,507 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:25,507 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:25,507 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:25,508 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:26,327 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 03:12:26,508 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:26,509 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:26,509 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:27,328 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 03:12:27,510 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:27,510 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:27,510 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:12:28,193 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-09-15 03:12:28,277 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:233 - Loading 1 INodes.
2019-09-15 03:12:28,309 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:183 - Loaded FSImage in 0 seconds.
2019-09-15 03:12:28,309 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-09-15 03:12:28,313 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@67c2e933 expecting start txid #1
2019-09-15 03:12:28,313 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:12:28,317 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:12:28,317 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:12:28,567 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 31 loaded in 0 seconds
2019-09-15 03:12:28,568 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@41dd05a expecting start txid #32
2019-09-15 03:12:28,568 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:12:28,568 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:12:28,568 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:12:28,701 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 36 loaded in 0 seconds
2019-09-15 03:12:28,701 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1102 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-09-15 03:12:28,702 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-09-15 03:12:28,702 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 8542 msecs
2019-09-15 03:12:28,910 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-09-15 03:12:28,922 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-15 03:12:28,933 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-09-15 03:12:29,193 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:5000 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-09-15 03:12:29,242 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-09-15 03:12:29,273 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON. 
The reported blocks 0 needs additional 4 blocks to reach the threshold 0.9990 of total blocks 5.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-09-15 03:12:29,321 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-09-15 03:12:29,332 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-09-15 03:12:29,355 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/192.168.122.148:8020
2019-09-15 03:12:29,367 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1376 - Starting services required for standby state
2019-09-15 03:12:29,376 INFO  ha.EditLogTailer EditLogTailer.java:<init>:186 - Will roll logs on active node every 120 seconds.
2019-09-15 03:12:29,380 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-09-15 03:12:30,252 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.153:9866, datanodeUuid=ae59bdb9-f4b3-4594-8b68-f5b4155c47f4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage ae59bdb9-f4b3-4594-8b68-f5b4155c47f4
2019-09-15 03:12:30,254 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.153:9866
2019-09-15 03:12:30,254 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN ae59bdb9-f4b3-4594-8b68-f5b4155c47f4 (192.168.122.153:9866).
2019-09-15 03:12:30,392 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.31:9866, datanodeUuid=a3ddaf29-9834-4263-9360-432a183b4f7e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage a3ddaf29-9834-4263-9360-432a183b4f7e
2019-09-15 03:12:30,392 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.31:9866
2019-09-15 03:12:30,392 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN a3ddaf29-9834-4263-9360-432a183b4f7e (192.168.122.31:9866).
2019-09-15 03:12:30,394 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.50:9866, datanodeUuid=85236b5e-74cc-44f1-b732-9d8965e2a42d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage 85236b5e-74cc-44f1-b732-9d8965e2a42d
2019-09-15 03:12:30,394 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.50:9866
2019-09-15 03:12:30,395 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 85236b5e-74cc-44f1-b732-9d8965e2a42d (192.168.122.50:9866).
2019-09-15 03:12:30,395 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.235:9866, datanodeUuid=95f66c0e-6699-4f0f-b589-cdf63382f5b9, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage 95f66c0e-6699-4f0f-b589-cdf63382f5b9
2019-09-15 03:12:30,395 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.235:9866
2019-09-15 03:12:30,396 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 95f66c0e-6699-4f0f-b589-cdf63382f5b9 (192.168.122.235:9866).
2019-09-15 03:12:30,476 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-7030c263-fd6e-445c-add8-a45a5e96f152 for DN 192.168.122.31:9866
2019-09-15 03:12:30,479 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 for DN 192.168.122.153:9866
2019-09-15 03:12:30,485 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 for DN 192.168.122.50:9866
2019-09-15 03:12:30,486 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 for DN 192.168.122.235:9866
2019-09-15 03:12:30,564 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x3428b37a8cc35f3d: Processing first storage report for DS-7030c263-fd6e-445c-add8-a45a5e96f152 from datanode a3ddaf29-9834-4263-9360-432a183b4f7e
2019-09-15 03:12:30,568 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode extension entered. 
The reported blocks 4 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 30 seconds.
2019-09-15 03:12:30,568 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x3428b37a8cc35f3d: from storage DS-7030c263-fd6e-445c-add8-a45a5e96f152 node DatanodeRegistration(192.168.122.31:9866, datanodeUuid=a3ddaf29-9834-4263-9360-432a183b4f7e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 4, hasStaleStorage: false, processing time: 5 msecs, invalidatedBlocks: 0
2019-09-15 03:12:30,568 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xb37ade95722ae36: Processing first storage report for DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 from datanode 85236b5e-74cc-44f1-b732-9d8965e2a42d
2019-09-15 03:12:30,568 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xb37ade95722ae36: from storage DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 node DatanodeRegistration(192.168.122.50:9866, datanodeUuid=85236b5e-74cc-44f1-b732-9d8965e2a42d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 03:12:30,569 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x9b648ac6a928fb28: Processing first storage report for DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 from datanode ae59bdb9-f4b3-4594-8b68-f5b4155c47f4
2019-09-15 03:12:30,569 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x9b648ac6a928fb28: from storage DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 node DatanodeRegistration(192.168.122.153:9866, datanodeUuid=ae59bdb9-f4b3-4594-8b68-f5b4155c47f4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 5, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 03:12:30,580 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x12830b960ddd0897: Processing first storage report for DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 from datanode 95f66c0e-6699-4f0f-b589-cdf63382f5b9
2019-09-15 03:12:30,580 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x12830b960ddd0897: from storage DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 node DatanodeRegistration(192.168.122.235:9866, datanodeUuid=95f66c0e-6699-4f0f-b589-cdf63382f5b9, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 03:12:30,853 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1419 - Stopping services started for standby state
2019-09-15 03:12:30,855 WARN  ha.EditLogTailer EditLogTailer.java:doWork:471 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2019-09-15 03:12:30,964 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Starting services required for active state
2019-09-15 03:12:30,981 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:442 - Starting recovery process for unclosed journal segments...
2019-09-15 03:12:31,180 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:444 - Successfully started new epoch 4
2019-09-15 03:12:31,180 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:284 - Beginning recovery of unclosed segment starting at txid 68
2019-09-15 03:12:31,235 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:293 - Recovery prepare phase complete. Responses:
192.168.122.50:8485: segmentState { startTxId: 68 endTxId: 103 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 102
192.168.122.31:8485: segmentState { startTxId: 68 endTxId: 103 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 102
2019-09-15 03:12:31,239 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:317 - Using longest log: 192.168.122.50:8485=segmentState {
  startTxId: 68
  endTxId: 103
  isInProgress: true
}
lastWriterEpoch: 3
lastCommittedTxId: 102

2019-09-15 03:12:31,389 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-09-15 03:12:31,416 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000068 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000068-0000000000000000103
2019-09-15 03:12:31,439 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1225 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-09-15 03:12:31,448 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3d79622d expecting start txid #68
2019-09-15 03:12:31,448 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000068-0000000000000000103, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:12:31,448 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream '/tmp/hadoop-root/dfs/name/current/edits_0000000000000000068-0000000000000000103' to transaction ID 68
2019-09-15 03:12:31,459 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000068-0000000000000000103, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 36 loaded in 0 seconds
2019-09-15 03:12:31,460 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1840 - Marking all datanodes as stale
2019-09-15 03:12:31,461 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1247 - Will take over writing edit logs at txnid 104
2019-09-15 03:12:31,467 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 104
2019-09-15 03:12:32,053 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:769 - Initializing quota with 4 thread(s)
2019-09-15 03:12:32,058 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:778 - Quota initialization completed in 5 milliseconds
name space=6
storage space=2013265920
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-09-15 03:12:32,067 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-09-15 03:12:51,071 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON, in safe mode extension. 
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-09-15 03:12:58,581 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42906
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:12:58,581 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42908
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:12:58,618 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42908
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:12:58,636 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42906
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:12:59,316 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42912
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:12:59,326 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42916
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:12:59,334 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42912
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:12:59,339 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42916
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:12:59,433 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42920
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:12:59,445 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42920
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:12:59,576 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42906
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:13:00,030 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42908
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:13:00,151 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42912
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:13:00,473 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42920
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:13:00,545 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:42916
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:13:01,074 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4792 - initializing replication queues
2019-09-15 03:13:01,074 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:391 - STATE* Safe mode is OFF
2019-09-15 03:13:01,075 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 31 secs
2019-09-15 03:13:01,075 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 1 racks and 4 datanodes
2019-09-15 03:13:01,075 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-09-15 03:13:01,091 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3475 - Total number of blocks            = 5
2019-09-15 03:13:01,091 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3476 - Number of invalid blocks          = 0
2019-09-15 03:13:01,093 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3477 - Number of under-replicated blocks = 0
2019-09-15 03:13:01,093 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3478 - Number of  over-replicated blocks = 0
2019-09-15 03:13:01,093 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3480 - Number of blocks being written    = 0
2019-09-15 03:13:01,094 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3483 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 19 msec
2019-09-15 03:13:01,620 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741840_1016, replicas=192.168.122.153:9866, 192.168.122.235:9866, 192.168.122.31:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 03:13:01,867 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741841_1017, replicas=192.168.122.235:9866, 192.168.122.153:9866, 192.168.122.31:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 03:13:02,550 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741842_1018, replicas=192.168.122.235:9866, 192.168.122.50:9866, 192.168.122.31:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 03:13:03,096 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741843_1019, replicas=192.168.122.235:9866, 192.168.122.31:9866, 192.168.122.153:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 03:13:03,638 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_553180830_1
2019-09-15 03:13:03,882 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1894300487_1
2019-09-15 03:13:04,349 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1251ms to send a batch of 3 edits (117 bytes) to remote journal 192.168.122.31:8485
2019-09-15 03:13:04,350 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1251ms to send a batch of 3 edits (117 bytes) to remote journal 192.168.122.235:8485
2019-09-15 03:13:07,711 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3347ms to send a batch of 3 edits (443 bytes) to remote journal 192.168.122.235:8485
2019-09-15 03:13:07,990 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3628ms to send a batch of 3 edits (443 bytes) to remote journal 192.168.122.31:8485
2019-09-15 03:13:08,317 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-580814059_1
2019-09-15 03:13:10,800 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741844_1020, replicas=192.168.122.153:9866, 192.168.122.50:9866, 192.168.122.31:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 03:13:11,079 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1725655704_1
2019-09-15 03:13:14,570 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3854ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.50:8485
2019-09-15 03:13:14,939 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4223ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.235:8485
2019-09-15 03:13:15,928 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5213ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.31:8485
2019-09-15 03:13:18,021 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2092ms to send a batch of 6 edits (443 bytes) to remote journal 192.168.122.31:8485
2019-09-15 03:13:18,216 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2294ms to send a batch of 6 edits (443 bytes) to remote journal 192.168.122.50:8485
2019-09-15 03:13:19,177 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_901066732_1
2019-09-15 03:13:26,020 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 32 Total time for transactions(ms): 16 Number of transactions batched in Syncs: 116 Number of syncs: 18 SyncTimes(ms): 11422 4417 
2019-09-15 03:13:45,062 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741845_1021, replicas=192.168.122.153:9866, 192.168.122.235:9866, 192.168.122.50:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 03:13:45,895 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741846_1022, replicas=192.168.122.31:9866, 192.168.122.50:9866, 192.168.122.235:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 03:13:45,898 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741847_1023, replicas=192.168.122.50:9866, 192.168.122.31:9866, 192.168.122.153:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 03:13:46,641 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741848_1024, replicas=192.168.122.153:9866, 192.168.122.235:9866, 192.168.122.50:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 03:13:46,984 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741849_1025, replicas=192.168.122.50:9866, 192.168.122.153:9866, 192.168.122.235:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 03:13:48,589 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-743900033_1
2019-09-15 03:13:51,409 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2819ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.50:8485
2019-09-15 03:13:53,365 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4775ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.235:8485
2019-09-15 03:14:03,404 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_485524793_1
2019-09-15 03:14:03,405 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1542331888_1
2019-09-15 03:14:03,423 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-332560533_1
2019-09-15 03:14:03,854 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1774516832_1
2019-09-15 03:14:49,675 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-09-15 03:14:49,678 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-1-link-0/192.168.122.148
************************************************************/
2019-09-15 03:15:03,291 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-1-link-0/192.168.122.148
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/etc/hadoop:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-kms-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-07-19T04:04Z
STARTUP_MSG:   java = 1.8.0_212
************************************************************/
2019-09-15 03:15:03,301 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-15 03:15:03,402 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-09-15 03:15:03,592 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-09-15 03:15:03,625 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-09-15 03:15:03,753 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-09-15 03:15:03,753 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-09-15 03:15:03,828 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-09-15 03:15:03,828 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-09-15 03:15:03,963 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-09-15 03:15:03,983 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-09-15 03:15:03,996 INFO  util.log Log.java:initialized:192 - Logging initialized @1219ms
2019-09-15 03:15:04,133 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-15 03:15:04,147 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-09-15 03:15:04,159 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:970 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-15 03:15:04,161 INFO  http.HttpServer2 HttpServer2.java:addFilter:943 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-09-15 03:15:04,163 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-15 03:15:04,163 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-15 03:15:04,186 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-09-15 03:15:04,186 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:789 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-09-15 03:15:04,194 INFO  http.HttpServer2 HttpServer2.java:bindListener:1186 - Jetty bound to port 9870
2019-09-15 03:15:04,195 INFO  server.Server Server.java:doStart:351 - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T13:11:56-04:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-15 03:15:04,238 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@66982506{/logs,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/logs/,AVAILABLE}
2019-09-15 03:15:04,239 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@5a59ca5e{/static,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-09-15 03:15:04,314 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@15f47664{/,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-09-15 03:15:04,320 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@56dc1551{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-09-15 03:15:04,320 INFO  server.Server Server.java:doStart:419 - Started @1544ms
2019-09-15 03:15:04,558 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-09-15 03:15:04,679 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-09-15 03:15:04,694 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-09-15 03:15:04,696 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:121 - fsLock is fair: true
2019-09-15 03:15:04,697 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:139 - Detailed lock hold time metrics enabled: false
2019-09-15 03:15:04,705 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-09-15 03:15:04,705 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-09-15 03:15:04,705 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-09-15 03:15:04,706 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-09-15 03:15:04,706 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-09-15 03:15:04,741 INFO  common.Util Util.java:isDiskStatsEnabled:394 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-15 03:15:04,751 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-09-15 03:15:04,751 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-15 03:15:04,755 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-15 03:15:04,755 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Sep 15 03:15:04
2019-09-15 03:15:04,757 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-09-15 03:15:04,757 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:15:04,758 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 444.5 MB = 8.9 MB
2019-09-15 03:15:04,758 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-09-15 03:15:04,767 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-09-15 03:15:04,778 INFO  Configuration.deprecation Configuration.java:logDeprecation:1394 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-09-15 03:15:04,779 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-15 03:15:04,779 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-09-15 03:15:04,779 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-09-15 03:15:04,779 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-09-15 03:15:04,779 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-09-15 03:15:04,779 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-09-15 03:15:04,779 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-09-15 03:15:04,779 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-09-15 03:15:04,779 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-09-15 03:15:04,779 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-09-15 03:15:04,808 INFO  namenode.FSDirectory SerialNumberManager.java:initialize:77 - GLOBAL serial map: bits=24 maxEntries=16777215
2019-09-15 03:15:04,822 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-09-15 03:15:04,822 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:15:04,823 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 444.5 MB = 4.4 MB
2019-09-15 03:15:04,823 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^19 = 524288 entries
2019-09-15 03:15:04,826 INFO  namenode.FSDirectory FSDirectory.java:<init>:285 - ACLs enabled? false
2019-09-15 03:15:04,826 INFO  namenode.FSDirectory FSDirectory.java:<init>:289 - POSIX ACL inheritance enabled? true
2019-09-15 03:15:04,826 INFO  namenode.FSDirectory FSDirectory.java:<init>:293 - XAttrs enabled? true
2019-09-15 03:15:04,826 INFO  namenode.NameNode FSDirectory.java:<init>:357 - Caching file names occurring more than 10 times
2019-09-15 03:15:04,831 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-09-15 03:15:04,835 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-09-15 03:15:04,839 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-09-15 03:15:04,839 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:15:04,839 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 444.5 MB = 1.1 MB
2019-09-15 03:15:04,840 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^17 = 131072 entries
2019-09-15 03:15:04,846 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-15 03:15:04,846 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-09-15 03:15:04,846 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-15 03:15:04,850 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:990 - Retry cache on namenode is enabled
2019-09-15 03:15:04,850 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:998 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-09-15 03:15:04,852 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-09-15 03:15:04,852 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:15:04,853 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 444.5 MB = 136.5 KB
2019-09-15 03:15:04,853 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^14 = 16384 entries
2019-09-15 03:15:04,917 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 5057@node-1-link-0
2019-09-15 03:15:06,279 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:06,280 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:06,280 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:07,281 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:07,282 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:07,282 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:08,283 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:08,284 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:08,287 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:09,285 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:09,286 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:09,288 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:10,287 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:10,287 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:10,290 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:11,130 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 03:15:11,288 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:11,289 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:11,291 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:12,131 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 03:15:12,290 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:12,291 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:12,292 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:15:12,728 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-09-15 03:15:12,812 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:233 - Loading 1 INodes.
2019-09-15 03:15:12,841 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:183 - Loaded FSImage in 0 seconds.
2019-09-15 03:15:12,841 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-09-15 03:15:12,845 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@41dd05a expecting start txid #1
2019-09-15 03:15:12,845 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:15:12,849 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:15:12,849 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:15:13,132 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 31 loaded in 0 seconds
2019-09-15 03:15:13,132 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@613a8ee1 expecting start txid #32
2019-09-15 03:15:13,132 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:15:13,132 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:15:13,132 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:15:13,329 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 36 loaded in 0 seconds
2019-09-15 03:15:13,330 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@178213b expecting start txid #68
2019-09-15 03:15:13,330 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:15:13,330 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:15:13,330 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:15:13,349 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 36 loaded in 0 seconds
2019-09-15 03:15:13,349 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1102 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-09-15 03:15:13,349 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-09-15 03:15:13,350 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 8492 msecs
2019-09-15 03:15:13,558 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-09-15 03:15:13,562 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-15 03:15:13,586 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-09-15 03:15:13,875 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:5000 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-09-15 03:15:13,900 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-09-15 03:15:13,933 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON. 
The reported blocks 0 needs additional 4 blocks to reach the threshold 0.9990 of total blocks 5.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-09-15 03:15:13,989 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-09-15 03:15:13,997 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-09-15 03:15:14,063 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/192.168.122.148:8020
2019-09-15 03:15:14,079 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1376 - Starting services required for standby state
2019-09-15 03:15:14,092 INFO  ha.EditLogTailer EditLogTailer.java:<init>:186 - Will roll logs on active node every 120 seconds.
2019-09-15 03:15:14,116 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-09-15 03:15:15,361 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1419 - Stopping services started for standby state
2019-09-15 03:15:15,364 WARN  ha.EditLogTailer EditLogTailer.java:doWork:471 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2019-09-15 03:15:15,472 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Starting services required for active state
2019-09-15 03:15:15,498 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:442 - Starting recovery process for unclosed journal segments...
2019-09-15 03:15:15,719 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:444 - Successfully started new epoch 5
2019-09-15 03:15:15,720 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:284 - Beginning recovery of unclosed segment starting at txid 104
2019-09-15 03:15:15,800 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:293 - Recovery prepare phase complete. Responses:
192.168.122.31:8485: segmentState { startTxId: 104 endTxId: 174 isInProgress: true } lastWriterEpoch: 4 lastCommittedTxId: 173
192.168.122.50:8485: segmentState { startTxId: 104 endTxId: 174 isInProgress: true } lastWriterEpoch: 4 lastCommittedTxId: 173
2019-09-15 03:15:15,804 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:317 - Using longest log: 192.168.122.31:8485=segmentState {
  startTxId: 104
  endTxId: 174
  isInProgress: true
}
lastWriterEpoch: 4
lastCommittedTxId: 173

2019-09-15 03:15:15,955 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-09-15 03:15:15,985 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000104 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000104-0000000000000000174
2019-09-15 03:15:16,016 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1225 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-09-15 03:15:16,025 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@500be1fc expecting start txid #104
2019-09-15 03:15:16,025 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000104-0000000000000000174, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=104&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=104&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:15:16,025 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream '/tmp/hadoop-root/dfs/name/current/edits_0000000000000000104-0000000000000000174' to transaction ID 104
2019-09-15 03:15:16,055 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000104-0000000000000000174, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=104&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=104&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 71 loaded in 0 seconds
2019-09-15 03:15:16,056 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1840 - Marking all datanodes as stale
2019-09-15 03:15:16,057 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1247 - Will take over writing edit logs at txnid 175
2019-09-15 03:15:16,063 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 175
2019-09-15 03:15:16,704 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:769 - Initializing quota with 4 thread(s)
2019-09-15 03:15:16,712 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:778 - Quota initialization completed in 7 milliseconds
name space=6
storage space=2013265920
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-09-15 03:15:16,719 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.235:9866, datanodeUuid=95f66c0e-6699-4f0f-b589-cdf63382f5b9, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage 95f66c0e-6699-4f0f-b589-cdf63382f5b9
2019-09-15 03:15:16,723 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.235:9866
2019-09-15 03:15:16,724 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 95f66c0e-6699-4f0f-b589-cdf63382f5b9 (192.168.122.235:9866).
2019-09-15 03:15:16,720 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-09-15 03:15:16,729 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.153:9866, datanodeUuid=ae59bdb9-f4b3-4594-8b68-f5b4155c47f4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage ae59bdb9-f4b3-4594-8b68-f5b4155c47f4
2019-09-15 03:15:16,729 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.153:9866
2019-09-15 03:15:16,729 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN ae59bdb9-f4b3-4594-8b68-f5b4155c47f4 (192.168.122.153:9866).
2019-09-15 03:15:16,730 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.50:9866, datanodeUuid=85236b5e-74cc-44f1-b732-9d8965e2a42d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage 85236b5e-74cc-44f1-b732-9d8965e2a42d
2019-09-15 03:15:16,730 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.50:9866
2019-09-15 03:15:16,731 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 85236b5e-74cc-44f1-b732-9d8965e2a42d (192.168.122.50:9866).
2019-09-15 03:15:16,732 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.31:9866, datanodeUuid=a3ddaf29-9834-4263-9360-432a183b4f7e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage a3ddaf29-9834-4263-9360-432a183b4f7e
2019-09-15 03:15:16,732 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.31:9866
2019-09-15 03:15:16,733 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN a3ddaf29-9834-4263-9360-432a183b4f7e (192.168.122.31:9866).
2019-09-15 03:15:16,795 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 for DN 192.168.122.235:9866
2019-09-15 03:15:16,800 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 for DN 192.168.122.50:9866
2019-09-15 03:15:16,802 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-7030c263-fd6e-445c-add8-a45a5e96f152 for DN 192.168.122.31:9866
2019-09-15 03:15:16,806 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 for DN 192.168.122.153:9866
2019-09-15 03:15:16,836 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x2bbe24597e6c1d58: Processing first storage report for DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 from datanode ae59bdb9-f4b3-4594-8b68-f5b4155c47f4
2019-09-15 03:15:16,841 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode extension entered. 
The reported blocks 4 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2019-09-15 03:15:16,841 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x2bbe24597e6c1d58: from storage DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 node DatanodeRegistration(192.168.122.153:9866, datanodeUuid=ae59bdb9-f4b3-4594-8b68-f5b4155c47f4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 5, hasStaleStorage: false, processing time: 5 msecs, invalidatedBlocks: 0
2019-09-15 03:15:16,842 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xad664ce37b94f209: Processing first storage report for DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 from datanode 85236b5e-74cc-44f1-b732-9d8965e2a42d
2019-09-15 03:15:16,842 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xad664ce37b94f209: from storage DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 node DatanodeRegistration(192.168.122.50:9866, datanodeUuid=85236b5e-74cc-44f1-b732-9d8965e2a42d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 3, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-09-15 03:15:16,842 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xe565a40767fd3b8d: Processing first storage report for DS-7030c263-fd6e-445c-add8-a45a5e96f152 from datanode a3ddaf29-9834-4263-9360-432a183b4f7e
2019-09-15 03:15:16,843 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xe565a40767fd3b8d: from storage DS-7030c263-fd6e-445c-add8-a45a5e96f152 node DatanodeRegistration(192.168.122.31:9866, datanodeUuid=a3ddaf29-9834-4263-9360-432a183b4f7e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 4, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 03:15:16,843 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x50aacd25098889f4: Processing first storage report for DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 from datanode 95f66c0e-6699-4f0f-b589-cdf63382f5b9
2019-09-15 03:15:16,844 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x50aacd25098889f4: from storage DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 node DatanodeRegistration(192.168.122.235:9866, datanodeUuid=95f66c0e-6699-4f0f-b589-cdf63382f5b9, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 3, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-09-15 03:15:36,846 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON, in safe mode extension. 
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-09-15 03:15:43,174 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43114
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 3 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 3 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:43,199 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43114
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 3 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 3 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:43,751 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43118
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 3 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 3 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:43,805 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43118
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 3 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 3 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:44,002 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43122
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:44,015 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43122
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:44,104 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43126
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:44,124 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43126
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:44,201 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43130
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:44,214 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43130
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:44,507 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43114
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:44,518 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43118
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:44,620 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43122
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:44,629 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43126
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:44,795 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43130
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:45,700 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43118
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:45,818 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43114
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:45,997 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43130
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:46,050 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43126
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:15:46,848 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4792 - initializing replication queues
2019-09-15 03:15:46,849 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:391 - STATE* Safe mode is OFF
2019-09-15 03:15:46,849 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 32 secs
2019-09-15 03:15:46,850 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 1 racks and 4 datanodes
2019-09-15 03:15:46,850 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-09-15 03:15:46,854 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3475 - Total number of blocks            = 5
2019-09-15 03:15:46,854 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3476 - Number of invalid blocks          = 0
2019-09-15 03:15:46,854 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3477 - Number of under-replicated blocks = 0
2019-09-15 03:15:46,854 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3478 - Number of  over-replicated blocks = 0
2019-09-15 03:15:46,854 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3480 - Number of blocks being written    = 0
2019-09-15 03:15:46,855 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3483 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2019-09-15 03:15:47,140 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741850_1026, replicas=192.168.122.31:9866, 192.168.122.50:9866, 192.168.122.153:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 03:15:48,453 INFO  namenode.FSNamesystem FSNamesystem.java:checkBlocksComplete:2908 - BLOCK* blk_1073741850_1026 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /myfile5.remotecopy._COPYING_
2019-09-15 03:15:48,533 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741851_1027, replicas=192.168.122.153:9866, 192.168.122.31:9866, 192.168.122.50:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 03:15:48,864 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1485974206_1
2019-09-15 03:15:49,747 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_289718267_1
2019-09-15 03:15:51,918 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2236ms to send a batch of 1 edits (187 bytes) to remote journal 192.168.122.31:8485
2019-09-15 03:15:52,965 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3284ms to send a batch of 1 edits (187 bytes) to remote journal 192.168.122.50:8485
2019-09-15 03:15:53,056 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741852_1028, replicas=192.168.122.153:9866, 192.168.122.235:9866, 192.168.122.31:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 03:15:53,221 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741853_1029, replicas=192.168.122.31:9866, 192.168.122.50:9866, 192.168.122.153:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 03:15:53,263 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741854_1030, replicas=192.168.122.31:9866, 192.168.122.235:9866, 192.168.122.50:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 03:15:55,415 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_456111574_1
2019-09-15 03:15:55,597 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1264497879_1
2019-09-15 03:15:55,673 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_659535263_1
2019-09-15 03:15:56,858 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1441ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.235:8485
2019-09-15 03:16:00,273 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4854ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.31:8485
2019-09-15 03:16:02,546 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 7129ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.50:8485
2019-09-15 03:16:08,535 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 30 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 185 Number of syncs: 15 SyncTimes(ms): 8260 9655 
2019-09-15 03:16:11,346 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2808ms to send a batch of 4 edits (392 bytes) to remote journal 192.168.122.31:8485
2019-09-15 03:16:11,398 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2861ms to send a batch of 4 edits (392 bytes) to remote journal 192.168.122.235:8485
2019-09-15 03:16:11,416 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2878ms to send a batch of 4 edits (392 bytes) to remote journal 192.168.122.50:8485
2019-09-15 03:16:29,754 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741855_1031, replicas=192.168.122.235:9866, 192.168.122.50:9866, 192.168.122.31:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 03:16:30,015 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741856_1032, replicas=192.168.122.50:9866, 192.168.122.153:9866, 192.168.122.235:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 03:16:31,894 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1695512915_1
2019-09-15 03:16:32,034 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1391308681_1
2019-09-15 03:16:34,637 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2742ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.235:8485
2019-09-15 03:16:34,639 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2743ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.50:8485
2019-09-15 03:16:42,704 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1464ms to send a batch of 1 edits (68 bytes) to remote journal 192.168.122.235:8485
2019-09-15 03:17:00,038 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-09-15 03:17:00,041 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-1-link-0/192.168.122.148
************************************************************/
2019-09-15 03:17:13,998 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-1-link-0/192.168.122.148
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/etc/hadoop:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-kms-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-07-19T04:04Z
STARTUP_MSG:   java = 1.8.0_212
************************************************************/
2019-09-15 03:17:14,007 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-15 03:17:14,106 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-09-15 03:17:14,279 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-09-15 03:17:14,317 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-09-15 03:17:14,443 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-09-15 03:17:14,443 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-09-15 03:17:14,522 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-09-15 03:17:14,523 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-09-15 03:17:14,673 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-09-15 03:17:14,693 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-09-15 03:17:14,706 INFO  util.log Log.java:initialized:192 - Logging initialized @1185ms
2019-09-15 03:17:14,802 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-15 03:17:14,812 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-09-15 03:17:14,821 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:970 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-15 03:17:14,823 INFO  http.HttpServer2 HttpServer2.java:addFilter:943 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-09-15 03:17:14,826 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-15 03:17:14,827 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-15 03:17:14,849 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-09-15 03:17:14,849 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:789 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-09-15 03:17:14,856 INFO  http.HttpServer2 HttpServer2.java:bindListener:1186 - Jetty bound to port 9870
2019-09-15 03:17:14,857 INFO  server.Server Server.java:doStart:351 - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T13:11:56-04:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-15 03:17:14,887 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@66982506{/logs,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/logs/,AVAILABLE}
2019-09-15 03:17:14,888 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@5a59ca5e{/static,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-09-15 03:17:14,942 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@15f47664{/,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-09-15 03:17:14,948 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@674c4669{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-09-15 03:17:14,948 INFO  server.Server Server.java:doStart:419 - Started @1427ms
2019-09-15 03:17:15,102 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-09-15 03:17:15,249 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-09-15 03:17:15,266 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-09-15 03:17:15,268 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:121 - fsLock is fair: true
2019-09-15 03:17:15,270 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:139 - Detailed lock hold time metrics enabled: false
2019-09-15 03:17:15,279 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-09-15 03:17:15,279 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-09-15 03:17:15,279 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-09-15 03:17:15,280 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-09-15 03:17:15,281 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-09-15 03:17:15,324 INFO  common.Util Util.java:isDiskStatsEnabled:394 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-15 03:17:15,334 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-09-15 03:17:15,334 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-15 03:17:15,338 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-15 03:17:15,338 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Sep 15 03:17:15
2019-09-15 03:17:15,340 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-09-15 03:17:15,340 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:17:15,341 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 444.5 MB = 8.9 MB
2019-09-15 03:17:15,341 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-09-15 03:17:15,349 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-09-15 03:17:15,361 INFO  Configuration.deprecation Configuration.java:logDeprecation:1394 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-09-15 03:17:15,361 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-15 03:17:15,361 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-09-15 03:17:15,361 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-09-15 03:17:15,361 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-09-15 03:17:15,361 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-09-15 03:17:15,361 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-09-15 03:17:15,361 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-09-15 03:17:15,362 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-09-15 03:17:15,362 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-09-15 03:17:15,362 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-09-15 03:17:15,386 INFO  namenode.FSDirectory SerialNumberManager.java:initialize:77 - GLOBAL serial map: bits=24 maxEntries=16777215
2019-09-15 03:17:15,399 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-09-15 03:17:15,400 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:17:15,400 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 444.5 MB = 4.4 MB
2019-09-15 03:17:15,400 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^19 = 524288 entries
2019-09-15 03:17:15,401 INFO  namenode.FSDirectory FSDirectory.java:<init>:285 - ACLs enabled? false
2019-09-15 03:17:15,401 INFO  namenode.FSDirectory FSDirectory.java:<init>:289 - POSIX ACL inheritance enabled? true
2019-09-15 03:17:15,401 INFO  namenode.FSDirectory FSDirectory.java:<init>:293 - XAttrs enabled? true
2019-09-15 03:17:15,401 INFO  namenode.NameNode FSDirectory.java:<init>:357 - Caching file names occurring more than 10 times
2019-09-15 03:17:15,405 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-09-15 03:17:15,407 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-09-15 03:17:15,411 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-09-15 03:17:15,411 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:17:15,412 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 444.5 MB = 1.1 MB
2019-09-15 03:17:15,412 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^17 = 131072 entries
2019-09-15 03:17:15,419 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-15 03:17:15,419 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-09-15 03:17:15,419 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-15 03:17:15,423 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:990 - Retry cache on namenode is enabled
2019-09-15 03:17:15,423 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:998 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-09-15 03:17:15,425 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-09-15 03:17:15,425 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 03:17:15,425 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 444.5 MB = 136.5 KB
2019-09-15 03:17:15,425 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^14 = 16384 entries
2019-09-15 03:17:15,457 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 5523@node-1-link-0
2019-09-15 03:17:16,714 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:16,715 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:16,716 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:17,717 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:17,718 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:17,719 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:18,719 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:18,720 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:18,721 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:19,721 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:19,722 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:19,722 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:20,723 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:20,724 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:20,723 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:21,576 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 03:17:21,725 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:21,725 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:21,726 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:22,577 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 03:17:22,726 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.235:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:22,727 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.31:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:22,727 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.50:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 03:17:23,427 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-09-15 03:17:23,535 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:233 - Loading 1 INodes.
2019-09-15 03:17:23,564 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:183 - Loaded FSImage in 0 seconds.
2019-09-15 03:17:23,565 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-09-15 03:17:23,569 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@67c2e933 expecting start txid #1
2019-09-15 03:17:23,569 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:17:23,573 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:17:23,573 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:17:23,825 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 31 loaded in 0 seconds
2019-09-15 03:17:23,825 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@41dd05a expecting start txid #32
2019-09-15 03:17:23,825 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:17:23,825 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:17:23,825 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:17:23,856 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 36 loaded in 0 seconds
2019-09-15 03:17:23,856 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@613a8ee1 expecting start txid #68
2019-09-15 03:17:23,856 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:17:23,857 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:17:23,858 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:17:24,014 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=68&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 36 loaded in 0 seconds
2019-09-15 03:17:24,014 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@178213b expecting start txid #104
2019-09-15 03:17:24,014 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=104&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=104&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:17:24,015 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=104&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=104&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:17:24,017 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=104&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true' to transaction ID 1
2019-09-15 03:17:24,043 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=104&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=104&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 71 loaded in 0 seconds
2019-09-15 03:17:24,044 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1102 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-09-15 03:17:24,044 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-09-15 03:17:24,044 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 8617 msecs
2019-09-15 03:17:24,298 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-09-15 03:17:24,303 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-15 03:17:24,313 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-09-15 03:17:24,583 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:5000 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-09-15 03:17:24,603 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-09-15 03:17:24,619 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON. 
The reported blocks 0 needs additional 4 blocks to reach the threshold 0.9990 of total blocks 5.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-09-15 03:17:24,670 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-09-15 03:17:24,677 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/192.168.122.148:8020
2019-09-15 03:17:24,679 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-09-15 03:17:24,697 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1376 - Starting services required for standby state
2019-09-15 03:17:24,701 INFO  ha.EditLogTailer EditLogTailer.java:<init>:186 - Will roll logs on active node every 120 seconds.
2019-09-15 03:17:24,726 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-09-15 03:17:25,692 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.31:9866, datanodeUuid=a3ddaf29-9834-4263-9360-432a183b4f7e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage a3ddaf29-9834-4263-9360-432a183b4f7e
2019-09-15 03:17:25,693 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.31:9866
2019-09-15 03:17:25,694 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN a3ddaf29-9834-4263-9360-432a183b4f7e (192.168.122.31:9866).
2019-09-15 03:17:25,703 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.50:9866, datanodeUuid=85236b5e-74cc-44f1-b732-9d8965e2a42d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage 85236b5e-74cc-44f1-b732-9d8965e2a42d
2019-09-15 03:17:25,704 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.50:9866
2019-09-15 03:17:25,704 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 85236b5e-74cc-44f1-b732-9d8965e2a42d (192.168.122.50:9866).
2019-09-15 03:17:25,705 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.153:9866, datanodeUuid=ae59bdb9-f4b3-4594-8b68-f5b4155c47f4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage ae59bdb9-f4b3-4594-8b68-f5b4155c47f4
2019-09-15 03:17:25,705 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.153:9866
2019-09-15 03:17:25,705 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN ae59bdb9-f4b3-4594-8b68-f5b4155c47f4 (192.168.122.153:9866).
2019-09-15 03:17:25,707 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.235:9866, datanodeUuid=95f66c0e-6699-4f0f-b589-cdf63382f5b9, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941) storage 95f66c0e-6699-4f0f-b589-cdf63382f5b9
2019-09-15 03:17:25,707 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.235:9866
2019-09-15 03:17:25,707 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 95f66c0e-6699-4f0f-b589-cdf63382f5b9 (192.168.122.235:9866).
2019-09-15 03:17:25,813 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 for DN 192.168.122.153:9866
2019-09-15 03:17:25,816 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-7030c263-fd6e-445c-add8-a45a5e96f152 for DN 192.168.122.31:9866
2019-09-15 03:17:25,818 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 for DN 192.168.122.235:9866
2019-09-15 03:17:25,818 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 for DN 192.168.122.50:9866
2019-09-15 03:17:25,875 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x83b544f6faaad9f2: Processing first storage report for DS-7030c263-fd6e-445c-add8-a45a5e96f152 from datanode a3ddaf29-9834-4263-9360-432a183b4f7e
2019-09-15 03:17:25,883 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode extension entered. 
The reported blocks 4 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2019-09-15 03:17:25,884 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x83b544f6faaad9f2: from storage DS-7030c263-fd6e-445c-add8-a45a5e96f152 node DatanodeRegistration(192.168.122.31:9866, datanodeUuid=a3ddaf29-9834-4263-9360-432a183b4f7e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 4, hasStaleStorage: false, processing time: 12 msecs, invalidatedBlocks: 0
2019-09-15 03:17:25,886 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x53dbb7d6b8b46951: Processing first storage report for DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 from datanode ae59bdb9-f4b3-4594-8b68-f5b4155c47f4
2019-09-15 03:17:25,886 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x53dbb7d6b8b46951: from storage DS-6be3da8c-2b40-458b-8a01-b09f7b835e43 node DatanodeRegistration(192.168.122.153:9866, datanodeUuid=ae59bdb9-f4b3-4594-8b68-f5b4155c47f4, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 5, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-09-15 03:17:25,887 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xf2f52a5b1ac11d2f: Processing first storage report for DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 from datanode 95f66c0e-6699-4f0f-b589-cdf63382f5b9
2019-09-15 03:17:25,887 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xf2f52a5b1ac11d2f: from storage DS-0eb24377-26e3-45b5-afa0-0b76510ef4a2 node DatanodeRegistration(192.168.122.235:9866, datanodeUuid=95f66c0e-6699-4f0f-b589-cdf63382f5b9, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 03:17:25,887 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x263823f9fd3e6f75: Processing first storage report for DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 from datanode 85236b5e-74cc-44f1-b732-9d8965e2a42d
2019-09-15 03:17:25,887 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x263823f9fd3e6f75: from storage DS-378b42c4-25f3-48bb-b2b0-46b0a0e502b5 node DatanodeRegistration(192.168.122.50:9866, datanodeUuid=85236b5e-74cc-44f1-b732-9d8965e2a42d, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-944c971e-156c-42a4-9030-e3ee72b20f68;nsid=1470756460;c=1568531172941), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 03:17:26,014 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1419 - Stopping services started for standby state
2019-09-15 03:17:26,016 WARN  ha.EditLogTailer EditLogTailer.java:doWork:471 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2019-09-15 03:17:26,127 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Starting services required for active state
2019-09-15 03:17:26,155 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:442 - Starting recovery process for unclosed journal segments...
2019-09-15 03:17:26,381 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:444 - Successfully started new epoch 6
2019-09-15 03:17:26,382 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:284 - Beginning recovery of unclosed segment starting at txid 175
2019-09-15 03:17:26,440 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:293 - Recovery prepare phase complete. Responses:
192.168.122.50:8485: segmentState { startTxId: 175 endTxId: 224 isInProgress: true } lastWriterEpoch: 5 lastCommittedTxId: 223
192.168.122.235:8485: segmentState { startTxId: 175 endTxId: 224 isInProgress: true } lastWriterEpoch: 5 lastCommittedTxId: 223
2019-09-15 03:17:26,444 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:317 - Using longest log: 192.168.122.50:8485=segmentState {
  startTxId: 175
  endTxId: 224
  isInProgress: true
}
lastWriterEpoch: 5
lastCommittedTxId: 223

2019-09-15 03:17:26,611 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-09-15 03:17:26,636 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000175 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000175-0000000000000000224
2019-09-15 03:17:26,662 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1225 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-09-15 03:17:26,673 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@72e4e7c5 expecting start txid #175
2019-09-15 03:17:26,673 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000175-0000000000000000224, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=175&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=175&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 03:17:26,673 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream '/tmp/hadoop-root/dfs/name/current/edits_0000000000000000175-0000000000000000224' to transaction ID 175
2019-09-15 03:17:26,687 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000175-0000000000000000224, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=175&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=175&storageInfo=-64%3A1470756460%3A1568531172941%3ACID-944c971e-156c-42a4-9030-e3ee72b20f68&inProgressOk=true of size 1048576 edits # 50 loaded in 0 seconds
2019-09-15 03:17:26,687 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1840 - Marking all datanodes as stale
2019-09-15 03:17:26,688 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1247 - Will take over writing edit logs at txnid 225
2019-09-15 03:17:26,699 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 225
2019-09-15 03:17:27,239 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:769 - Initializing quota with 4 thread(s)
2019-09-15 03:17:27,245 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:778 - Quota initialization completed in 5 milliseconds
name space=6
storage space=2013265920
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-09-15 03:17:27,254 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-09-15 03:17:46,257 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON, in safe mode extension. 
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-09-15 03:17:53,654 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43274
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:53,678 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43274
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:53,705 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43272
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:53,738 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43272
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:54,127 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43278
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:54,171 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43278
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:54,350 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43284
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:54,363 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43284
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:54,442 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43286
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:54,471 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43286
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:54,625 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43274
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:54,735 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43272
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:54,900 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43284
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:55,375 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43278
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:55,832 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43274
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:55,887 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.227:43286
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 03:17:56,433 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4792 - initializing replication queues
2019-09-15 03:17:56,434 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:391 - STATE* Safe mode is OFF
2019-09-15 03:17:56,434 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 31 secs
2019-09-15 03:17:56,434 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 1 racks and 4 datanodes
2019-09-15 03:17:56,434 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-09-15 03:17:56,439 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3475 - Total number of blocks            = 5
2019-09-15 03:17:56,439 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3476 - Number of invalid blocks          = 0
2019-09-15 03:17:56,439 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3477 - Number of under-replicated blocks = 0
2019-09-15 03:17:56,439 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3478 - Number of  over-replicated blocks = 0
2019-09-15 03:17:56,439 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3480 - Number of blocks being written    = 0
2019-09-15 03:17:56,443 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3483 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2019-09-15 03:17:57,488 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741857_1033, replicas=192.168.122.31:9866, 192.168.122.50:9866, 192.168.122.153:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 03:17:57,709 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741858_1034, replicas=192.168.122.153:9866, 192.168.122.50:9866, 192.168.122.235:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 03:17:57,816 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741859_1035, replicas=192.168.122.31:9866, 192.168.122.153:9866, 192.168.122.235:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 03:17:58,611 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741860_1036, replicas=192.168.122.50:9866, 192.168.122.31:9866, 192.168.122.153:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 03:17:58,955 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741861_1037, replicas=192.168.122.153:9866, 192.168.122.31:9866, 192.168.122.235:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 03:18:00,004 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1578777056_1
2019-09-15 03:18:00,309 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1259908963_1
2019-09-15 03:18:00,497 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_168814703_1
2019-09-15 03:18:03,712 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3709ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.31:8485
2019-09-15 03:18:04,005 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-501775360_1
2019-09-15 03:18:04,029 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4026ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.50:8485
2019-09-15 03:18:04,208 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4205ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.235:8485
2019-09-15 03:18:04,316 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1931412426_1
2019-09-15 03:18:17,400 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 26 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 232 Number of syncs: 14 SyncTimes(ms): 4420 13615 
