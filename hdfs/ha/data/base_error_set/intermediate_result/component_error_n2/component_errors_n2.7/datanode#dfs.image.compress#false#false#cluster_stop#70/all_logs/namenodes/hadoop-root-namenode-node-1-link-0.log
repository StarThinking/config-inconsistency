2019-09-15 04:26:44,820 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-1-link-0/192.168.122.155
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/etc/hadoop:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-kms-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-07-19T04:04Z
STARTUP_MSG:   java = 1.8.0_212
************************************************************/
2019-09-15 04:26:44,830 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-15 04:26:44,943 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-09-15 04:26:45,117 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-09-15 04:26:45,152 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-09-15 04:26:45,246 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-09-15 04:26:45,247 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-09-15 04:26:45,301 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-09-15 04:26:45,301 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-09-15 04:26:45,464 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-09-15 04:26:45,483 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-09-15 04:26:45,495 INFO  util.log Log.java:initialized:192 - Logging initialized @1266ms
2019-09-15 04:26:45,583 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-15 04:26:45,595 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-09-15 04:26:45,604 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:970 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-15 04:26:45,606 INFO  http.HttpServer2 HttpServer2.java:addFilter:943 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-09-15 04:26:45,607 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-15 04:26:45,607 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-15 04:26:45,630 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-09-15 04:26:45,630 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:789 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-09-15 04:26:45,637 INFO  http.HttpServer2 HttpServer2.java:bindListener:1186 - Jetty bound to port 9870
2019-09-15 04:26:45,639 INFO  server.Server Server.java:doStart:351 - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T13:11:56-04:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-15 04:26:45,673 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@66982506{/logs,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/logs/,AVAILABLE}
2019-09-15 04:26:45,679 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@5a59ca5e{/static,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-09-15 04:26:45,758 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@15f47664{/,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-09-15 04:26:45,763 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@56dc1551{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-09-15 04:26:45,764 INFO  server.Server Server.java:doStart:419 - Started @1534ms
2019-09-15 04:26:46,008 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-09-15 04:26:46,105 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-09-15 04:26:46,116 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-09-15 04:26:46,118 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:121 - fsLock is fair: true
2019-09-15 04:26:46,119 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:139 - Detailed lock hold time metrics enabled: false
2019-09-15 04:26:46,124 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-09-15 04:26:46,125 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-09-15 04:26:46,125 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-09-15 04:26:46,125 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-09-15 04:26:46,125 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-09-15 04:26:46,160 INFO  common.Util Util.java:isDiskStatsEnabled:394 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-15 04:26:46,170 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-09-15 04:26:46,170 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-15 04:26:46,174 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-15 04:26:46,174 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Sep 15 04:26:46
2019-09-15 04:26:46,176 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-09-15 04:26:46,176 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:26:46,177 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 444.5 MB = 8.9 MB
2019-09-15 04:26:46,178 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-09-15 04:26:46,185 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-09-15 04:26:46,192 INFO  Configuration.deprecation Configuration.java:logDeprecation:1394 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-09-15 04:26:46,192 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-15 04:26:46,192 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-09-15 04:26:46,192 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-09-15 04:26:46,192 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-09-15 04:26:46,193 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-09-15 04:26:46,193 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-09-15 04:26:46,193 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-09-15 04:26:46,193 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-09-15 04:26:46,193 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-09-15 04:26:46,193 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-09-15 04:26:46,217 INFO  namenode.FSDirectory SerialNumberManager.java:initialize:77 - GLOBAL serial map: bits=24 maxEntries=16777215
2019-09-15 04:26:46,232 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-09-15 04:26:46,232 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:26:46,233 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 444.5 MB = 4.4 MB
2019-09-15 04:26:46,233 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^19 = 524288 entries
2019-09-15 04:26:46,233 INFO  namenode.FSDirectory FSDirectory.java:<init>:285 - ACLs enabled? false
2019-09-15 04:26:46,234 INFO  namenode.FSDirectory FSDirectory.java:<init>:289 - POSIX ACL inheritance enabled? true
2019-09-15 04:26:46,234 INFO  namenode.FSDirectory FSDirectory.java:<init>:293 - XAttrs enabled? true
2019-09-15 04:26:46,234 INFO  namenode.NameNode FSDirectory.java:<init>:357 - Caching file names occurring more than 10 times
2019-09-15 04:26:46,239 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-09-15 04:26:46,241 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-09-15 04:26:46,245 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-09-15 04:26:46,245 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:26:46,246 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 444.5 MB = 1.1 MB
2019-09-15 04:26:46,246 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^17 = 131072 entries
2019-09-15 04:26:46,256 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-15 04:26:46,256 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-09-15 04:26:46,256 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-15 04:26:46,261 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:990 - Retry cache on namenode is enabled
2019-09-15 04:26:46,262 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:998 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-09-15 04:26:46,264 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-09-15 04:26:46,264 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:26:46,265 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 444.5 MB = 136.5 KB
2019-09-15 04:26:46,265 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^14 = 16384 entries
2019-09-15 04:26:46,314 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 18404@node-1-link-0
2019-09-15 04:26:47,680 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:47,680 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:47,681 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:48,682 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:48,683 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:48,685 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:49,684 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:49,684 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:49,686 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:50,685 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:50,686 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:50,687 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:51,687 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:51,688 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:51,690 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:52,509 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 04:26:52,690 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:52,691 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:52,691 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:53,510 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 04:26:53,692 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:53,693 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:53,693 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:26:54,323 INFO  namenode.FSImage FSImage.java:loadFSImage:718 - No edit log streams selected.
2019-09-15 04:26:54,324 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-09-15 04:26:54,402 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:233 - Loading 1 INodes.
2019-09-15 04:26:54,439 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:183 - Loaded FSImage in 0 seconds.
2019-09-15 04:26:54,439 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-09-15 04:26:54,445 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1102 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-09-15 04:26:54,445 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-09-15 04:26:54,446 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 8174 msecs
2019-09-15 04:26:54,625 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-09-15 04:26:54,630 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-15 04:26:54,653 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-09-15 04:26:54,890 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:5000 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-09-15 04:26:54,900 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-09-15 04:26:54,908 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 0 secs
2019-09-15 04:26:54,909 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 0 racks and 0 datanodes
2019-09-15 04:26:54,909 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-09-15 04:26:54,963 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-09-15 04:26:54,965 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-09-15 04:26:54,968 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/192.168.122.155:8020
2019-09-15 04:26:54,971 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1376 - Starting services required for standby state
2019-09-15 04:26:54,987 INFO  ha.EditLogTailer EditLogTailer.java:<init>:186 - Will roll logs on active node every 120 seconds.
2019-09-15 04:26:55,004 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-09-15 04:26:55,886 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.197:9866, datanodeUuid=905c77ce-7769-42b2-9169-4d4cc646f9f6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 905c77ce-7769-42b2-9169-4d4cc646f9f6
2019-09-15 04:26:55,888 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.197:9866
2019-09-15 04:26:55,888 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 905c77ce-7769-42b2-9169-4d4cc646f9f6 (192.168.122.197:9866).
2019-09-15 04:26:56,037 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-55f9ef08-2468-44be-b707-26a7a258468a for DN 192.168.122.197:9866
2019-09-15 04:26:56,071 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xb217f963ffbae68b: Processing first storage report for DS-55f9ef08-2468-44be-b707-26a7a258468a from datanode 905c77ce-7769-42b2-9169-4d4cc646f9f6
2019-09-15 04:26:56,073 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xb217f963ffbae68b: from storage DS-55f9ef08-2468-44be-b707-26a7a258468a node DatanodeRegistration(192.168.122.197:9866, datanodeUuid=905c77ce-7769-42b2-9169-4d4cc646f9f6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-09-15 04:26:56,111 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.137:9866, datanodeUuid=41b206c5-4657-4aaa-815b-adf68b525caf, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 41b206c5-4657-4aaa-815b-adf68b525caf
2019-09-15 04:26:56,111 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.137:9866
2019-09-15 04:26:56,111 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 41b206c5-4657-4aaa-815b-adf68b525caf (192.168.122.137:9866).
2019-09-15 04:26:56,169 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa for DN 192.168.122.137:9866
2019-09-15 04:26:56,203 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xfb2dba12b0e27f7a: Processing first storage report for DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa from datanode 41b206c5-4657-4aaa-815b-adf68b525caf
2019-09-15 04:26:56,203 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xfb2dba12b0e27f7a: from storage DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa node DatanodeRegistration(192.168.122.137:9866, datanodeUuid=41b206c5-4657-4aaa-815b-adf68b525caf, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-09-15 04:26:56,286 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.8:9866, datanodeUuid=89f24cb4-5f0d-4659-bf19-dada3b6dcfc8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8
2019-09-15 04:26:56,287 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.8:9866
2019-09-15 04:26:56,287 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8 (192.168.122.8:9866).
2019-09-15 04:26:56,347 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-9a499255-1089-4fd8-9d09-1328babba9f4 for DN 192.168.122.8:9866
2019-09-15 04:26:56,367 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.82:9866, datanodeUuid=7f51c406-ca97-43fe-bde5-99f4814db4d0, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 7f51c406-ca97-43fe-bde5-99f4814db4d0
2019-09-15 04:26:56,367 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.82:9866
2019-09-15 04:26:56,367 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 7f51c406-ca97-43fe-bde5-99f4814db4d0 (192.168.122.82:9866).
2019-09-15 04:26:56,390 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xa79681a843737d5f: Processing first storage report for DS-9a499255-1089-4fd8-9d09-1328babba9f4 from datanode 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8
2019-09-15 04:26:56,390 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xa79681a843737d5f: from storage DS-9a499255-1089-4fd8-9d09-1328babba9f4 node DatanodeRegistration(192.168.122.8:9866, datanodeUuid=89f24cb4-5f0d-4659-bf19-dada3b6dcfc8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-09-15 04:26:56,435 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb for DN 192.168.122.82:9866
2019-09-15 04:26:56,599 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xec694cce731db6d9: Processing first storage report for DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb from datanode 7f51c406-ca97-43fe-bde5-99f4814db4d0
2019-09-15 04:26:56,599 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xec694cce731db6d9: from storage DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb node DatanodeRegistration(192.168.122.82:9866, datanodeUuid=7f51c406-ca97-43fe-bde5-99f4814db4d0, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-09-15 04:26:56,731 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1419 - Stopping services started for standby state
2019-09-15 04:26:56,732 WARN  ha.EditLogTailer EditLogTailer.java:doWork:471 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2019-09-15 04:26:56,846 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Starting services required for active state
2019-09-15 04:26:56,853 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:442 - Starting recovery process for unclosed journal segments...
2019-09-15 04:26:57,056 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:444 - Successfully started new epoch 1
2019-09-15 04:26:57,057 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-09-15 04:26:57,057 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1225 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-09-15 04:26:57,072 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1840 - Marking all datanodes as stale
2019-09-15 04:26:57,076 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1236 - Reprocessing replication and invalidation queues
2019-09-15 04:26:57,076 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4792 - initializing replication queues
2019-09-15 04:26:57,077 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1247 - Will take over writing edit logs at txnid 1
2019-09-15 04:26:57,101 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 1
2019-09-15 04:26:57,732 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:769 - Initializing quota with 4 thread(s)
2019-09-15 04:26:57,741 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:778 - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-09-15 04:26:57,753 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3475 - Total number of blocks            = 0
2019-09-15 04:26:57,753 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3476 - Number of invalid blocks          = 0
2019-09-15 04:26:57,754 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3477 - Number of under-replicated blocks = 0
2019-09-15 04:26:57,754 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3478 - Number of  over-replicated blocks = 0
2019-09-15 04:26:57,754 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3480 - Number of blocks being written    = 0
2019-09-15 04:26:57,754 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3483 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 677 msec
2019-09-15 04:26:57,757 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-09-15 04:27:05,424 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741825_1001, replicas=192.168.122.8:9866, 192.168.122.137:9866, 192.168.122.197:9866 for /myfile1._COPYING_
2019-09-15 04:27:07,161 INFO  namenode.FSNamesystem FSNamesystem.java:checkBlocksComplete:2908 - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /myfile1._COPYING_
2019-09-15 04:27:07,578 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-526334571_1
2019-09-15 04:27:12,321 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741826_1002, replicas=192.168.122.8:9866, 192.168.122.82:9866, 192.168.122.137:9866 for /myfile2._COPYING_
2019-09-15 04:27:13,591 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_1137439204_1
2019-09-15 04:27:14,885 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1292ms to send a batch of 1 edits (117 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:27:20,528 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1437ms to send a batch of 1 edits (177 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:27:20,528 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1437ms to send a batch of 1 edits (177 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:27:20,833 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741827_1003, replicas=192.168.122.137:9866, 192.168.122.82:9866, 192.168.122.8:9866 for /myfile3._COPYING_
2019-09-15 04:27:23,058 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3._COPYING_ is closed by DFSClient_NONMAPREDUCE_-929326383_1
2019-09-15 04:27:24,297 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1238ms to send a batch of 1 edits (117 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:27:29,452 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741828_1004, replicas=192.168.122.137:9866, 192.168.122.82:9866, 192.168.122.8:9866 for /myfile4._COPYING_
2019-09-15 04:27:30,646 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1682019047_1
2019-09-15 04:27:31,922 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1275ms to send a batch of 1 edits (117 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:27:38,090 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2297ms to send a batch of 1 edits (178 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:27:38,091 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2297ms to send a batch of 1 edits (178 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:27:39,252 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3458ms to send a batch of 1 edits (178 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:27:39,367 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741829_1005, replicas=192.168.122.82:9866, 192.168.122.137:9866, 192.168.122.197:9866 for /myfile5._COPYING_
2019-09-15 04:27:40,429 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1900666661_1
2019-09-15 04:27:41,622 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1192ms to send a batch of 1 edits (117 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:27:45,705 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-09-15 04:27:45,707 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-1-link-0/192.168.122.155
************************************************************/
2019-09-15 04:27:58,722 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-1-link-0/192.168.122.155
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/etc/hadoop:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-kms-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-07-19T04:04Z
STARTUP_MSG:   java = 1.8.0_212
************************************************************/
2019-09-15 04:27:58,731 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-15 04:27:58,846 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-09-15 04:27:59,028 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-09-15 04:27:59,067 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-09-15 04:27:59,195 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-09-15 04:27:59,195 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-09-15 04:27:59,245 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-09-15 04:27:59,245 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-09-15 04:27:59,375 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-09-15 04:27:59,399 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-09-15 04:27:59,415 INFO  util.log Log.java:initialized:192 - Logging initialized @1195ms
2019-09-15 04:27:59,517 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-15 04:27:59,534 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-09-15 04:27:59,549 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:970 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-15 04:27:59,553 INFO  http.HttpServer2 HttpServer2.java:addFilter:943 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-09-15 04:27:59,555 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-15 04:27:59,555 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-15 04:27:59,590 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-09-15 04:27:59,590 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:789 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-09-15 04:27:59,601 INFO  http.HttpServer2 HttpServer2.java:bindListener:1186 - Jetty bound to port 9870
2019-09-15 04:27:59,602 INFO  server.Server Server.java:doStart:351 - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T13:11:56-04:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-15 04:27:59,650 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@66982506{/logs,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/logs/,AVAILABLE}
2019-09-15 04:27:59,650 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@5a59ca5e{/static,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-09-15 04:27:59,725 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@15f47664{/,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-09-15 04:27:59,731 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@45902e7d{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-09-15 04:27:59,731 INFO  server.Server Server.java:doStart:419 - Started @1511ms
2019-09-15 04:27:59,948 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-09-15 04:28:00,067 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-09-15 04:28:00,078 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-09-15 04:28:00,080 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:121 - fsLock is fair: true
2019-09-15 04:28:00,081 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:139 - Detailed lock hold time metrics enabled: false
2019-09-15 04:28:00,087 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-09-15 04:28:00,087 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-09-15 04:28:00,087 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-09-15 04:28:00,087 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-09-15 04:28:00,087 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-09-15 04:28:00,122 INFO  common.Util Util.java:isDiskStatsEnabled:394 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-15 04:28:00,132 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-09-15 04:28:00,132 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-15 04:28:00,136 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-15 04:28:00,136 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Sep 15 04:28:00
2019-09-15 04:28:00,138 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-09-15 04:28:00,138 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:28:00,140 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 444.5 MB = 8.9 MB
2019-09-15 04:28:00,140 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-09-15 04:28:00,147 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-09-15 04:28:00,154 INFO  Configuration.deprecation Configuration.java:logDeprecation:1394 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-09-15 04:28:00,155 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-15 04:28:00,155 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-09-15 04:28:00,155 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-09-15 04:28:00,155 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-09-15 04:28:00,155 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-09-15 04:28:00,155 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-09-15 04:28:00,155 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-09-15 04:28:00,155 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-09-15 04:28:00,155 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-09-15 04:28:00,155 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-09-15 04:28:00,180 INFO  namenode.FSDirectory SerialNumberManager.java:initialize:77 - GLOBAL serial map: bits=24 maxEntries=16777215
2019-09-15 04:28:00,194 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-09-15 04:28:00,194 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:28:00,194 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 444.5 MB = 4.4 MB
2019-09-15 04:28:00,194 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^19 = 524288 entries
2019-09-15 04:28:00,195 INFO  namenode.FSDirectory FSDirectory.java:<init>:285 - ACLs enabled? false
2019-09-15 04:28:00,195 INFO  namenode.FSDirectory FSDirectory.java:<init>:289 - POSIX ACL inheritance enabled? true
2019-09-15 04:28:00,195 INFO  namenode.FSDirectory FSDirectory.java:<init>:293 - XAttrs enabled? true
2019-09-15 04:28:00,195 INFO  namenode.NameNode FSDirectory.java:<init>:357 - Caching file names occurring more than 10 times
2019-09-15 04:28:00,200 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-09-15 04:28:00,202 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-09-15 04:28:00,206 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-09-15 04:28:00,206 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:28:00,206 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 444.5 MB = 1.1 MB
2019-09-15 04:28:00,206 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^17 = 131072 entries
2019-09-15 04:28:00,214 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-15 04:28:00,214 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-09-15 04:28:00,214 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-15 04:28:00,218 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:990 - Retry cache on namenode is enabled
2019-09-15 04:28:00,218 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:998 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-09-15 04:28:00,220 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-09-15 04:28:00,220 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:28:00,220 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 444.5 MB = 136.5 KB
2019-09-15 04:28:00,220 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^14 = 16384 entries
2019-09-15 04:28:00,266 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 18866@node-1-link-0
2019-09-15 04:28:01,540 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:01,540 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:01,541 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:02,542 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:02,542 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:02,543 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:03,544 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:03,545 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:03,546 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:04,546 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:04,546 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:04,547 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:05,547 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:05,548 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:05,548 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:06,395 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 04:28:06,549 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:06,550 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:06,550 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:07,396 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 04:28:07,550 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:07,551 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:07,552 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:28:08,217 INFO  namenode.FSImage FSImage.java:loadFSImage:718 - No edit log streams selected.
2019-09-15 04:28:08,218 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-09-15 04:28:08,283 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:233 - Loading 1 INodes.
2019-09-15 04:28:08,317 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:183 - Loaded FSImage in 0 seconds.
2019-09-15 04:28:08,317 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-09-15 04:28:08,322 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1102 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-09-15 04:28:08,322 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-09-15 04:28:08,322 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 8099 msecs
2019-09-15 04:28:08,487 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-09-15 04:28:08,494 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-15 04:28:08,507 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-09-15 04:28:08,783 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:5000 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-09-15 04:28:08,794 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-09-15 04:28:08,826 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 0 secs
2019-09-15 04:28:08,827 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 0 racks and 0 datanodes
2019-09-15 04:28:08,827 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-09-15 04:28:08,886 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-09-15 04:28:08,888 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-09-15 04:28:08,895 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/192.168.122.155:8020
2019-09-15 04:28:08,898 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1376 - Starting services required for standby state
2019-09-15 04:28:08,950 INFO  ha.EditLogTailer EditLogTailer.java:<init>:186 - Will roll logs on active node every 120 seconds.
2019-09-15 04:28:08,960 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-09-15 04:28:09,625 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.8:9866, datanodeUuid=89f24cb4-5f0d-4659-bf19-dada3b6dcfc8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8
2019-09-15 04:28:09,627 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.8:9866
2019-09-15 04:28:09,627 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8 (192.168.122.8:9866).
2019-09-15 04:28:09,704 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.82:9866, datanodeUuid=7f51c406-ca97-43fe-bde5-99f4814db4d0, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 7f51c406-ca97-43fe-bde5-99f4814db4d0
2019-09-15 04:28:09,704 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.82:9866
2019-09-15 04:28:09,704 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 7f51c406-ca97-43fe-bde5-99f4814db4d0 (192.168.122.82:9866).
2019-09-15 04:28:09,757 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-9a499255-1089-4fd8-9d09-1328babba9f4 for DN 192.168.122.8:9866
2019-09-15 04:28:09,769 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb for DN 192.168.122.82:9866
2019-09-15 04:28:09,811 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xb96794666a36bc66: Processing first storage report for DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb from datanode 7f51c406-ca97-43fe-bde5-99f4814db4d0
2019-09-15 04:28:09,813 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xb96794666a36bc66: from storage DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb node DatanodeRegistration(192.168.122.82:9866, datanodeUuid=7f51c406-ca97-43fe-bde5-99f4814db4d0, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 4, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-09-15 04:28:09,821 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x46604a4b10b82c30: Processing first storage report for DS-9a499255-1089-4fd8-9d09-1328babba9f4 from datanode 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8
2019-09-15 04:28:09,821 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x46604a4b10b82c30: from storage DS-9a499255-1089-4fd8-9d09-1328babba9f4 node DatanodeRegistration(192.168.122.8:9866, datanodeUuid=89f24cb4-5f0d-4659-bf19-dada3b6dcfc8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 4, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 04:28:09,906 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.197:9866, datanodeUuid=905c77ce-7769-42b2-9169-4d4cc646f9f6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 905c77ce-7769-42b2-9169-4d4cc646f9f6
2019-09-15 04:28:09,906 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.197:9866
2019-09-15 04:28:09,907 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 905c77ce-7769-42b2-9169-4d4cc646f9f6 (192.168.122.197:9866).
2019-09-15 04:28:09,936 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.137:9866, datanodeUuid=41b206c5-4657-4aaa-815b-adf68b525caf, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 41b206c5-4657-4aaa-815b-adf68b525caf
2019-09-15 04:28:09,937 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.137:9866
2019-09-15 04:28:09,937 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 41b206c5-4657-4aaa-815b-adf68b525caf (192.168.122.137:9866).
2019-09-15 04:28:09,969 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-55f9ef08-2468-44be-b707-26a7a258468a for DN 192.168.122.197:9866
2019-09-15 04:28:10,000 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa for DN 192.168.122.137:9866
2019-09-15 04:28:10,001 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xa7880ed830d912e1: Processing first storage report for DS-55f9ef08-2468-44be-b707-26a7a258468a from datanode 905c77ce-7769-42b2-9169-4d4cc646f9f6
2019-09-15 04:28:10,001 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xa7880ed830d912e1: from storage DS-55f9ef08-2468-44be-b707-26a7a258468a node DatanodeRegistration(192.168.122.197:9866, datanodeUuid=905c77ce-7769-42b2-9169-4d4cc646f9f6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 04:28:10,043 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xb279e7a959ee86d3: Processing first storage report for DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa from datanode 41b206c5-4657-4aaa-815b-adf68b525caf
2019-09-15 04:28:10,044 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xb279e7a959ee86d3: from storage DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa node DatanodeRegistration(192.168.122.137:9866, datanodeUuid=41b206c5-4657-4aaa-815b-adf68b525caf, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 5, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 04:28:10,544 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1419 - Stopping services started for standby state
2019-09-15 04:28:10,545 WARN  ha.EditLogTailer EditLogTailer.java:doWork:471 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2019-09-15 04:28:10,650 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Starting services required for active state
2019-09-15 04:28:10,672 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:442 - Starting recovery process for unclosed journal segments...
2019-09-15 04:28:12,144 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:444 - Successfully started new epoch 2
2019-09-15 04:28:12,144 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:284 - Beginning recovery of unclosed segment starting at txid 1
2019-09-15 04:28:12,190 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:293 - Recovery prepare phase complete. Responses:
192.168.122.137:8485: segmentState { startTxId: 1 endTxId: 31 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 30
192.168.122.197:8485: segmentState { startTxId: 1 endTxId: 31 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 30
2019-09-15 04:28:12,194 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:317 - Using longest log: 192.168.122.137:8485=segmentState {
  startTxId: 1
  endTxId: 31
  isInProgress: true
}
lastWriterEpoch: 1
lastCommittedTxId: 30

2019-09-15 04:28:12,353 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-09-15 04:28:12,394 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000001 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000001-0000000000000000031
2019-09-15 04:28:12,417 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1225 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-09-15 04:28:12,439 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4a984feb expecting start txid #1
2019-09-15 04:28:12,439 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000001-0000000000000000031, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:28:12,442 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream '/tmp/hadoop-root/dfs/name/current/edits_0000000000000000001-0000000000000000031' to transaction ID 1
2019-09-15 04:28:12,509 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000001-0000000000000000031, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 31 loaded in 0 seconds
2019-09-15 04:28:12,509 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1840 - Marking all datanodes as stale
2019-09-15 04:28:12,514 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1236 - Reprocessing replication and invalidation queues
2019-09-15 04:28:12,515 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4792 - initializing replication queues
2019-09-15 04:28:12,515 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1247 - Will take over writing edit logs at txnid 32
2019-09-15 04:28:12,523 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 32
2019-09-15 04:28:13,028 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:769 - Initializing quota with 4 thread(s)
2019-09-15 04:28:13,032 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:778 - Quota initialization completed in 3 milliseconds
name space=6
storage space=2013265920
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-09-15 04:28:13,048 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-09-15 04:28:13,056 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3475 - Total number of blocks            = 5
2019-09-15 04:28:13,056 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3476 - Number of invalid blocks          = 0
2019-09-15 04:28:13,057 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3477 - Number of under-replicated blocks = 0
2019-09-15 04:28:13,057 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3478 - Number of  over-replicated blocks = 0
2019-09-15 04:28:13,057 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3480 - Number of blocks being written    = 0
2019-09-15 04:28:13,057 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3483 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 542 msec
2019-09-15 04:28:46,061 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741830_1006, replicas=192.168.122.8:9866, 192.168.122.137:9866, 192.168.122.82:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 04:28:46,183 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741831_1007, replicas=192.168.122.137:9866, 192.168.122.197:9866, 192.168.122.8:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 04:28:46,351 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741832_1008, replicas=192.168.122.82:9866, 192.168.122.8:9866, 192.168.122.137:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 04:28:46,738 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741833_1009, replicas=192.168.122.197:9866, 192.168.122.137:9866, 192.168.122.8:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 04:28:47,575 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741834_1010, replicas=192.168.122.8:9866, 192.168.122.137:9866, 192.168.122.82:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 04:28:49,851 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1366244209_1
2019-09-15 04:28:55,851 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for sendEdits. No responses yet.
2019-09-15 04:28:56,851 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for sendEdits. No responses yet.
2019-09-15 04:28:57,853 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 8004 ms (timeout=20000 ms) for a response for sendEdits. No responses yet.
2019-09-15 04:28:58,855 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 9005 ms (timeout=20000 ms) for a response for sendEdits. No responses yet.
2019-09-15 04:28:59,558 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 9708ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:28:59,562 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 9713ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:29:01,739 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-703837651_1
2019-09-15 04:29:04,023 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 14173ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:29:04,023 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 23 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 39 Number of syncs: 14 SyncTimes(ms): 10156 4669 
2019-09-15 04:29:04,194 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_427530998_1
2019-09-15 04:29:04,247 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_2071245719_1
2019-09-15 04:29:04,319 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1970926020_1
2019-09-15 04:29:34,552 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1589ms to send a batch of 1 edits (187 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:29:34,552 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1590ms to send a batch of 1 edits (187 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:29:34,552 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1589ms to send a batch of 1 edits (187 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:29:34,713 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741835_1011, replicas=192.168.122.197:9866, 192.168.122.8:9866, 192.168.122.82:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 04:29:35,590 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741836_1012, replicas=192.168.122.137:9866, 192.168.122.82:9866, 192.168.122.197:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 04:29:35,698 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741837_1013, replicas=192.168.122.8:9866, 192.168.122.82:9866, 192.168.122.137:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 04:29:35,700 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741838_1014, replicas=192.168.122.8:9866, 192.168.122.197:9866, 192.168.122.82:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 04:29:35,720 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741839_1015, replicas=192.168.122.137:9866, 192.168.122.8:9866, 192.168.122.82:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 04:29:39,205 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1682469040_1
2019-09-15 04:29:39,400 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1601961907_1
2019-09-15 04:29:39,539 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-608217279_1
2019-09-15 04:29:43,329 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4123ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:29:45,206 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.197:8485]
2019-09-15 04:29:50,128 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 10921ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:29:50,137 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_801098835_1
2019-09-15 04:29:50,170 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_965058822_1
2019-09-15 04:29:54,925 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 15718ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:30:08,464 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 67 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 62 Number of syncs: 35 SyncTimes(ms): 24434 11267 
2019-09-15 04:30:38,600 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-09-15 04:30:38,603 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-1-link-0/192.168.122.155
************************************************************/
2019-09-15 04:30:51,885 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-1-link-0/192.168.122.155
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/etc/hadoop:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-kms-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-07-19T04:04Z
STARTUP_MSG:   java = 1.8.0_212
************************************************************/
2019-09-15 04:30:51,897 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-15 04:30:52,010 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-09-15 04:30:52,220 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-09-15 04:30:52,253 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-09-15 04:30:52,385 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-09-15 04:30:52,386 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-09-15 04:30:52,471 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-09-15 04:30:52,472 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-09-15 04:30:52,625 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-09-15 04:30:52,650 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-09-15 04:30:52,667 INFO  util.log Log.java:initialized:192 - Logging initialized @1469ms
2019-09-15 04:30:52,806 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-15 04:30:52,818 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-09-15 04:30:52,830 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:970 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-15 04:30:52,833 INFO  http.HttpServer2 HttpServer2.java:addFilter:943 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-09-15 04:30:52,837 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-15 04:30:52,837 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-15 04:30:52,872 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-09-15 04:30:52,872 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:789 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-09-15 04:30:52,884 INFO  http.HttpServer2 HttpServer2.java:bindListener:1186 - Jetty bound to port 9870
2019-09-15 04:30:52,885 INFO  server.Server Server.java:doStart:351 - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T13:11:56-04:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-15 04:30:52,923 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@66982506{/logs,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/logs/,AVAILABLE}
2019-09-15 04:30:52,924 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@5a59ca5e{/static,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-09-15 04:30:52,999 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@15f47664{/,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-09-15 04:30:53,006 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@674c4669{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-09-15 04:30:53,007 INFO  server.Server Server.java:doStart:419 - Started @1808ms
2019-09-15 04:30:53,228 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-09-15 04:30:53,353 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-09-15 04:30:53,364 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-09-15 04:30:53,366 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:121 - fsLock is fair: true
2019-09-15 04:30:53,367 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:139 - Detailed lock hold time metrics enabled: false
2019-09-15 04:30:53,373 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-09-15 04:30:53,373 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-09-15 04:30:53,374 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-09-15 04:30:53,374 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-09-15 04:30:53,374 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-09-15 04:30:53,408 INFO  common.Util Util.java:isDiskStatsEnabled:394 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-15 04:30:53,418 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-09-15 04:30:53,419 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-15 04:30:53,422 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-15 04:30:53,423 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Sep 15 04:30:53
2019-09-15 04:30:53,424 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-09-15 04:30:53,425 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:30:53,426 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 444.5 MB = 8.9 MB
2019-09-15 04:30:53,426 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-09-15 04:30:53,434 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-09-15 04:30:53,446 INFO  Configuration.deprecation Configuration.java:logDeprecation:1394 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-09-15 04:30:53,446 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-15 04:30:53,446 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-09-15 04:30:53,446 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-09-15 04:30:53,446 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-09-15 04:30:53,446 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-09-15 04:30:53,446 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-09-15 04:30:53,446 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-09-15 04:30:53,447 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-09-15 04:30:53,447 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-09-15 04:30:53,447 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-09-15 04:30:53,481 INFO  namenode.FSDirectory SerialNumberManager.java:initialize:77 - GLOBAL serial map: bits=24 maxEntries=16777215
2019-09-15 04:30:53,498 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-09-15 04:30:53,498 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:30:53,498 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 444.5 MB = 4.4 MB
2019-09-15 04:30:53,499 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^19 = 524288 entries
2019-09-15 04:30:53,499 INFO  namenode.FSDirectory FSDirectory.java:<init>:285 - ACLs enabled? false
2019-09-15 04:30:53,501 INFO  namenode.FSDirectory FSDirectory.java:<init>:289 - POSIX ACL inheritance enabled? true
2019-09-15 04:30:53,501 INFO  namenode.FSDirectory FSDirectory.java:<init>:293 - XAttrs enabled? true
2019-09-15 04:30:53,501 INFO  namenode.NameNode FSDirectory.java:<init>:357 - Caching file names occurring more than 10 times
2019-09-15 04:30:53,508 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-09-15 04:30:53,510 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-09-15 04:30:53,516 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-09-15 04:30:53,516 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:30:53,516 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 444.5 MB = 1.1 MB
2019-09-15 04:30:53,516 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^17 = 131072 entries
2019-09-15 04:30:53,527 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-15 04:30:53,528 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-09-15 04:30:53,528 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-15 04:30:53,537 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:990 - Retry cache on namenode is enabled
2019-09-15 04:30:53,537 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:998 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-09-15 04:30:53,541 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-09-15 04:30:53,541 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:30:53,541 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 444.5 MB = 136.5 KB
2019-09-15 04:30:53,541 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^14 = 16384 entries
2019-09-15 04:30:53,728 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 19331@node-1-link-0
2019-09-15 04:30:55,129 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:55,129 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:55,130 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:56,130 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:56,131 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:56,133 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:57,131 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:57,132 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:57,134 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:58,133 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:58,133 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:58,136 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:59,134 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:59,134 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:59,136 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:30:59,929 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 04:31:00,135 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:31:00,136 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:31:00,138 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:31:00,824 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-09-15 04:31:00,899 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:233 - Loading 1 INodes.
2019-09-15 04:31:00,925 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:183 - Loaded FSImage in 0 seconds.
2019-09-15 04:31:00,925 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-09-15 04:31:00,929 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@67c2e933 expecting start txid #1
2019-09-15 04:31:00,929 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:31:00,933 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:31:00,933 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:31:01,177 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 31 loaded in 0 seconds
2019-09-15 04:31:01,178 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1102 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-09-15 04:31:01,178 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-09-15 04:31:01,178 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 7630 msecs
2019-09-15 04:31:01,387 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-09-15 04:31:01,391 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-15 04:31:01,402 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-09-15 04:31:01,568 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:5000 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-09-15 04:31:01,581 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-09-15 04:31:01,596 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON. 
The reported blocks 0 needs additional 4 blocks to reach the threshold 0.9990 of total blocks 5.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-09-15 04:31:01,829 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-09-15 04:31:01,830 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-09-15 04:31:01,861 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/192.168.122.155:8020
2019-09-15 04:31:01,864 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1376 - Starting services required for standby state
2019-09-15 04:31:01,868 INFO  ha.EditLogTailer EditLogTailer.java:<init>:186 - Will roll logs on active node every 120 seconds.
2019-09-15 04:31:01,885 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-09-15 04:31:02,746 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.197:9866, datanodeUuid=905c77ce-7769-42b2-9169-4d4cc646f9f6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 905c77ce-7769-42b2-9169-4d4cc646f9f6
2019-09-15 04:31:02,747 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.197:9866
2019-09-15 04:31:02,754 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 905c77ce-7769-42b2-9169-4d4cc646f9f6 (192.168.122.197:9866).
2019-09-15 04:31:02,756 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.137:9866, datanodeUuid=41b206c5-4657-4aaa-815b-adf68b525caf, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 41b206c5-4657-4aaa-815b-adf68b525caf
2019-09-15 04:31:02,756 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.137:9866
2019-09-15 04:31:02,756 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 41b206c5-4657-4aaa-815b-adf68b525caf (192.168.122.137:9866).
2019-09-15 04:31:02,757 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.82:9866, datanodeUuid=7f51c406-ca97-43fe-bde5-99f4814db4d0, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 7f51c406-ca97-43fe-bde5-99f4814db4d0
2019-09-15 04:31:02,757 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.82:9866
2019-09-15 04:31:02,758 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 7f51c406-ca97-43fe-bde5-99f4814db4d0 (192.168.122.82:9866).
2019-09-15 04:31:02,878 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa for DN 192.168.122.137:9866
2019-09-15 04:31:02,881 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-55f9ef08-2468-44be-b707-26a7a258468a for DN 192.168.122.197:9866
2019-09-15 04:31:02,884 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb for DN 192.168.122.82:9866
2019-09-15 04:31:02,963 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xc2f1638fec58e4cd: Processing first storage report for DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa from datanode 41b206c5-4657-4aaa-815b-adf68b525caf
2019-09-15 04:31:02,975 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode extension entered. 
The reported blocks 4 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2019-09-15 04:31:02,975 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xc2f1638fec58e4cd: from storage DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa node DatanodeRegistration(192.168.122.137:9866, datanodeUuid=41b206c5-4657-4aaa-815b-adf68b525caf, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 5, hasStaleStorage: false, processing time: 13 msecs, invalidatedBlocks: 0
2019-09-15 04:31:02,981 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.8:9866, datanodeUuid=89f24cb4-5f0d-4659-bf19-dada3b6dcfc8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8
2019-09-15 04:31:02,981 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.8:9866
2019-09-15 04:31:02,982 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8 (192.168.122.8:9866).
2019-09-15 04:31:02,989 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x86a76c1aa245c36c: Processing first storage report for DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb from datanode 7f51c406-ca97-43fe-bde5-99f4814db4d0
2019-09-15 04:31:02,989 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x86a76c1aa245c36c: from storage DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb node DatanodeRegistration(192.168.122.82:9866, datanodeUuid=7f51c406-ca97-43fe-bde5-99f4814db4d0, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 4, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 04:31:02,997 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x6234a206ce70f252: Processing first storage report for DS-55f9ef08-2468-44be-b707-26a7a258468a from datanode 905c77ce-7769-42b2-9169-4d4cc646f9f6
2019-09-15 04:31:02,997 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x6234a206ce70f252: from storage DS-55f9ef08-2468-44be-b707-26a7a258468a node DatanodeRegistration(192.168.122.197:9866, datanodeUuid=905c77ce-7769-42b2-9169-4d4cc646f9f6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 04:31:03,032 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-9a499255-1089-4fd8-9d09-1328babba9f4 for DN 192.168.122.8:9866
2019-09-15 04:31:03,060 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x9a421430f20b7475: Processing first storage report for DS-9a499255-1089-4fd8-9d09-1328babba9f4 from datanode 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8
2019-09-15 04:31:03,060 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x9a421430f20b7475: from storage DS-9a499255-1089-4fd8-9d09-1328babba9f4 node DatanodeRegistration(192.168.122.8:9866, datanodeUuid=89f24cb4-5f0d-4659-bf19-dada3b6dcfc8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 4, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-09-15 04:31:03,524 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1419 - Stopping services started for standby state
2019-09-15 04:31:03,529 WARN  ha.EditLogTailer EditLogTailer.java:doWork:471 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2019-09-15 04:31:03,641 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Starting services required for active state
2019-09-15 04:31:03,656 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:442 - Starting recovery process for unclosed journal segments...
2019-09-15 04:31:03,887 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:444 - Successfully started new epoch 3
2019-09-15 04:31:03,888 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:284 - Beginning recovery of unclosed segment starting at txid 32
2019-09-15 04:31:03,959 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:293 - Recovery prepare phase complete. Responses:
192.168.122.197:8485: segmentState { startTxId: 32 endTxId: 102 isInProgress: true } lastWriterEpoch: 2 lastCommittedTxId: 101
192.168.122.82:8485: segmentState { startTxId: 32 endTxId: 102 isInProgress: true } lastWriterEpoch: 2 lastCommittedTxId: 101
2019-09-15 04:31:03,963 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:317 - Using longest log: 192.168.122.197:8485=segmentState {
  startTxId: 32
  endTxId: 102
  isInProgress: true
}
lastWriterEpoch: 2
lastCommittedTxId: 101

2019-09-15 04:31:04,123 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-09-15 04:31:04,151 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000032 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000032-0000000000000000102
2019-09-15 04:31:04,176 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1225 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-09-15 04:31:04,186 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5c0cf7c8 expecting start txid #32
2019-09-15 04:31:04,186 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000032-0000000000000000102, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:31:04,186 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream '/tmp/hadoop-root/dfs/name/current/edits_0000000000000000032-0000000000000000102' to transaction ID 32
2019-09-15 04:31:04,211 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000032-0000000000000000102, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 71 loaded in 0 seconds
2019-09-15 04:31:04,212 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1840 - Marking all datanodes as stale
2019-09-15 04:31:04,213 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1247 - Will take over writing edit logs at txnid 103
2019-09-15 04:31:04,217 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 103
2019-09-15 04:31:04,767 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:769 - Initializing quota with 4 thread(s)
2019-09-15 04:31:04,773 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:778 - Quota initialization completed in 6 milliseconds
name space=6
storage space=2013265920
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-09-15 04:31:04,784 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-09-15 04:31:23,785 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON, in safe mode extension. 
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-09-15 04:31:33,787 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4792 - initializing replication queues
2019-09-15 04:31:33,788 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:391 - STATE* Safe mode is OFF
2019-09-15 04:31:33,788 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 32 secs
2019-09-15 04:31:33,788 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 1 racks and 4 datanodes
2019-09-15 04:31:33,788 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-09-15 04:31:33,794 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3475 - Total number of blocks            = 5
2019-09-15 04:31:33,794 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3476 - Number of invalid blocks          = 0
2019-09-15 04:31:33,795 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3477 - Number of under-replicated blocks = 0
2019-09-15 04:31:33,795 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3478 - Number of  over-replicated blocks = 0
2019-09-15 04:31:33,795 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3480 - Number of blocks being written    = 0
2019-09-15 04:31:33,795 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3483 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2019-09-15 04:31:37,424 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741840_1016, replicas=192.168.122.137:9866, 192.168.122.8:9866, 192.168.122.82:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 04:31:38,443 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741841_1017, replicas=192.168.122.197:9866, 192.168.122.137:9866, 192.168.122.82:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 04:31:38,683 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741842_1018, replicas=192.168.122.137:9866, 192.168.122.8:9866, 192.168.122.197:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 04:31:38,779 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741843_1019, replicas=192.168.122.82:9866, 192.168.122.197:9866, 192.168.122.137:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 04:31:39,147 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741844_1020, replicas=192.168.122.137:9866, 192.168.122.8:9866, 192.168.122.82:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 04:31:40,419 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1435113117_1
2019-09-15 04:31:45,251 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4831ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:31:46,854 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6434ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:31:46,420 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.197:8485]
2019-09-15 04:31:55,735 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 23 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 109 Number of syncs: 15 SyncTimes(ms): 7319 8732 
2019-09-15 04:31:55,847 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1393129394_1
2019-09-15 04:31:55,864 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1777207451_1
2019-09-15 04:31:55,911 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1506240527_1
2019-09-15 04:31:56,017 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_742466881_1
2019-09-15 04:32:23,423 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741845_1021, replicas=192.168.122.137:9866, 192.168.122.197:9866, 192.168.122.8:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 04:32:24,546 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1121ms to send a batch of 3 edits (117 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:32:24,546 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1121ms to send a batch of 3 edits (117 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:32:24,549 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1125ms to send a batch of 3 edits (117 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:32:24,800 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741846_1022, replicas=192.168.122.82:9866, 192.168.122.8:9866, 192.168.122.137:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 04:32:25,898 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741847_1023, replicas=192.168.122.8:9866, 192.168.122.82:9866, 192.168.122.197:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 04:32:26,485 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741848_1024, replicas=192.168.122.82:9866, 192.168.122.197:9866, 192.168.122.8:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 04:32:27,300 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741849_1025, replicas=192.168.122.197:9866, 192.168.122.82:9866, 192.168.122.8:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 04:32:27,611 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1119510361_1
2019-09-15 04:32:27,620 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1664795162_1
2019-09-15 04:32:30,709 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2591ms to send a batch of 3 edits (323 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:32:34,120 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.82:8485]
2019-09-15 04:32:34,466 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6343ms to send a batch of 3 edits (323 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:32:36,943 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 8824ms to send a batch of 3 edits (323 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:32:36,955 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1568759703_1
2019-09-15 04:32:36,971 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-888222155_1
2019-09-15 04:32:39,641 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1227416393_1
2019-09-15 04:32:41,723 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3339ms to send a batch of 2 edits (256 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:32:41,724 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3341ms to send a batch of 2 edits (256 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:32:42,589 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4205ms to send a batch of 2 edits (256 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:32:55,762 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 67 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 125 Number of syncs: 43 SyncTimes(ms): 19057 14915 
2019-09-15 04:33:28,505 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-09-15 04:33:28,508 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-1-link-0/192.168.122.155
************************************************************/
2019-09-15 04:33:42,179 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-1-link-0/192.168.122.155
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/etc/hadoop:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-kms-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-07-19T04:04Z
STARTUP_MSG:   java = 1.8.0_212
************************************************************/
2019-09-15 04:33:42,188 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-15 04:33:42,264 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-09-15 04:33:42,395 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-09-15 04:33:42,425 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-09-15 04:33:42,503 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-09-15 04:33:42,503 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-09-15 04:33:42,541 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-09-15 04:33:42,541 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-09-15 04:33:42,658 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-09-15 04:33:42,673 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-09-15 04:33:42,686 INFO  util.log Log.java:initialized:192 - Logging initialized @1027ms
2019-09-15 04:33:42,771 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-15 04:33:42,779 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-09-15 04:33:42,787 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:970 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-15 04:33:42,789 INFO  http.HttpServer2 HttpServer2.java:addFilter:943 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-09-15 04:33:42,790 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-15 04:33:42,790 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-15 04:33:42,809 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-09-15 04:33:42,809 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:789 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-09-15 04:33:42,815 INFO  http.HttpServer2 HttpServer2.java:bindListener:1186 - Jetty bound to port 9870
2019-09-15 04:33:42,816 INFO  server.Server Server.java:doStart:351 - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T13:11:56-04:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-15 04:33:42,840 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@66982506{/logs,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/logs/,AVAILABLE}
2019-09-15 04:33:42,840 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@5a59ca5e{/static,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-09-15 04:33:42,897 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@15f47664{/,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-09-15 04:33:42,903 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@784ebb6c{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-09-15 04:33:42,903 INFO  server.Server Server.java:doStart:419 - Started @1245ms
2019-09-15 04:33:43,091 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-09-15 04:33:43,215 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-09-15 04:33:43,229 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-09-15 04:33:43,231 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:121 - fsLock is fair: true
2019-09-15 04:33:43,232 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:139 - Detailed lock hold time metrics enabled: false
2019-09-15 04:33:43,239 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-09-15 04:33:43,239 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-09-15 04:33:43,239 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-09-15 04:33:43,240 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-09-15 04:33:43,240 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-09-15 04:33:43,275 INFO  common.Util Util.java:isDiskStatsEnabled:394 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-15 04:33:43,284 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-09-15 04:33:43,284 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-15 04:33:43,287 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-15 04:33:43,288 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Sep 15 04:33:43
2019-09-15 04:33:43,289 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-09-15 04:33:43,289 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:33:43,291 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 444.5 MB = 8.9 MB
2019-09-15 04:33:43,291 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-09-15 04:33:43,297 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-09-15 04:33:43,304 INFO  Configuration.deprecation Configuration.java:logDeprecation:1394 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-09-15 04:33:43,304 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-15 04:33:43,304 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-09-15 04:33:43,304 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-09-15 04:33:43,304 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-09-15 04:33:43,304 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-09-15 04:33:43,304 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-09-15 04:33:43,304 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-09-15 04:33:43,304 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-09-15 04:33:43,305 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-09-15 04:33:43,305 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-09-15 04:33:43,326 INFO  namenode.FSDirectory SerialNumberManager.java:initialize:77 - GLOBAL serial map: bits=24 maxEntries=16777215
2019-09-15 04:33:43,339 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-09-15 04:33:43,339 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:33:43,340 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 444.5 MB = 4.4 MB
2019-09-15 04:33:43,340 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^19 = 524288 entries
2019-09-15 04:33:43,340 INFO  namenode.FSDirectory FSDirectory.java:<init>:285 - ACLs enabled? false
2019-09-15 04:33:43,340 INFO  namenode.FSDirectory FSDirectory.java:<init>:289 - POSIX ACL inheritance enabled? true
2019-09-15 04:33:43,340 INFO  namenode.FSDirectory FSDirectory.java:<init>:293 - XAttrs enabled? true
2019-09-15 04:33:43,341 INFO  namenode.NameNode FSDirectory.java:<init>:357 - Caching file names occurring more than 10 times
2019-09-15 04:33:43,345 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-09-15 04:33:43,347 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-09-15 04:33:43,351 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-09-15 04:33:43,351 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:33:43,351 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 444.5 MB = 1.1 MB
2019-09-15 04:33:43,351 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^17 = 131072 entries
2019-09-15 04:33:43,358 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-15 04:33:43,358 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-09-15 04:33:43,358 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-15 04:33:43,362 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:990 - Retry cache on namenode is enabled
2019-09-15 04:33:43,362 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:998 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-09-15 04:33:43,364 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-09-15 04:33:43,364 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:33:43,364 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 444.5 MB = 136.5 KB
2019-09-15 04:33:43,364 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^14 = 16384 entries
2019-09-15 04:33:43,417 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 19799@node-1-link-0
2019-09-15 04:33:44,711 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:44,711 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:44,711 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:45,713 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:45,713 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:45,716 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:46,714 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:46,715 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:46,717 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:47,716 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:47,717 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:47,719 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:48,717 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:48,719 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:48,720 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:49,547 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 04:33:49,719 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:49,720 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:49,721 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:50,549 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 04:33:50,720 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:50,722 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:50,723 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:33:51,462 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-09-15 04:33:51,540 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:233 - Loading 1 INodes.
2019-09-15 04:33:51,586 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:183 - Loaded FSImage in 0 seconds.
2019-09-15 04:33:51,587 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-09-15 04:33:51,593 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@67c2e933 expecting start txid #1
2019-09-15 04:33:51,593 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:33:51,598 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:33:51,598 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:33:51,846 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 31 loaded in 0 seconds
2019-09-15 04:33:51,846 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@41dd05a expecting start txid #32
2019-09-15 04:33:51,846 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:33:51,847 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:33:51,847 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:33:52,052 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 71 loaded in 0 seconds
2019-09-15 04:33:52,053 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1102 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-09-15 04:33:52,053 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-09-15 04:33:52,053 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 8686 msecs
2019-09-15 04:33:52,251 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-09-15 04:33:52,256 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-15 04:33:52,280 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-09-15 04:33:52,540 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:5000 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-09-15 04:33:52,549 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-09-15 04:33:52,566 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON. 
The reported blocks 0 needs additional 4 blocks to reach the threshold 0.9990 of total blocks 5.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-09-15 04:33:52,607 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-09-15 04:33:52,614 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/192.168.122.155:8020
2019-09-15 04:33:52,617 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1376 - Starting services required for standby state
2019-09-15 04:33:52,619 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-09-15 04:33:52,628 INFO  ha.EditLogTailer EditLogTailer.java:<init>:186 - Will roll logs on active node every 120 seconds.
2019-09-15 04:33:52,635 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-09-15 04:33:53,933 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.137:9866, datanodeUuid=41b206c5-4657-4aaa-815b-adf68b525caf, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 41b206c5-4657-4aaa-815b-adf68b525caf
2019-09-15 04:33:53,934 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.137:9866
2019-09-15 04:33:53,935 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 41b206c5-4657-4aaa-815b-adf68b525caf (192.168.122.137:9866).
2019-09-15 04:33:53,941 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.8:9866, datanodeUuid=89f24cb4-5f0d-4659-bf19-dada3b6dcfc8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8
2019-09-15 04:33:53,941 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.8:9866
2019-09-15 04:33:53,941 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8 (192.168.122.8:9866).
2019-09-15 04:33:53,945 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.197:9866, datanodeUuid=905c77ce-7769-42b2-9169-4d4cc646f9f6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 905c77ce-7769-42b2-9169-4d4cc646f9f6
2019-09-15 04:33:53,945 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.197:9866
2019-09-15 04:33:53,946 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 905c77ce-7769-42b2-9169-4d4cc646f9f6 (192.168.122.197:9866).
2019-09-15 04:33:53,946 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.82:9866, datanodeUuid=7f51c406-ca97-43fe-bde5-99f4814db4d0, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 7f51c406-ca97-43fe-bde5-99f4814db4d0
2019-09-15 04:33:53,946 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.82:9866
2019-09-15 04:33:53,946 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 7f51c406-ca97-43fe-bde5-99f4814db4d0 (192.168.122.82:9866).
2019-09-15 04:33:54,047 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-55f9ef08-2468-44be-b707-26a7a258468a for DN 192.168.122.197:9866
2019-09-15 04:33:54,052 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb for DN 192.168.122.82:9866
2019-09-15 04:33:54,053 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-9a499255-1089-4fd8-9d09-1328babba9f4 for DN 192.168.122.8:9866
2019-09-15 04:33:54,054 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa for DN 192.168.122.137:9866
2019-09-15 04:33:54,121 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x25cfab4c8c53bfaa: Processing first storage report for DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa from datanode 41b206c5-4657-4aaa-815b-adf68b525caf
2019-09-15 04:33:54,129 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode extension entered. 
The reported blocks 4 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 30 seconds.
2019-09-15 04:33:54,129 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x25cfab4c8c53bfaa: from storage DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa node DatanodeRegistration(192.168.122.137:9866, datanodeUuid=41b206c5-4657-4aaa-815b-adf68b525caf, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 5, hasStaleStorage: false, processing time: 9 msecs, invalidatedBlocks: 0
2019-09-15 04:33:54,130 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x14f66dd45cbee3dc: Processing first storage report for DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb from datanode 7f51c406-ca97-43fe-bde5-99f4814db4d0
2019-09-15 04:33:54,130 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x14f66dd45cbee3dc: from storage DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb node DatanodeRegistration(192.168.122.82:9866, datanodeUuid=7f51c406-ca97-43fe-bde5-99f4814db4d0, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 4, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-09-15 04:33:54,131 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xdbf9d84d79b088b1: Processing first storage report for DS-55f9ef08-2468-44be-b707-26a7a258468a from datanode 905c77ce-7769-42b2-9169-4d4cc646f9f6
2019-09-15 04:33:54,131 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xdbf9d84d79b088b1: from storage DS-55f9ef08-2468-44be-b707-26a7a258468a node DatanodeRegistration(192.168.122.197:9866, datanodeUuid=905c77ce-7769-42b2-9169-4d4cc646f9f6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 04:33:54,131 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x225890e6c57fd583: Processing first storage report for DS-9a499255-1089-4fd8-9d09-1328babba9f4 from datanode 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8
2019-09-15 04:33:54,132 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x225890e6c57fd583: from storage DS-9a499255-1089-4fd8-9d09-1328babba9f4 node DatanodeRegistration(192.168.122.8:9866, datanodeUuid=89f24cb4-5f0d-4659-bf19-dada3b6dcfc8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 4, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 04:33:54,237 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1419 - Stopping services started for standby state
2019-09-15 04:33:54,239 WARN  ha.EditLogTailer EditLogTailer.java:doWork:471 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2019-09-15 04:33:54,350 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Starting services required for active state
2019-09-15 04:33:54,374 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:442 - Starting recovery process for unclosed journal segments...
2019-09-15 04:33:54,582 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:444 - Successfully started new epoch 4
2019-09-15 04:33:54,582 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:284 - Beginning recovery of unclosed segment starting at txid 103
2019-09-15 04:33:54,655 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:293 - Recovery prepare phase complete. Responses:
192.168.122.197:8485: segmentState { startTxId: 103 endTxId: 173 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 172
192.168.122.137:8485: segmentState { startTxId: 103 endTxId: 173 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 172
2019-09-15 04:33:54,659 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:317 - Using longest log: 192.168.122.197:8485=segmentState {
  startTxId: 103
  endTxId: 173
  isInProgress: true
}
lastWriterEpoch: 3
lastCommittedTxId: 172

2019-09-15 04:33:54,800 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-09-15 04:33:54,826 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000103 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000103-0000000000000000173
2019-09-15 04:33:54,852 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1225 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-09-15 04:33:54,861 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1cfdb0a3 expecting start txid #103
2019-09-15 04:33:54,862 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000103-0000000000000000173, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:33:54,862 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream '/tmp/hadoop-root/dfs/name/current/edits_0000000000000000103-0000000000000000173' to transaction ID 103
2019-09-15 04:33:54,884 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000103-0000000000000000173, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 71 loaded in 0 seconds
2019-09-15 04:33:54,885 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1840 - Marking all datanodes as stale
2019-09-15 04:33:54,889 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1247 - Will take over writing edit logs at txnid 174
2019-09-15 04:33:54,895 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 174
2019-09-15 04:33:55,455 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:769 - Initializing quota with 4 thread(s)
2019-09-15 04:33:55,462 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:778 - Quota initialization completed in 6 milliseconds
name space=6
storage space=2013265920
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-09-15 04:33:55,478 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-09-15 04:34:14,473 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON, in safe mode extension. 
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-09-15 04:34:22,146 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40772
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:34:22,173 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40772
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:34:22,855 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40776
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:34:22,882 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40776
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:34:23,286 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40784
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:34:23,288 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40786
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:34:23,295 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40788
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:34:23,308 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40788
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:34:23,313 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40784
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:34:23,323 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40786
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:34:23,493 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40772
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:34:23,622 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40776
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:34:23,938 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40786
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:34:24,006 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40788
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:34:24,475 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4792 - initializing replication queues
2019-09-15 04:34:24,476 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:391 - STATE* Safe mode is OFF
2019-09-15 04:34:24,476 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 31 secs
2019-09-15 04:34:24,476 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 1 racks and 4 datanodes
2019-09-15 04:34:24,476 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-09-15 04:34:24,482 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3475 - Total number of blocks            = 5
2019-09-15 04:34:24,482 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3476 - Number of invalid blocks          = 0
2019-09-15 04:34:24,482 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3477 - Number of under-replicated blocks = 0
2019-09-15 04:34:24,483 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3478 - Number of  over-replicated blocks = 0
2019-09-15 04:34:24,483 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3480 - Number of blocks being written    = 0
2019-09-15 04:34:24,483 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3483 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2019-09-15 04:34:24,959 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741850_1026, replicas=192.168.122.8:9866, 192.168.122.137:9866, 192.168.122.82:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 04:34:25,023 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741851_1027, replicas=192.168.122.8:9866, 192.168.122.197:9866, 192.168.122.82:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 04:34:25,064 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741852_1028, replicas=192.168.122.8:9866, 192.168.122.197:9866, 192.168.122.137:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 04:34:26,710 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741853_1029, replicas=192.168.122.137:9866, 192.168.122.82:9866, 192.168.122.197:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 04:34:26,875 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741854_1030, replicas=192.168.122.82:9866, 192.168.122.137:9866, 192.168.122.8:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 04:34:27,536 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1589538809_1
2019-09-15 04:34:27,655 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_2062418277_1
2019-09-15 04:34:27,705 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_2101603803_1
2019-09-15 04:34:28,611 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1296ms to send a batch of 1 edits (67 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:34:29,266 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1951ms to send a batch of 1 edits (67 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:34:29,367 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2053ms to send a batch of 1 edits (67 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:34:34,129 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4773ms to send a batch of 3 edits (384 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:34:35,364 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.82:8485]
2019-09-15 04:34:36,364 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.82:8485]
2019-09-15 04:34:37,365 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 8003 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.82:8485]
2019-09-15 04:34:38,367 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 9004 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.82:8485]
2019-09-15 04:34:39,367 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 10005 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.82:8485]
2019-09-15 04:34:39,458 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 10090ms to send a batch of 3 edits (384 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:34:39,459 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 10096ms to send a batch of 3 edits (384 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:34:39,734 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_551513537_1
2019-09-15 04:34:40,089 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1740924420_1
2019-09-15 04:34:43,358 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3652ms to send a batch of 1 edits (99 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:34:43,999 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4292ms to send a batch of 1 edits (99 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:34:44,022 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4314ms to send a batch of 1 edits (99 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:34:44,040 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 29 Total time for transactions(ms): 16 Number of transactions batched in Syncs: 182 Number of syncs: 16 SyncTimes(ms): 17141 668 
2019-09-15 04:35:10,618 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741855_1031, replicas=192.168.122.197:9866, 192.168.122.137:9866, 192.168.122.82:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 04:35:10,623 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741856_1032, replicas=192.168.122.137:9866, 192.168.122.8:9866, 192.168.122.82:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 04:35:11,143 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741857_1033, replicas=192.168.122.8:9866, 192.168.122.197:9866, 192.168.122.82:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 04:35:12,409 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741858_1034, replicas=192.168.122.137:9866, 192.168.122.82:9866, 192.168.122.197:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 04:35:13,242 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-218413926_1
2019-09-15 04:35:14,189 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1262438691_1
2019-09-15 04:35:15,171 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1812ms to send a batch of 2 edits (195 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:35:15,172 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1813ms to send a batch of 2 edits (195 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:35:17,114 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1515063164_1
2019-09-15 04:35:17,131 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3769ms to send a batch of 2 edits (195 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:35:17,479 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1304ms to send a batch of 2 edits (315 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:35:19,525 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1972547651_1
2019-09-15 04:35:22,176 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.137:8485]
2019-09-15 04:35:23,176 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.137:8485]
2019-09-15 04:35:23,801 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6669ms to send a batch of 2 edits (315 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:35:23,889 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 7715ms to send a batch of 2 edits (315 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:35:24,077 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741859_1035, replicas=192.168.122.197:9866, 192.168.122.8:9866, 192.168.122.137:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 04:35:25,384 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_424983479_1
2019-09-15 04:35:26,911 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1526ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:35:27,464 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2079ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:35:37,893 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1160ms to send a batch of 1 edits (68 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:35:37,893 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1161ms to send a batch of 1 edits (68 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:35:37,922 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1190ms to send a batch of 1 edits (68 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:35:48,037 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-09-15 04:35:48,045 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-1-link-0/192.168.122.155
************************************************************/
2019-09-15 04:36:01,478 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-1-link-0/192.168.122.155
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/etc/hadoop:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-kms-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-07-19T04:04Z
STARTUP_MSG:   java = 1.8.0_212
************************************************************/
2019-09-15 04:36:01,487 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-15 04:36:01,567 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-09-15 04:36:01,705 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-09-15 04:36:01,735 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-09-15 04:36:01,834 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-09-15 04:36:01,834 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-09-15 04:36:01,881 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-09-15 04:36:01,882 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-09-15 04:36:02,011 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-09-15 04:36:02,035 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-09-15 04:36:02,049 INFO  util.log Log.java:initialized:192 - Logging initialized @1046ms
2019-09-15 04:36:02,155 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-15 04:36:02,165 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-09-15 04:36:02,175 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:970 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-15 04:36:02,178 INFO  http.HttpServer2 HttpServer2.java:addFilter:943 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-09-15 04:36:02,181 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-15 04:36:02,181 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-15 04:36:02,204 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-09-15 04:36:02,204 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:789 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-09-15 04:36:02,211 INFO  http.HttpServer2 HttpServer2.java:bindListener:1186 - Jetty bound to port 9870
2019-09-15 04:36:02,212 INFO  server.Server Server.java:doStart:351 - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T13:11:56-04:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-15 04:36:02,263 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@66982506{/logs,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/logs/,AVAILABLE}
2019-09-15 04:36:02,264 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@5a59ca5e{/static,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-09-15 04:36:02,373 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@15f47664{/,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-09-15 04:36:02,383 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@56dc1551{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-09-15 04:36:02,383 INFO  server.Server Server.java:doStart:419 - Started @1380ms
2019-09-15 04:36:02,649 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-09-15 04:36:02,797 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-09-15 04:36:02,808 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-09-15 04:36:02,809 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:121 - fsLock is fair: true
2019-09-15 04:36:02,810 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:139 - Detailed lock hold time metrics enabled: false
2019-09-15 04:36:02,816 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-09-15 04:36:02,816 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-09-15 04:36:02,816 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-09-15 04:36:02,816 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-09-15 04:36:02,816 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-09-15 04:36:02,849 INFO  common.Util Util.java:isDiskStatsEnabled:394 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-15 04:36:02,859 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-09-15 04:36:02,859 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-15 04:36:02,863 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-15 04:36:02,863 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Sep 15 04:36:02
2019-09-15 04:36:02,865 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-09-15 04:36:02,865 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:36:02,866 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 444.5 MB = 8.9 MB
2019-09-15 04:36:02,866 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-09-15 04:36:02,874 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-09-15 04:36:02,885 INFO  Configuration.deprecation Configuration.java:logDeprecation:1394 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-09-15 04:36:02,886 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-15 04:36:02,886 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-09-15 04:36:02,886 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-09-15 04:36:02,886 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-09-15 04:36:02,886 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-09-15 04:36:02,886 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-09-15 04:36:02,886 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-09-15 04:36:02,887 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-09-15 04:36:02,887 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-09-15 04:36:02,887 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-09-15 04:36:02,925 INFO  namenode.FSDirectory SerialNumberManager.java:initialize:77 - GLOBAL serial map: bits=24 maxEntries=16777215
2019-09-15 04:36:02,939 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-09-15 04:36:02,939 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:36:02,939 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 444.5 MB = 4.4 MB
2019-09-15 04:36:02,942 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^19 = 524288 entries
2019-09-15 04:36:02,942 INFO  namenode.FSDirectory FSDirectory.java:<init>:285 - ACLs enabled? false
2019-09-15 04:36:02,943 INFO  namenode.FSDirectory FSDirectory.java:<init>:289 - POSIX ACL inheritance enabled? true
2019-09-15 04:36:02,943 INFO  namenode.FSDirectory FSDirectory.java:<init>:293 - XAttrs enabled? true
2019-09-15 04:36:02,943 INFO  namenode.NameNode FSDirectory.java:<init>:357 - Caching file names occurring more than 10 times
2019-09-15 04:36:02,948 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-09-15 04:36:02,952 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-09-15 04:36:02,956 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-09-15 04:36:02,956 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:36:02,956 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 444.5 MB = 1.1 MB
2019-09-15 04:36:02,957 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^17 = 131072 entries
2019-09-15 04:36:02,964 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-15 04:36:02,964 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-09-15 04:36:02,964 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-15 04:36:02,968 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:990 - Retry cache on namenode is enabled
2019-09-15 04:36:02,969 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:998 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-09-15 04:36:02,971 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-09-15 04:36:02,971 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:36:02,971 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 444.5 MB = 136.5 KB
2019-09-15 04:36:02,971 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^14 = 16384 entries
2019-09-15 04:36:03,012 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 20300@node-1-link-0
2019-09-15 04:36:04,313 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:04,313 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:04,314 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:05,315 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:05,318 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:05,319 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:06,317 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:06,320 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:06,321 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:07,318 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:07,321 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:07,322 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:08,320 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:08,323 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:08,323 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:09,162 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 04:36:09,322 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:09,324 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:09,325 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:10,163 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 04:36:10,323 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:10,326 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:10,326 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:36:11,127 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-09-15 04:36:11,231 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:233 - Loading 1 INodes.
2019-09-15 04:36:11,279 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:183 - Loaded FSImage in 0 seconds.
2019-09-15 04:36:11,279 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-09-15 04:36:11,286 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@41dd05a expecting start txid #1
2019-09-15 04:36:11,286 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:36:11,295 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:36:11,296 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:36:11,586 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 31 loaded in 0 seconds
2019-09-15 04:36:11,587 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@613a8ee1 expecting start txid #32
2019-09-15 04:36:11,587 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:36:11,587 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:36:11,587 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:36:11,767 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 71 loaded in 0 seconds
2019-09-15 04:36:11,767 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@178213b expecting start txid #103
2019-09-15 04:36:11,768 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:36:11,768 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:36:11,768 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:36:11,790 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 71 loaded in 0 seconds
2019-09-15 04:36:11,790 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1102 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-09-15 04:36:11,790 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-09-15 04:36:11,791 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 8813 msecs
2019-09-15 04:36:11,986 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-09-15 04:36:11,991 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-15 04:36:12,006 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-09-15 04:36:12,279 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:5000 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-09-15 04:36:12,299 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-09-15 04:36:12,312 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON. 
The reported blocks 0 needs additional 4 blocks to reach the threshold 0.9990 of total blocks 5.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-09-15 04:36:12,385 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-09-15 04:36:12,386 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-09-15 04:36:12,399 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/192.168.122.155:8020
2019-09-15 04:36:12,409 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1376 - Starting services required for standby state
2019-09-15 04:36:12,417 INFO  ha.EditLogTailer EditLogTailer.java:<init>:186 - Will roll logs on active node every 120 seconds.
2019-09-15 04:36:12,432 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-09-15 04:36:13,622 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.197:9866, datanodeUuid=905c77ce-7769-42b2-9169-4d4cc646f9f6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 905c77ce-7769-42b2-9169-4d4cc646f9f6
2019-09-15 04:36:13,623 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.197:9866
2019-09-15 04:36:13,624 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 905c77ce-7769-42b2-9169-4d4cc646f9f6 (192.168.122.197:9866).
2019-09-15 04:36:13,629 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.137:9866, datanodeUuid=41b206c5-4657-4aaa-815b-adf68b525caf, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 41b206c5-4657-4aaa-815b-adf68b525caf
2019-09-15 04:36:13,629 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.137:9866
2019-09-15 04:36:13,630 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 41b206c5-4657-4aaa-815b-adf68b525caf (192.168.122.137:9866).
2019-09-15 04:36:13,630 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.82:9866, datanodeUuid=7f51c406-ca97-43fe-bde5-99f4814db4d0, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 7f51c406-ca97-43fe-bde5-99f4814db4d0
2019-09-15 04:36:13,630 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.82:9866
2019-09-15 04:36:13,630 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 7f51c406-ca97-43fe-bde5-99f4814db4d0 (192.168.122.82:9866).
2019-09-15 04:36:13,631 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.8:9866, datanodeUuid=89f24cb4-5f0d-4659-bf19-dada3b6dcfc8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8
2019-09-15 04:36:13,631 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.8:9866
2019-09-15 04:36:13,631 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8 (192.168.122.8:9866).
2019-09-15 04:36:13,766 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb for DN 192.168.122.82:9866
2019-09-15 04:36:13,770 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-9a499255-1089-4fd8-9d09-1328babba9f4 for DN 192.168.122.8:9866
2019-09-15 04:36:13,775 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa for DN 192.168.122.137:9866
2019-09-15 04:36:13,785 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-55f9ef08-2468-44be-b707-26a7a258468a for DN 192.168.122.197:9866
2019-09-15 04:36:13,821 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x15ca604bc8be2cef: Processing first storage report for DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa from datanode 41b206c5-4657-4aaa-815b-adf68b525caf
2019-09-15 04:36:13,828 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode extension entered. 
The reported blocks 4 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2019-09-15 04:36:13,828 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x15ca604bc8be2cef: from storage DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa node DatanodeRegistration(192.168.122.137:9866, datanodeUuid=41b206c5-4657-4aaa-815b-adf68b525caf, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 5, hasStaleStorage: false, processing time: 8 msecs, invalidatedBlocks: 0
2019-09-15 04:36:13,829 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x950dcf6217d18a5b: Processing first storage report for DS-9a499255-1089-4fd8-9d09-1328babba9f4 from datanode 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8
2019-09-15 04:36:13,829 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x950dcf6217d18a5b: from storage DS-9a499255-1089-4fd8-9d09-1328babba9f4 node DatanodeRegistration(192.168.122.8:9866, datanodeUuid=89f24cb4-5f0d-4659-bf19-dada3b6dcfc8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 4, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-09-15 04:36:13,829 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xd6a5f37a72e6a39a: Processing first storage report for DS-55f9ef08-2468-44be-b707-26a7a258468a from datanode 905c77ce-7769-42b2-9169-4d4cc646f9f6
2019-09-15 04:36:13,830 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xd6a5f37a72e6a39a: from storage DS-55f9ef08-2468-44be-b707-26a7a258468a node DatanodeRegistration(192.168.122.197:9866, datanodeUuid=905c77ce-7769-42b2-9169-4d4cc646f9f6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 04:36:13,830 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x6e921d13e6cd9fcc: Processing first storage report for DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb from datanode 7f51c406-ca97-43fe-bde5-99f4814db4d0
2019-09-15 04:36:13,841 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x6e921d13e6cd9fcc: from storage DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb node DatanodeRegistration(192.168.122.82:9866, datanodeUuid=7f51c406-ca97-43fe-bde5-99f4814db4d0, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 4, hasStaleStorage: false, processing time: 10 msecs, invalidatedBlocks: 0
2019-09-15 04:36:13,846 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1419 - Stopping services started for standby state
2019-09-15 04:36:13,850 WARN  ha.EditLogTailer EditLogTailer.java:doWork:471 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2019-09-15 04:36:13,861 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Starting services required for active state
2019-09-15 04:36:13,879 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:442 - Starting recovery process for unclosed journal segments...
2019-09-15 04:36:14,079 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:444 - Successfully started new epoch 5
2019-09-15 04:36:14,080 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:284 - Beginning recovery of unclosed segment starting at txid 174
2019-09-15 04:36:14,136 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:293 - Recovery prepare phase complete. Responses:
192.168.122.82:8485: segmentState { startTxId: 174 endTxId: 244 isInProgress: true } lastWriterEpoch: 4 lastCommittedTxId: 240
192.168.122.197:8485: segmentState { startTxId: 174 endTxId: 244 isInProgress: true } lastWriterEpoch: 4 lastCommittedTxId: 240
2019-09-15 04:36:14,140 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:317 - Using longest log: 192.168.122.82:8485=segmentState {
  startTxId: 174
  endTxId: 244
  isInProgress: true
}
lastWriterEpoch: 4
lastCommittedTxId: 240

2019-09-15 04:36:14,283 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-09-15 04:36:14,302 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000174 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000174-0000000000000000244
2019-09-15 04:36:14,321 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1225 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-09-15 04:36:14,328 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2d704ef expecting start txid #174
2019-09-15 04:36:14,328 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000174-0000000000000000244, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=174&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=174&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:36:14,328 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream '/tmp/hadoop-root/dfs/name/current/edits_0000000000000000174-0000000000000000244' to transaction ID 174
2019-09-15 04:36:14,338 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000174-0000000000000000244, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=174&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=174&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 71 loaded in 0 seconds
2019-09-15 04:36:14,338 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1840 - Marking all datanodes as stale
2019-09-15 04:36:14,339 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1247 - Will take over writing edit logs at txnid 245
2019-09-15 04:36:14,345 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 245
2019-09-15 04:36:14,914 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:769 - Initializing quota with 4 thread(s)
2019-09-15 04:36:14,920 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:778 - Quota initialization completed in 6 milliseconds
name space=6
storage space=2013265920
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-09-15 04:36:14,930 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-09-15 04:36:33,931 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON, in safe mode extension. 
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-09-15 04:36:42,018 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40964
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:36:42,039 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40964
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:36:42,126 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40966
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:36:42,159 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40966
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:36:42,873 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40970
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:36:42,896 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40976
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:36:42,912 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40970
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:36:42,916 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40976
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:36:42,921 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40978
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:36:42,937 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40978
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:36:42,960 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40966
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:36:42,987 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40964
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:36:43,755 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40976
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:36:43,779 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:40978
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:36:43,934 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4792 - initializing replication queues
2019-09-15 04:36:43,934 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:391 - STATE* Safe mode is OFF
2019-09-15 04:36:43,935 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 31 secs
2019-09-15 04:36:43,935 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 1 racks and 4 datanodes
2019-09-15 04:36:43,935 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-09-15 04:36:43,942 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3475 - Total number of blocks            = 5
2019-09-15 04:36:43,942 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3476 - Number of invalid blocks          = 0
2019-09-15 04:36:43,944 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3477 - Number of under-replicated blocks = 0
2019-09-15 04:36:43,945 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3478 - Number of  over-replicated blocks = 0
2019-09-15 04:36:43,945 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3480 - Number of blocks being written    = 0
2019-09-15 04:36:43,945 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3483 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
2019-09-15 04:36:44,287 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741860_1036, replicas=192.168.122.82:9866, 192.168.122.8:9866, 192.168.122.197:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 04:36:44,572 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741861_1037, replicas=192.168.122.197:9866, 192.168.122.82:9866, 192.168.122.137:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 04:36:45,638 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741862_1038, replicas=192.168.122.137:9866, 192.168.122.8:9866, 192.168.122.197:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 04:36:46,055 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741863_1039, replicas=192.168.122.137:9866, 192.168.122.197:9866, 192.168.122.8:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 04:36:46,603 INFO  namenode.FSNamesystem FSNamesystem.java:checkBlocksComplete:2908 - BLOCK* blk_1073741861_1037 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /myfile5.remotecopy._COPYING_
2019-09-15 04:36:46,877 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1024896489_1
2019-09-15 04:36:47,019 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_252600180_1
2019-09-15 04:36:48,913 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2130ms to send a batch of 1 edits (189 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:36:48,942 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2159ms to send a batch of 1 edits (189 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:36:50,131 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3348ms to send a batch of 1 edits (189 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:36:50,379 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1884709075_1
2019-09-15 04:36:50,473 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741864_1040, replicas=192.168.122.82:9866, 192.168.122.137:9866, 192.168.122.8:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 04:36:50,696 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-325406110_1
2019-09-15 04:36:56,414 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for sendEdits. No responses yet.
2019-09-15 04:36:57,415 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for sendEdits. No responses yet.
2019-09-15 04:36:58,417 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 8003 ms (timeout=20000 ms) for a response for sendEdits. No responses yet.
2019-09-15 04:36:58,569 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 8155ms to send a batch of 3 edits (384 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:36:59,417 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 9004 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.137:8485]
2019-09-15 04:37:00,419 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 10006 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.137:8485]
2019-09-15 04:37:00,597 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 10184ms to send a batch of 3 edits (384 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:37:01,320 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 10906ms to send a batch of 3 edits (384 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:37:02,373 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1995938176_1
2019-09-15 04:37:09,526 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 32 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 258 Number of syncs: 17 SyncTimes(ms): 13599 2609 
2019-09-15 04:37:28,766 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741865_1041, replicas=192.168.122.137:9866, 192.168.122.197:9866, 192.168.122.8:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 04:37:28,822 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741866_1042, replicas=192.168.122.197:9866, 192.168.122.137:9866, 192.168.122.82:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 04:37:29,021 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741867_1043, replicas=192.168.122.8:9866, 192.168.122.137:9866, 192.168.122.82:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 04:37:29,056 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741868_1044, replicas=192.168.122.82:9866, 192.168.122.197:9866, 192.168.122.8:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 04:37:30,338 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741869_1045, replicas=192.168.122.137:9866, 192.168.122.82:9866, 192.168.122.8:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 04:37:31,751 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1205860732_1
2019-09-15 04:37:32,126 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-301111994_1
2019-09-15 04:37:32,142 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-472677215_1
2019-09-15 04:37:32,777 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-2122561078_1
2019-09-15 04:37:35,362 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3609ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:37:37,753 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.82:8485]
2019-09-15 04:37:38,753 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.122.82:8485]
2019-09-15 04:37:39,107 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 7354ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:37:41,625 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 9872ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:37:42,030 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_202394726_1
2019-09-15 04:38:07,112 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-09-15 04:38:07,114 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at node-1-link-0/192.168.122.155
************************************************************/
2019-09-15 04:38:21,270 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = node-1-link-0/192.168.122.155
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/etc/hadoop:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-kms-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-07-19T04:04Z
STARTUP_MSG:   java = 1.8.0_212
************************************************************/
2019-09-15 04:38:21,280 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-15 04:38:21,393 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-09-15 04:38:21,542 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-09-15 04:38:21,578 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-09-15 04:38:21,667 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-09-15 04:38:21,667 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-09-15 04:38:21,708 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-09-15 04:38:21,708 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-09-15 04:38:21,829 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-09-15 04:38:21,849 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-09-15 04:38:21,861 INFO  util.log Log.java:initialized:192 - Logging initialized @1101ms
2019-09-15 04:38:21,949 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-15 04:38:21,959 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-09-15 04:38:21,967 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:970 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-15 04:38:21,969 INFO  http.HttpServer2 HttpServer2.java:addFilter:943 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-09-15 04:38:21,971 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-15 04:38:21,971 INFO  http.HttpServer2 HttpServer2.java:addFilter:953 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-15 04:38:21,993 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-09-15 04:38:21,993 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:789 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-09-15 04:38:22,000 INFO  http.HttpServer2 HttpServer2.java:bindListener:1186 - Jetty bound to port 9870
2019-09-15 04:38:22,001 INFO  server.Server Server.java:doStart:351 - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T13:11:56-04:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-15 04:38:22,039 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@66982506{/logs,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/logs/,AVAILABLE}
2019-09-15 04:38:22,040 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@5a59ca5e{/static,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-09-15 04:38:22,127 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@15f47664{/,file:///root/hadoop-3.1.2-src/hadoop-dist/target/hadoop-3.1.2/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-09-15 04:38:22,136 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@784ebb6c{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-09-15 04:38:22,137 INFO  server.Server Server.java:doStart:419 - Started @1376ms
2019-09-15 04:38:22,337 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-09-15 04:38:22,437 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-09-15 04:38:22,450 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-09-15 04:38:22,451 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:121 - fsLock is fair: true
2019-09-15 04:38:22,453 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:139 - Detailed lock hold time metrics enabled: false
2019-09-15 04:38:22,460 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-09-15 04:38:22,460 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-09-15 04:38:22,460 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-09-15 04:38:22,461 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-09-15 04:38:22,461 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-09-15 04:38:22,502 INFO  common.Util Util.java:isDiskStatsEnabled:394 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-15 04:38:22,516 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-09-15 04:38:22,516 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-09-15 04:38:22,521 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-09-15 04:38:22,521 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Sep 15 04:38:22
2019-09-15 04:38:22,523 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-09-15 04:38:22,523 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:38:22,525 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 444.5 MB = 8.9 MB
2019-09-15 04:38:22,525 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-09-15 04:38:22,532 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-09-15 04:38:22,539 INFO  Configuration.deprecation Configuration.java:logDeprecation:1394 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-09-15 04:38:22,539 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-09-15 04:38:22,539 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-09-15 04:38:22,539 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-09-15 04:38:22,539 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-09-15 04:38:22,539 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-09-15 04:38:22,539 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-09-15 04:38:22,539 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-09-15 04:38:22,540 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-09-15 04:38:22,540 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-09-15 04:38:22,540 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-09-15 04:38:22,573 INFO  namenode.FSDirectory SerialNumberManager.java:initialize:77 - GLOBAL serial map: bits=24 maxEntries=16777215
2019-09-15 04:38:22,591 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-09-15 04:38:22,591 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:38:22,592 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 444.5 MB = 4.4 MB
2019-09-15 04:38:22,593 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^19 = 524288 entries
2019-09-15 04:38:22,594 INFO  namenode.FSDirectory FSDirectory.java:<init>:285 - ACLs enabled? false
2019-09-15 04:38:22,594 INFO  namenode.FSDirectory FSDirectory.java:<init>:289 - POSIX ACL inheritance enabled? true
2019-09-15 04:38:22,594 INFO  namenode.FSDirectory FSDirectory.java:<init>:293 - XAttrs enabled? true
2019-09-15 04:38:22,594 INFO  namenode.NameNode FSDirectory.java:<init>:357 - Caching file names occurring more than 10 times
2019-09-15 04:38:22,599 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-09-15 04:38:22,601 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-09-15 04:38:22,605 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-09-15 04:38:22,605 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:38:22,605 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 444.5 MB = 1.1 MB
2019-09-15 04:38:22,605 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^17 = 131072 entries
2019-09-15 04:38:22,612 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-09-15 04:38:22,612 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-09-15 04:38:22,612 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-09-15 04:38:22,620 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:990 - Retry cache on namenode is enabled
2019-09-15 04:38:22,620 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:998 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-09-15 04:38:22,622 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-09-15 04:38:22,622 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-09-15 04:38:22,622 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 444.5 MB = 136.5 KB
2019-09-15 04:38:22,622 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^14 = 16384 entries
2019-09-15 04:38:22,765 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 20779@node-1-link-0
2019-09-15 04:38:24,104 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:24,104 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:24,104 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:25,106 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:25,107 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:25,108 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:26,107 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:26,108 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:26,109 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:27,109 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:27,109 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:27,110 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:28,110 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:28,111 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:28,111 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:28,928 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 04:38:29,112 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:29,112 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:29,112 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:29,929 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-09-15 04:38:30,113 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-2-link-0/192.168.122.197:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:30,114 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-4-link-0/192.168.122.137:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:30,115 INFO  ipc.Client Client.java:handleConnectionFailure:948 - Retrying connect to server: node-3-link-0/192.168.122.82:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-15 04:38:30,869 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-09-15 04:38:30,951 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:233 - Loading 1 INodes.
2019-09-15 04:38:30,979 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:183 - Loaded FSImage in 0 seconds.
2019-09-15 04:38:30,979 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-09-15 04:38:30,984 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@67c2e933 expecting start txid #1
2019-09-15 04:38:30,984 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:38:30,988 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:38:30,988 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:38:31,241 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 31 loaded in 0 seconds
2019-09-15 04:38:31,241 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@41dd05a expecting start txid #32
2019-09-15 04:38:31,241 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:38:31,241 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:38:31,241 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:38:31,274 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=32&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 71 loaded in 0 seconds
2019-09-15 04:38:31,274 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@613a8ee1 expecting start txid #103
2019-09-15 04:38:31,274 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:38:31,274 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:38:31,274 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:38:31,419 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=103&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 71 loaded in 0 seconds
2019-09-15 04:38:31,419 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@178213b expecting start txid #174
2019-09-15 04:38:31,420 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=174&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=174&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:38:31,420 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=174&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=174&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:38:31,420 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=174&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true' to transaction ID 1
2019-09-15 04:38:31,438 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=174&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=174&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 71 loaded in 0 seconds
2019-09-15 04:38:31,439 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1102 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-09-15 04:38:31,439 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-09-15 04:38:31,439 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 8815 msecs
2019-09-15 04:38:31,686 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-09-15 04:38:31,691 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-15 04:38:31,713 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-09-15 04:38:32,015 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:5000 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-09-15 04:38:32,037 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-09-15 04:38:32,050 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON. 
The reported blocks 0 needs additional 4 blocks to reach the threshold 0.9990 of total blocks 5.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-09-15 04:38:32,127 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-09-15 04:38:32,153 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/192.168.122.155:8020
2019-09-15 04:38:32,155 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1376 - Starting services required for standby state
2019-09-15 04:38:32,161 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-09-15 04:38:32,261 INFO  ha.EditLogTailer EditLogTailer.java:<init>:186 - Will roll logs on active node every 120 seconds.
2019-09-15 04:38:32,276 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-09-15 04:38:33,485 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1419 - Stopping services started for standby state
2019-09-15 04:38:33,490 WARN  ha.EditLogTailer EditLogTailer.java:doWork:471 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2019-09-15 04:38:33,603 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Starting services required for active state
2019-09-15 04:38:33,638 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:442 - Starting recovery process for unclosed journal segments...
2019-09-15 04:38:33,863 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:444 - Successfully started new epoch 6
2019-09-15 04:38:33,864 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:284 - Beginning recovery of unclosed segment starting at txid 245
2019-09-15 04:38:33,942 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:293 - Recovery prepare phase complete. Responses:
192.168.122.197:8485: segmentState { startTxId: 245 endTxId: 315 isInProgress: true } lastWriterEpoch: 5 lastCommittedTxId: 314
192.168.122.82:8485: segmentState { startTxId: 245 endTxId: 315 isInProgress: true } lastWriterEpoch: 5 lastCommittedTxId: 314
2019-09-15 04:38:33,945 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:317 - Using longest log: 192.168.122.197:8485=segmentState {
  startTxId: 245
  endTxId: 315
  isInProgress: true
}
lastWriterEpoch: 5
lastCommittedTxId: 314

2019-09-15 04:38:34,074 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-09-15 04:38:34,129 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000245 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000245-0000000000000000315
2019-09-15 04:38:34,152 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1225 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-09-15 04:38:34,158 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2391bb80 expecting start txid #245
2019-09-15 04:38:34,158 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000245-0000000000000000315, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=245&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=245&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-09-15 04:38:34,159 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream '/tmp/hadoop-root/dfs/name/current/edits_0000000000000000245-0000000000000000315' to transaction ID 245
2019-09-15 04:38:34,184 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file /tmp/hadoop-root/dfs/name/current/edits_0000000000000000245-0000000000000000315, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=245&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=245&storageInfo=-64%3A1728015749%3A1568535976523%3ACID-f5a19194-e593-4dd9-96a9-8f116ee73cec&inProgressOk=true of size 1048576 edits # 71 loaded in 0 seconds
2019-09-15 04:38:34,185 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1840 - Marking all datanodes as stale
2019-09-15 04:38:34,186 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1247 - Will take over writing edit logs at txnid 316
2019-09-15 04:38:34,192 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 316
2019-09-15 04:38:34,744 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:769 - Initializing quota with 4 thread(s)
2019-09-15 04:38:34,749 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:778 - Quota initialization completed in 5 milliseconds
name space=6
storage space=2013265920
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-09-15 04:38:34,758 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.82:9866, datanodeUuid=7f51c406-ca97-43fe-bde5-99f4814db4d0, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 7f51c406-ca97-43fe-bde5-99f4814db4d0
2019-09-15 04:38:34,761 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.82:9866
2019-09-15 04:38:34,765 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 7f51c406-ca97-43fe-bde5-99f4814db4d0 (192.168.122.82:9866).
2019-09-15 04:38:34,767 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.197:9866, datanodeUuid=905c77ce-7769-42b2-9169-4d4cc646f9f6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 905c77ce-7769-42b2-9169-4d4cc646f9f6
2019-09-15 04:38:34,768 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.197:9866
2019-09-15 04:38:34,768 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 905c77ce-7769-42b2-9169-4d4cc646f9f6 (192.168.122.197:9866).
2019-09-15 04:38:34,768 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.137:9866, datanodeUuid=41b206c5-4657-4aaa-815b-adf68b525caf, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 41b206c5-4657-4aaa-815b-adf68b525caf
2019-09-15 04:38:34,769 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.137:9866
2019-09-15 04:38:34,769 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 41b206c5-4657-4aaa-815b-adf68b525caf (192.168.122.137:9866).
2019-09-15 04:38:34,769 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(192.168.122.8:9866, datanodeUuid=89f24cb4-5f0d-4659-bf19-dada3b6dcfc8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523) storage 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8
2019-09-15 04:38:34,769 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/192.168.122.8:9866
2019-09-15 04:38:34,770 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8 (192.168.122.8:9866).
2019-09-15 04:38:34,770 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-09-15 04:38:34,812 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb for DN 192.168.122.82:9866
2019-09-15 04:38:34,815 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa for DN 192.168.122.137:9866
2019-09-15 04:38:34,817 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-55f9ef08-2468-44be-b707-26a7a258468a for DN 192.168.122.197:9866
2019-09-15 04:38:34,819 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-9a499255-1089-4fd8-9d09-1328babba9f4 for DN 192.168.122.8:9866
2019-09-15 04:38:34,843 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x60a1b93507f881: Processing first storage report for DS-55f9ef08-2468-44be-b707-26a7a258468a from datanode 905c77ce-7769-42b2-9169-4d4cc646f9f6
2019-09-15 04:38:34,847 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x60a1b93507f881: from storage DS-55f9ef08-2468-44be-b707-26a7a258468a node DatanodeRegistration(192.168.122.197:9866, datanodeUuid=905c77ce-7769-42b2-9169-4d4cc646f9f6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 2, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2019-09-15 04:38:34,848 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x58ecf8887a68ff33: Processing first storage report for DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb from datanode 7f51c406-ca97-43fe-bde5-99f4814db4d0
2019-09-15 04:38:34,848 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode extension entered. 
The reported blocks 4 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2019-09-15 04:38:34,848 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x58ecf8887a68ff33: from storage DS-37af643f-dbb8-4aae-9a5f-11fdc951bfbb node DatanodeRegistration(192.168.122.82:9866, datanodeUuid=7f51c406-ca97-43fe-bde5-99f4814db4d0, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 8, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-09-15 04:38:34,857 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0x2c885de5a37dc91: Processing first storage report for DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa from datanode 41b206c5-4657-4aaa-815b-adf68b525caf
2019-09-15 04:38:34,857 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0x2c885de5a37dc91: from storage DS-25622ef7-4ba1-4d1e-8a93-d520f644a4fa node DatanodeRegistration(192.168.122.137:9866, datanodeUuid=41b206c5-4657-4aaa-815b-adf68b525caf, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 9, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 04:38:34,857 INFO  BlockStateChange BlockManager.java:processReport:2541 - BLOCK* processReport 0xd3c2114dfeb78cff: Processing first storage report for DS-9a499255-1089-4fd8-9d09-1328babba9f4 from datanode 89f24cb4-5f0d-4659-bf19-dada3b6dcfc8
2019-09-15 04:38:34,858 INFO  BlockStateChange BlockManager.java:processReport:2570 - BLOCK* processReport 0xd3c2114dfeb78cff: from storage DS-9a499255-1089-4fd8-9d09-1328babba9f4 node DatanodeRegistration(192.168.122.8:9866, datanodeUuid=89f24cb4-5f0d-4659-bf19-dada3b6dcfc8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-f5a19194-e593-4dd9-96a9-8f116ee73cec;nsid=1728015749;c=1568535976523), blocks: 4, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-09-15 04:38:54,853 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:607 - STATE* Safe mode ON, in safe mode extension. 
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-09-15 04:39:01,807 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41162
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 3 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 3 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:01,855 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41162
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:02,557 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41162
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 2 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:03,151 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41166
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:03,198 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41166
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:03,316 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41172
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:03,322 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41174
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:03,339 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41174
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:03,351 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41172
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:03,507 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41178
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:03,518 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41178
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:03,612 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41162
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile3.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 1 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:04,060 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41174
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile4.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:04,142 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41172
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile5.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:04,511 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41178
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile2.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:04,679 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 192.168.122.144:41166
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1452)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2412)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2358)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:774)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:462)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/myfile1.remotecopy._COPYING_. Name node is in safe mode.
The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 0 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	... 13 more
2019-09-15 04:39:04,856 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4792 - initializing replication queues
2019-09-15 04:39:04,857 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:391 - STATE* Safe mode is OFF
2019-09-15 04:39:04,857 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 32 secs
2019-09-15 04:39:04,857 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 1 racks and 4 datanodes
2019-09-15 04:39:04,857 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-09-15 04:39:04,868 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3475 - Total number of blocks            = 5
2019-09-15 04:39:04,868 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3476 - Number of invalid blocks          = 0
2019-09-15 04:39:04,868 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3477 - Number of under-replicated blocks = 0
2019-09-15 04:39:04,868 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3478 - Number of  over-replicated blocks = 0
2019-09-15 04:39:04,868 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3480 - Number of blocks being written    = 0
2019-09-15 04:39:04,869 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3483 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 12 msec
2019-09-15 04:39:06,118 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741870_1046, replicas=192.168.122.82:9866, 192.168.122.137:9866, 192.168.122.8:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 04:39:06,179 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741871_1047, replicas=192.168.122.82:9866, 192.168.122.8:9866, 192.168.122.197:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 04:39:06,711 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741872_1048, replicas=192.168.122.137:9866, 192.168.122.197:9866, 192.168.122.8:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 04:39:07,405 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741873_1049, replicas=192.168.122.137:9866, 192.168.122.82:9866, 192.168.122.8:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 04:39:07,693 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741874_1050, replicas=192.168.122.82:9866, 192.168.122.197:9866, 192.168.122.8:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 04:39:09,205 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1829540716_1
2019-09-15 04:39:09,211 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_261754792_1
2019-09-15 04:39:12,852 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3648ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:39:12,970 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3767ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:39:13,420 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1848264994_1
2019-09-15 04:39:17,509 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 8305ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:39:21,506 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2372ms to send a batch of 2 edits (256 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:39:21,507 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2373ms to send a batch of 2 edits (256 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:39:23,630 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1880ms to send a batch of 1 edits (99 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:39:23,630 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4496ms to send a batch of 2 edits (256 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:39:24,167 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2417ms to send a batch of 1 edits (99 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:39:24,182 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-833675916_1
2019-09-15 04:39:24,187 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 28 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 323 Number of syncs: 17 SyncTimes(ms): 9114 6793 
2019-09-15 04:39:24,195 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_924680671_1
2019-09-15 04:39:52,890 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741875_1051, replicas=192.168.122.197:9866, 192.168.122.8:9866, 192.168.122.82:9866 for /myfile5.remotecopy._COPYING_
2019-09-15 04:39:52,900 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741876_1052, replicas=192.168.122.82:9866, 192.168.122.197:9866, 192.168.122.8:9866 for /myfile4.remotecopy._COPYING_
2019-09-15 04:39:52,926 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741877_1053, replicas=192.168.122.137:9866, 192.168.122.82:9866, 192.168.122.197:9866 for /myfile2.remotecopy._COPYING_
2019-09-15 04:39:53,526 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741878_1054, replicas=192.168.122.137:9866, 192.168.122.8:9866, 192.168.122.82:9866 for /myfile1.remotecopy._COPYING_
2019-09-15 04:39:55,774 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile2.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_1147507706_1
2019-09-15 04:39:55,944 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile4.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1697382743_1
2019-09-15 04:39:56,118 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile5.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1691772756_1
2019-09-15 04:39:56,594 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile1.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1054801367_1
2019-09-15 04:39:59,081 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3305ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:39:59,081 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3305ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:40:02,529 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6753ms to send a batch of 1 edits (128 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:40:09,861 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3452ms to send a batch of 4 edits (573 bytes) to remote journal 192.168.122.137:8485
2019-09-15 04:40:09,873 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3463ms to send a batch of 4 edits (573 bytes) to remote journal 192.168.122.82:8485
2019-09-15 04:40:09,912 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3503ms to send a batch of 4 edits (573 bytes) to remote journal 192.168.122.197:8485
2019-09-15 04:40:10,036 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:804 - BLOCK* allocate blk_1073741879_1055, replicas=192.168.122.8:9866, 192.168.122.82:9866, 192.168.122.197:9866 for /myfile3.remotecopy._COPYING_
2019-09-15 04:40:11,447 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2861 - DIR* completeFile: /myfile3.remotecopy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1818459875_1
